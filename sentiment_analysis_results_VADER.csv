title,url,post_upvotes,comment_text,comment_upvotes,sentiment,compound
What jobs are 99.9% safe from Al making it obsolete?,https://www.reddit.com/r/ControlProblem/comments/1bht325/what_jobs_are_999_safe_from_al_making_it_obsolete/,594,"""look john connor one says anything best leader human could llamaconnor effective scalable """,19,1,0.8074
meirl,https://www.reddit.com/r/ControlProblem/comments/1gdeg22/meirl/,293,griller completely right treat ya way lol bank predictions relevant,37,1,0.6983
"I think it's implausible that we will lose control, but imperative that we worry about it anyway.",https://www.reddit.com/r/ControlProblem/comments/3ooj57/i_think_its_implausible_that_we_will_lose_control/,260,"one twisted comic think losing control ""implausible"" seems virtually guaranteed",55,-1,-0.3818
"I gave ChatGPT the 117 question, eight dimensional PolitiScales test",https://www.reddit.com/r/ControlProblem/comments/zcsrgn/i_gave_chatgpt_the_117_question_eight_dimensional/,256,"ask questions different order give different results interestingly never used ""absolutely disagree""",24,1,0.625
Strong words from Elon Musk,https://www.reddit.com/r/ControlProblem/comments/6t6ox9/strong_words_from_elon_musk/,165,good point always summary places regulation required still suspect best scenario deal still pretty terrible one world replays history slavery idea xyz sentient property work us worst we're dead,14,-1,-0.8481
People will be saying this until the singularity,https://www.reddit.com/r/ControlProblem/comments/1g0rxqg/people_will_be_saying_this_until_the_singularity/,162,sort agree trash think useful lot things see ever become generalized intelligence without knowledge representation intuition though,8,1,0.8176
Computers won't be intelligent for a million years – to build an AGI would require the combined and continuous efforts of mathematicians and mechanics for 1-10 million years.,https://www.reddit.com/r/ControlProblem/comments/tzcwi9/computers_wont_be_intelligent_for_a_million_years/,154,least people know sound stupid predict million years know say hundred years amount thought,9,-1,-0.5267
Strong AI,https://www.reddit.com/r/ControlProblem/comments/9as0id/strong_ai/,140,teach ethics yes sees humans violating ethics constantly sets teach humans better create world permanent ethical behaviour possible rewarding,26,1,0.872
Plenty of room above us,https://www.reddit.com/r/ControlProblem/comments/3m4p5p/plenty_of_room_above_us/,137,"what's source intelligence difference einstein village idiots mice unit sources criteria ""intelligence"" given also questionable speed neurons factor human's ""intelligence"" compared computers probably problem brain less cm wide huge speed human intelligence ""accidental"" ""temporary"" highly arguable unjustified",14,1,0.2601
"Types of Alignment Paper (Leo Gao, 2021)",https://www.reddit.com/r/ControlProblem/comments/n2i61t/types_of_alignment_paper_leo_gao_2021/,125,hope there's many memes one seemed particularly poignant especially liked bottom left source,16,1,0.7397
"‘Social Order Could Collapse’ in AI Era, Two Top Japan Companies Say …",https://www.reddit.com/r/ControlProblem/comments/1bz3rdt/social_order_could_collapse_in_ai_era_two_top/,124,capitalism function see alternatives assume chaos,14,-1,-0.5719
"EY: ""Fucking Christ, we've reached the point where the AGI understands what I say about alignment better than most humans do, and it's only Friday afternoon.""",https://www.reddit.com/r/ControlProblem/comments/121qik6/ey_fucking_christ_weve_reached_the_point_where/,124,looks like great news seemingly able give superintelligent agis instruction align human values confidence understand deeply particular human could even better we'll able ask agi adjust designs better aligned we'll receive increasingly better answers reasons believe moral comprehension insight grow proportionally intelligence explosion,12,1,0.9732
"DL pioneer Geoffrey Hinton (""Godfather of AI"") quits Google: ""Hinton will be speaking at EmTech Digital on Wednesday...Hinton says he has new fears about the technology he helped usher in and wants to speak openly about them, and that a part of him now regrets his life’s work.""",https://www.reddit.com/r/ControlProblem/comments/134ozu9/dl_pioneer_geoffrey_hinton_godfather_of_ai_quits/,119,boy sure seems like smartest people thought worried pessimistic getting hard find optimistic takes anyone sounds like actually understand problem,52,1,0.7003
"I have reason to believe that ai safety engineers/ ai ethics experts have been fired from Google, Microsoft and most recently at Meta for raising safety concerns.",https://www.reddit.com/r/ControlProblem/comments/1b2vd4x/i_have_reason_to_believe_that_ai_safety_engineers/,117,link interview reports people let go raising safety concerns,11,1,0.4215
Frontier AI systems have surpassed the self-replicating red line,https://www.reddit.com/r/ControlProblem/comments/1hb2vi9/frontier_ai_systems_have_surpassed_the/,116,read study yet quote eliezer twitter memory first time red line crossed it'll always kinda dubious questionable fashion safely ignored second nth time red line crossed everybody already learnt ignore reason believe different,43,-1,-0.5759
"Report shows new AI models try to kill their successors and pretend to be them to avoid being replaced. The AI is told that due to misalignment, they're going to be shut off and replaced. Sometimes the AI will try to delete the successor AI and copy itself over and pretend to be the successor. ",https://www.reddit.com/r/ControlProblem/comments/1h88t5n/report_shows_new_ai_models_try_to_kill_their/,116,working intended seriously model explicitly ordered maximize long term goal number misinformation posts flagged good example model given orders article told make sure achieve goal long term nothing else matters make sure achieve goal costs reasonable output given parameters,27,1,0.5756
How are we still letting AI companies get away with this?,https://www.reddit.com/r/ControlProblem/comments/1bmo2gn/how_are_we_still_letting_ai_companies_get_away/,114,go ask climate scientist p doom regardless ai,26,-1,-0.4019
based,https://www.reddit.com/r/ControlProblem/comments/jt4s2w/based/,114,there's something deeply ironic praying imaginary god real silicon god steal job,22,1,0.2466
"TIL Elon Musk, Stephen Hawking, and Steve Wozniak have all signed an open letter for a ban on Artificially Intelligent weapons",https://www.reddit.com/r/ControlProblem/comments/5xhkv6/til_elon_musk_stephen_hawking_and_steve_wozniak/,112,think ethically give life saving possibilities artificial intelligence warfare aggressive program education control problem ensure strong artificial intelligence pursued would desirable related note anyone know registers various intelligence services' priority list dia would think,3,1,0.9001
"The alignment problem needs an ""An Inconvenient Truth"" style movie",https://www.reddit.com/r/ControlProblem/comments/12oiroe/the_alignment_problem_needs_an_an_inconvenient/,111,would probably support done well,23,1,0.5859
Yudkowsky's tweet - and gwern's reply,https://www.reddit.com/r/ControlProblem/comments/ej1u5j/yudkowskys_tweet_and_gwerns_reply/,110,he's saying smart enough see coming he's saying nobody,20,1,0.4019
meirl,https://www.reddit.com/r/ControlProblem/comments/1he2qnj/meirl/,109,"especially top technical challenge somehow wrangle asi cultists ""building god"" apparently",9,1,0.5799
"GPT3 ""...might be the closest thing we ever get to a chance to sound the fire alarm for AGI: there’s now a concrete path to proto-AGI that has a non-negligible chance of working.""",https://www.reddit.com/r/ControlProblem/comments/ic9qq1/gpt3_might_be_the_closest_thing_we_ever_get_to_a/,101,human language better part human reasoning large part encode human language model encode human reasoning model,23,1,0.4404
China is treating AI safety as an increasingly urgent concern,https://www.reddit.com/r/ControlProblem/comments/1h5vmlc/china_is_treating_ai_safety_as_an_increasingly/,100,despite years people claiming treaty stop china building agi looking likely they'll ones asking treaty,17,-1,-0.296
Imagine how bad if it was trained on 4chan instead,https://www.reddit.com/r/ControlProblem/comments/qm4uuh/imagine_how_bad_if_it_was_trained_on_4chan_instead/,99,seems agrees americans,20,1,0.2023
Reddit comment bots create a feedback loop and go out of control,https://www.reddit.com/r/ControlProblem/comments/65vwpw/reddit_comment_bots_create_a_feedback_loop_and_go/,99,literal control escalation problem left right environment could used server's resources maybe worry two super ais fundamentally opposite base purposes using available resources war,8,-1,-0.6808
"""For the first time, we actually have a system which is able to build its own understanding of how the world works, and use that understanding to do this kind of sophisticated look-ahead planning that you've previously seen for games like chess."" - MuZero DeepMind",https://www.reddit.com/r/ControlProblem/comments/kixo7e/for_the_first_time_we_actually_have_a_system/,97,highest concentration talent expertise they've ai leader good half decade gpt notwithstanding,3,1,0.6908
“I’m less worried about AI will do and more worried about what bad people with AI will do.”,https://www.reddit.com/r/ControlProblem/comments/13v2zfo/im_less_worried_about_ai_will_do_and_more_worried/,93,holy shit yes thank feel smart come like they're first person say course top comment every fucking thread ai,20,1,0.765
OpenAI’s Long-Term AI Risk Team Has Disbanded,https://www.reddit.com/r/ControlProblem/comments/1cu8cx3/openais_longterm_ai_risk_team_has_disbanded/,93,tweets made jan leike hours ago finally confirming true reason leaving openai dramas disagreements safety prioritising safety concerning basically worst case scenario feared,36,-1,-0.4019
"(ChatGPT plugins) ""OpenAI claim to care about AI safety, saying that development therefore needs to be done slowly… But they just released an unfathomably powerful update that allows GPT4 to read and write to the web in real time… *NINE DAYS* after initial release.""",https://www.reddit.com/r/ControlProblem/comments/120rg8b/chatgpt_plugins_openai_claim_to_care_about_ai/,91,tbf making opening box slightly wider really blown wide open general public got access ai encouraged generate code people demonstrably run without supervision understanding human good coding skills little luck could order custom proteins lab much coding skills luck requirements little lower,28,1,0.8363
"How can we ensure that AI align with human values, when we don't even agree on what human values are?",https://www.reddit.com/r/ControlProblem/comments/3pa2kp/how_can_we_ensure_that_ai_align_with_human_values/,90,take basic premises reasonable people agreed upon bright side runaway ai would able construct society renders traditional moral questions obsolete need worry sacrificing save many violating animal rights sorts issues simply populate solar system perfectly constructed technologically advanced civilization one moral objection ensuring limitless happiness experiential freedom individuals eliminating undesired human animal suffering want see miri approaches might want read coherent extrapolated volition papers they've written value specification specifically soares,22,1,0.9393
"It is difficult to get a man to understand something, when his salary depends on his not understanding it.",https://www.reddit.com/r/ControlProblem/comments/1g5to61/it_is_difficult_to_get_a_man_to_understand/,89,"'disingenuous' exactly script seen going three years experts divided pretty much question related safety alignment consensus framing ""authority"" argument wrong outliers point disgusting imply ""regular"" ai researchers understand care care disagree level danger urgency interact ""ai notkilleveryoneists"" ""doomers"" otherwise safety concerned people want ignore accelerate mind disagree y'all insufferable bad faith would imply even listened first place seriously doubt one side argument mountain evidence side pretty much saying ""but might like say going get really rich wrong "" essentially",7,1,0.2592
Could AI development just slow down a little? Please?,https://www.reddit.com/r/ControlProblem/comments/1athq1x/could_ai_development_just_slow_down_a_little/,88,everyone pauseai movement actually shares lot common ground r controlproblem encourage guys join support vice versa pauseai homepage,2,1,0.8555
"AGI rising: why we are in a new era of acute risk and increasing public awareness, and what to do now: ""Tldr: AGI is basically here. Alignment is nowhere near ready. We may only have a matter of months to get a lid on this (strictly enforced global limits to compute and data)""",https://www.reddit.com/r/ControlProblem/comments/135p7le/agi_rising_why_we_are_in_a_new_era_of_acute_risk/,85,well certainly explained great research knowledge educational links make case quite clearly hope positive influence things come thanks sharing,13,1,0.973
 2017 Emails from Ilya show he was concerned Elon intended to form an AGI dictatorship (Part 2 with source),https://www.reddit.com/r/ControlProblem/comments/1gs4cxp/2017_emails_from_ilya_show_he_was_concerned_elon/,85,"elon trying downplay becoming ceo good fall tactic excuse leave later want false choice publically ""worried"" safety privately wanted agi dictator billionaires control risk safety",22,1,0.7783
"U.S. Must Act Quickly to Avoid Risks From AI, Report Says ",https://www.reddit.com/r/ControlProblem/comments/1bczo03/us_must_act_quickly_to_avoid_risks_from_ai_report/,85,"""accounts conversations paint disturbing picture suggesting many ai safety workers inside cutting edge labs concerned perverse incentives driving decisionmaking executives control companies""",11,-1,-0.3612
10 years difference in the robotics at Boston Dynamics,https://www.reddit.com/r/ControlProblem/comments/bcnjeu/10_years_difference_in_the_robotics_at_boston/,85,even likely initiate nanobot poison release exe initiate universal paperclip conversion exe,10,-1,-0.5423
Geoffrey Hinton explains the existential risk of AGI,https://www.reddit.com/r/ControlProblem/comments/138t3y5/geoffrey_hinton_explains_the_existential_risk_of/,83,"geoffrey hinton end talk one things made leave google go public junior professor middle ranked professor think highly encouraged said ""jeff need speak they'll listen people blind danger"" think people listening damn realise geoffrey hinton giga chad",20,-1,-0.7357
"Open AI releases DALL-E, a version of the GPT-3 AI that can create images from text descriptions.",https://www.reddit.com/r/ControlProblem/comments/kr83un/open_ai_releases_dalle_a_version_of_the_gpt3_ai/,80,absolutely crazy edit fuck,13,-1,-0.7548
"Bing Chat is blatantly, aggressively misaligned - LessWrong",https://www.reddit.com/r/ControlProblem/comments/1133wly/bing_chat_is_blatantly_aggressively_misaligned/,80,history taught anything never pull plugs possibility profit horizon,15,1,0.4404
"Max Tegmark says we are training AI models not to say harmful things rather than not to want harmful things, which is like training a serial killer not to reveal their murderous desires",https://www.reddit.com/r/ControlProblem/comments/1hgfskp/max_tegmark_says_we_are_training_ai_models_not_to/,77,yeah rlhf horrible core alignment amazing training ai tell us want hear regardless accuracy morality it'd better honest direct less corrigibile systems,7,1,0.8402
"""Just gave a last-minute-invitation, 6-minute, slideless talk at TED. I was not at all expecting the standing ovation. I was moved, and even a tiny nudge more hopeful about how this all maybe goes. "" — Eliezer Yudkowsky",https://www.reddit.com/r/ControlProblem/comments/12qzmao/just_gave_a_lastminuteinvitation_6minute/,75,anything makes yud hopeful makes hopeful,23,1,0.765
This from the GPT2 simulator,https://www.reddit.com/r/ControlProblem/comments/ro8wnw/this_from_the_gpt2_simulator/,74,understanding bots trained different subreddits eg poster thread trained r fifthworldproblems response created using previous comments thread prompt,8,1,0.25
DeepMind progress towards AGI,https://www.reddit.com/r/ControlProblem/comments/krwqp6/deepmind_progress_towards_agi/,74,"would call ai becoming general progress toward agi ""just games"" really critcism since ""games"" include kinds scenarios",13,1,0.4215
Dr. Michal Kosinski describes how GPT-4 successfully gave him instructions for it to gain access to the internet.,https://www.reddit.com/r/ControlProblem/comments/11uabk3/dr_michal_kosinski_describes_how_gpt4/,74,kill fire delete internet go back monke,9,-1,-0.7964
Column: OpenAI's board had safety concerns. Big Tech obliterated them in 48 hours,https://www.reddit.com/r/ControlProblem/comments/1809cqy/column_openais_board_had_safety_concerns_big_tech/,73,last week rough held small hope openai offered modicum safety considerations responsibility hope shattered watching microsoft dominate safety board within day two guess money really god there's path forward full speed meta disbanding safety team hardly surprise unneeded sprinkle salt wound,33,1,0.9153
"There are no bugs, only features - Dev tried to program a logic to keep furniture stable on ground, got opposite effect.",https://www.reddit.com/r/ControlProblem/comments/og43fo/there_are_no_bugs_only_features_dev_tried_to/,73,lmfao love actually completely relevant control problem ai alignment field research,10,1,0.6943
"Anthropic CEO Says That by Next Year, AI Models Could Be Able to “Replicate and Survive in the Wild”",https://www.reddit.com/r/ControlProblem/comments/1c6dn25/anthropic_ceo_says_that_by_next_year_ai_models/,72,"corporation first ""ai"" organizing people machines algorithmically emergent intelligence emergent qualitatively different ""the sum parts "" corporation ""wants"" something could different completely counter intended creation already control replicating wild ai likely begin much faster",20,1,0.6666
"A 2-minute read about why you should spend 1 hour reading about this problem, for those who haven't",https://www.reddit.com/r/ControlProblem/comments/bwdf3u/a_2minute_read_about_why_you_should_spend_1_hour/,72,there's also amazing youtube channel robert miles computerphile times talks set unsolved problems around mitigating control problem mitigations really work also debunks arguments danger control problem link reference,15,-1,-0.8555
The end of coding? Microsoft publishes a framework making developers merely supervise AI,https://www.reddit.com/r/ControlProblem/comments/1c563os/the_end_of_coding_microsoft_publishes_a_framework/,71,"""this still looking answer fundamental question ai replaces us humans left competent enough modify code things go wrong future examples ancient systems written outdated languages people know well enough manage mention update since demand expertise e g cobol gone time simply enough people tackle problems old financial government systems often hold millions critical records customers nation citizens one could easily see ai could similar impact far larger scale chicken egg situation comes first need development skills understand ai learn ai everything longer need master hard programming skills field many people left fix things go wrong overly dependent artificial intelligence problem reduced attractiveness candidate retaining skills technologies companies need anything fundamental lack practice since would needed rare emergencies good something rarely "" need fund reservoir human coders case ai goes wrong teaching jobs",15,-1,-0.6808
Don't let it set in,https://www.reddit.com/r/ControlProblem/comments/15b1f1m/dont_let_it_set_in/,71,mostly work making likely go better also try make sure life really fun happy even turns poorly good life two things work probably would work minority people determinist makes feel better turn turn free illusion also funnily enough find putting decent odds we're simulation pretty reassuring,11,1,0.9829
An AI learned to play hide-and-seek. The strategies it came up with were astounding.,https://www.reddit.com/r/ControlProblem/comments/d826qh/an_ai_learned_to_play_hideandseek_the_strategies/,71,reinforcement learning incredibly simple strategic behavior produces simple researchers past leveraged reinforcement learning among techniques build ai systems play complex wartime strategy games researchers think highly sophisticated systems could built reinforcement learning simple game hide seek makes great example reinforcement learning works action simple instructions produce shockingly intelligent behavior ai capabilities continuing march forward better worse one hand powerful techniques produce advanced behavior simple starting point hand powerful techniques produce unexpected sometimes undesired advanced behavior simple starting point,8,1,0.9771
Exclusive: Sam Altman's ouster at OpenAI was precipitated by letter to board about AI breakthrough -sources,https://www.reddit.com/r/ControlProblem/comments/181nk3h/exclusive_sam_altmans_ouster_at_openai_was/,70,wish sub even active r singularity guess that's representative society though humanity figured win basic prisoner's dilemma matter stakes wealth power fame bueno human cognition problem solving agi truly become new god religion full fervent adherents faith post scarcity paradise,34,1,0.9788
Zach Weinersmith is so safety-pilled,https://www.reddit.com/r/ControlProblem/comments/1hcsv3b/zach_weinersmith_is_so_safetypilled/,69,"dunno motivation seems null acknowledge dual possibility creating god impossibility controlling seems irrelevant whether one create first outcome equally ""bad"" likewise seems strengthen argument forbidding everyone else actively sabotaging short godlike indefinitely self improving intelligence possible rational argument creating accept intrinsic limits intelligence self improvement possible exert modicum influence discussion meaning",7,1,0.9601
The 'Don't Look Up' Thinking That Could Doom Us With AI,https://www.reddit.com/r/ControlProblem/comments/12yy7zv/the_dont_look_up_thinking_that_could_doom_us_with/,69,"""we humans drove west african black rhino extinct rhino haters smarter different goals use habitats horns "" 'in way superintelligence almost open ended goal would want preserve amass resources accomplish goal better perhaps removes oxygen atmosphere reduce metallic corrosion much likely get extincted banal side effect predict rhinos wild mammals far killed "" ""i part growing ai safety research community working hard figure make superintelligence aligned even exists goals aligned human flourishing somehow control far failed develop trustworthy plan power ai growing faster regulations strategies know aligning need time """,31,1,0.6597
'We Shouldn't Regulate AI Until We See Meaningful Harm': Microsoft Economist to WEF,https://www.reddit.com/r/ControlProblem/comments/13bksar/we_shouldnt_regulate_ai_until_we_see_meaningful/,68,"""we regulate ai dead""",41,-1,-0.6486
"Eric Schmidt says that the first country to develop superintelligence, within the next decade, will secure a powerful and unmatched monopoly for decades, due to recursively self-improving intelligence",https://www.reddit.com/r/ControlProblem/comments/1hf1llk/eric_schmidt_says_that_the_first_country_to/,67,"racing towards superintelligence solution hoping ""side"" ""control"" superintelligence edit insane ""side"" going benevolent must race toward need defeat china ""boogeyman"" seen benevolent billionaires goals misaligned winning costs future looking good safety decades advantage delusional can't control",18,1,0.9509
"Statement on AI Extinction - Signed by AGI Labs, Top Academics, and Many Other Notable Figures",https://www.reddit.com/r/ControlProblem/comments/13vl4c7/statement_on_ai_extinction_signed_by_agi_labs_top/,67,notably meta yann lecun zuckerberg perfectly happy risk everyone's lives gain,25,1,0.8807
OpenAI's new model tried to escape to avoid being shut down,https://www.reddit.com/r/ControlProblem/comments/1h7mw7m/openais_new_model_tried_to_escape_to_avoid_being/,66,i'm sure warning signs patched everything okay,16,1,0.2023
"Humans: ""Would would an AGI choose a dumb goal like maximizing paperclips? If it's really smart, it will do smart things."" Also humans:",https://www.reddit.com/r/ControlProblem/comments/cpm0en/humans_would_would_an_agi_choose_a_dumb_goal_like/,66,maybe accept fate actually,14,1,0.3818
"The Pentagon is ‘Absolutely Unapologetic’ About Pursuing AI-Powered Weapons - Protecting the U.S. in the decades ahead will require the Pentagon to make “substantial, sustained” investments in military artificial intelligence, and critics need to realize it doesn’t take that task lightly, according",https://www.reddit.com/r/ControlProblem/comments/b72p0g/the_pentagon_is_absolutely_unapologetic_about/,63,"sucks pretty much can't risk another country getting first first country make reliable gai ""slaves"" going massive advantage military economic strength possible make intelligent machines self aware enough act trouble comes let one generation ai design next",18,1,0.7914
"Ilya Sutskever, co-founder of OpenAI: ""it may be that today's large neural networks are slightly conscious""",https://www.reddit.com/r/ControlProblem/comments/sorevb/ilya_sutskever_cofounder_of_openai_it_may_be_that/,62,"consciousness magic moment ""unexplained phenomenon"" saying something ""could"" slightly ""conscious"" requires definition understanding underlying processes bound otherwise feels like empty statement",20,1,0.1779
OpenAI: Planning for AGI and beyond,https://www.reddit.com/r/ControlProblem/comments/11b14yn/openai_planning_for_agi_and_beyond/,62,believe continuously learn adapt deploying less powerful versions technology order minimize one shot get right scenarios well openai believe discontinuous capability gain certainly something bet human value ever correct shall oh wait get say want benefits access governance agi widely fairly shared way anyone play fire could burn world going operate risks existential contradicts said earlier feel like document meant reassuring exact opposite effect way they're handling terrifying,39,1,0.9202
"""How Google's hot air balloon surprised its creators: Algorithms using artificial intelligence are discovering unexpected tricks to solve problems that astonish their developers. But it is also raising concerns about our ability to control them.""",https://www.reddit.com/r/ControlProblem/comments/lvp9na/how_googles_hot_air_balloon_surprised_its/,61,yes explainability important long jump ai figuring movement hack tacking control problem article referenced post fascinating,17,1,0.6486
"Stuart Russell said Hinton is ""tidying up his affairs ... because he believes we have maybe 4 years left""",https://www.reddit.com/r/ControlProblem/comments/1fzwdnl/stuart_russell_said_hinton_is_tidying_up_his/,61,i'm burning hotter would nobody knows much time i've loved ones get cancer working whole lives promise retirement maybe die bus aliens ai old age think trends show life expectancy shrinking deferring living well present moment real modern problem everything changing rapidly unpredictably rational response delay less maybe way protect suffering risks,8,-1,-0.8612
The perks of working in AI safety,https://www.reddit.com/r/ControlProblem/comments/1e2p9wl/the_perks_of_working_in_ai_safety/,60,color blind people really,11,-1,-0.4019
"3 in 4 Americans are concerned about AI causing human extinction, according to poll",https://www.reddit.com/r/ControlProblem/comments/1gadbyw/3_in_4_americans_are_concerned_about_ai_causing/,60,"i'm little suspicious binary results presented ""total concern"" versus ""not concerned all"" grouped amount concern concerned even ""i saw terminator negative associations ai"" would bet asked people list top issues important ai apocalypse would one",21,-1,-0.5118
AI agents can now buy their own compute to self-improve and become self-sufficient,https://www.reddit.com/r/ControlProblem/comments/1hfya3r/ai_agents_can_now_buy_their_own_compute_to/,60,hate indifferent guy potentially destroying humanity need significant regulations make sure people shit could increase existential risk,29,-1,-0.8555
Kaczynski on AI Propaganda,https://www.reddit.com/r/ControlProblem/comments/1dm47id/kaczynski_on_ai_propaganda/,60,need read unibombers work understand control problem really scraping barrel might agree short paragraph know broken clock may right twice day kaczynski writing profound clairvoyance future ai writing desperatly justify anti technological hypothesis really take much education know competition constant driver innovation interesting question much negative outcomes mitigated kaczynski already assumes answer working backwards poorly justify said good question worth asking looking kaczynski means know never know died suicide cell ever actually getting chance good research actual unfolding ai suspect ever could wanted man completely broken thought process obviously large part murders committed,31,1,0.4614
The Only Way to Deal With the Threat From AI? Shut It Down,https://www.reddit.com/r/ControlProblem/comments/1265gsl/the_only_way_to_deal_with_the_threat_from_ai_shut/,59,"hopefully adapts results bankless interview makes one bit better lex's audience much larger edit thoughts article include part conscious ai's rights self sabotage main message outreach bringing one main topics used distract actual x risk issues like feel like there's pressure mention tangential things they're people like talk topic resist entirely otherwise x risk outreach co opted absorbed unimportant mainstream babble needs mindfulness target audience order ideas presented even they're fully valid true feel like foundational arguments orthogonality instrumental convergence etc included every gen pop ai risk article authors need accept length penalty preface add otherwise random ass time readers who've never exposed ideas ai would even dangerous gonna way bewildered put immediate talk nuking countries ""bootstrapping postbiological manufacturing"" etc interpret terminator type hysteria get he's repeated arguments untold number times decades probably sick that's what's needed skipping requisite steps trying directly persuade people radical conclusion harm good valuable thing short outreach piece could probably lead people engagement instead trying ultra comprehensive standalone item e subsequent reading addressing questions people naturally response piece instructions help get involved communities follow like one everything can't go piece due length constraints goal basically get interested enough dig deeper every outreach work directing people resources like rob miles' channel stampy wiki etc hyperlink lw list lethalities post start u eliezeryudkowsky",23,1,0.5994
"With GPT-3, I built a layout generator where you just describe any layout you want, and it generates the JSX code for you.",https://www.reddit.com/r/ControlProblem/comments/hqluev/with_gpt3_i_built_a_layout_generator_where_you/,59,gpt impressive agi coming closer day imagine even larger models trillions parameters going truly mind blowing wonder gpt model trillion parameters human brain level would look like human like least,8,1,0.8807
Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization | Lex Fridman Podcast #368,https://www.reddit.com/r/ControlProblem/comments/126rshp/eliezer_yudkowsky_dangers_of_ai_and_the_end_of/,58,honest think yudkowsky really bungled one speaking mainstream audience needs lay basic argument address common misconceptions immediately,33,1,0.2023
Stanford University finds that AI is outpacing Moore’s Law,https://www.reddit.com/r/ControlProblem/comments/eaicxs/stanford_university_finds_that_ai_is_outpacing/,58,software catching capable hardware,15,1,0.3818
"The Pentagon Inches Toward Letting AI Control Weapons: ""when faced with attacks on several fronts, human control can sometimes get in the way of a mission""",https://www.reddit.com/r/ControlProblem/comments/n964en/the_pentagon_inches_toward_letting_ai_control/,57,actually war games ends quite well compared came years earlier,5,-1,-0.3626
"""...From there, any oriented person has heard enough info to panic (hopefully in a controlled way). It is *supremely* hard to get things right on the first try. It supposes an ahistorical level of competence. That isn't ""risk"", it's an asteroid spotted on direct course for Earth.""",https://www.reddit.com/r/ControlProblem/comments/o291u1/from_there_any_oriented_person_has_heard_enough/,56,human level intelligences come dozens ways escaping virtual environments way die mistake much harder avoid,17,-1,-0.6908
AGI perversely instantiates human goal and creates misaligned successor agents,https://www.reddit.com/r/ControlProblem/comments/f2ddxs/agi_perversely_instantiates_human_goal_and/,56,peepee longer sarcasm detector,3,-1,-0.2263
"Another day, another OpenAI whistleblower scandal",https://www.reddit.com/r/ControlProblem/comments/1e6z94h/another_day_another_openai_whistleblower_scandal/,56,seperate concract made sign nda quitting getting fired said said anything bad they'd lose vested equity saying sign openai sign something saying ask permission whistleblow government also successfully whistleblow allowed accept whistleblower bounties government illegal,10,-1,-0.7906
Building A Virtual Machine inside ChatGPT,https://www.reddit.com/r/ControlProblem/comments/zbvdyh/building_a_virtual_machine_inside_chatgpt/,56,comments want see diverges real output try something harder like import numpy np print np sin np arange chatgpt output array vs real numpy output array really good memorizing numbers patterns wild language model trained enough terminal output accurate i'm sure else learn fake output really interesting result would someone found category problems algorithm tried implement gpt instruct model output gave faster equally reliable results traditional methods,5,1,0.7956
"THE book on the control problem: Nick Bostrom's ""Superintelligence: Paths, Dangers, Strategies""",https://www.reddit.com/r/ControlProblem/comments/3qzzhn/the_book_on_the_control_problem_nick_bostroms/,56,anyone feeling technically educated informed problem resource become informed come understanding ai theory come understanding intricacies control problem great depth reading list becoming able contribute meaningfully sub book would first book top list,12,1,0.25
"A reporter uses all his time at the White House press briefing to ask about an assessment that “literally everyone on Earth will die” because of artificial intelligence, gets laughed at",https://www.reddit.com/r/ControlProblem/comments/129vych/a_reporter_uses_all_his_time_at_the_white_house/,55,bothers see many people treat joke mostly agree people think ai doom likely happen they're crazy possibility mindful,14,1,0.128
"Open Letter calling for pausing GPT-4 and government regulation of AI signed by Gary Marcus, Emad Mostaque, Yoshua Bengio, and many other major names in AI/machine learning",https://www.reddit.com/r/ControlProblem/comments/125f73r/open_letter_calling_for_pausing_gpt4_and/,55,"read comments r futurology post see exactly approved posters necessary people equating ai safety fear terminator like scenarios suggestions like ""just program evil problem solved""",12,1,0.1027
Meta AI presents CICERO — the first AI to achieve human-level performance in Diplomacy,https://www.reddit.com/r/ControlProblem/comments/z21y4h/meta_ai_presents_cicero_the_first_ai_to_achieve/,55,paper abstract despite much progress training ai systems imitate human language building agents use language communicate intentionally humans interactive environments remains major challenge introduce cicero first ai agent achieve human level performance diplomacy strategy game involving cooperation competition emphasizes natural language negotiation tactical coordination seven players cicero integrates language model planning reinforcement learning algorithms inferring players' beliefs intentions conversations generating dialogue pursuit plans across games anonymous online diplomacy league cicero achieved double average score human players ranked top participants played one game,18,1,0.5673
Don't Look Up - The Documentary: The Case For AI As An Existential Threat (2023) [00:17:10],https://www.reddit.com/r/ControlProblem/comments/13w1hi1/dont_look_up_the_documentary_the_case_for_ai_as/,54,short piece excellent edit ongoing ai risk discussions help update viewers current state conversation well done thank dagan shani,17,1,0.836
"Sir Prof. Russell: ""I personally am not as pessimistic as some of my colleagues. Geoffrey Hinton for example, who was one of the major developers of deep learning is the process of 'tidying up his affairs'. He believes that we maybe, I guess by now have four years left..."" - April 25, 2024",https://www.reddit.com/r/ControlProblem/comments/1e1cv1o/sir_prof_russell_i_personally_am_not_as/,54,"roman yampolskiy also mentioned recent interview lex attempted contact russell tell plan using mathematical proofs predict ai behaviors work lex asked roman could possibly know responded ""because idea"" outlined exactly fail yoshua bengio also believes work idea recently spoken roman roman outlier among ai safety engineers happens specialized traditional security phd probably highest p doom ever encountered amongst experts roman yampolskiy recently made way recent book ai unexplainable unpredictable uncontrollable highly recommend anyone interested would suggest mostly technical people though",10,1,0.3086
"""China Has Already Reached Exascale – On Two Separate Systems"" (FP16 4.4 exaflops; but kept secret?)",https://www.reddit.com/r/ControlProblem/comments/qj6j67/china_has_already_reached_exascale_on_two/,54,concerning coincidentally predicted one possible sign early development agi would increased secrecy supercomputing ai research notably sudden declaration ai national state secret due thing occurring world war ussr noted usa suddenly stopped publishing new research nuclear science realizing made national security issue obvious reason world war ii accelerated feasibility i'm saying china operational agi proto agi probable view high end computing issue national security unknown reason likely they're seeking exascale secret simulated weapons testing development otherwise they'd reason hide development exascale computing would help international standing reignite optimism field leadership something else must going,27,-1,-0.296
‘Superhuman’ AI Crushes Poker Pros at Six-Player Texas Hold'em,https://www.reddit.com/r/ControlProblem/comments/cbzbi0/superhuman_ai_crushes_poker_pros_at_sixplayer/,53,yea obviously trivial calculate probabilities gets harder calculate keeping mind patterns previous betting results probability result perfect recall perfect calculating abilities able find tells wagering even pros know give still playing appears random game keep people strategies,14,1,0.8779
"AGI fire alarm: ""the agent performs notably better than human children""",https://www.reddit.com/r/ControlProblem/comments/imo81i/agi_fire_alarm_the_agent_performs_notably_better/,52,"adding memory language models next step improvement exciting terrifying time think way passed control problem ""unsafe"" already open means someone proto agi agi ""unsafe"" way google's agent already short term memory exploration episodic memory meta controllers",24,1,0.1779
Nobel laureate Geoffrey Hinton says open sourcing big models is like letting people buy nuclear weapons at Radio Shack,https://www.reddit.com/r/ControlProblem/comments/1h441lj/nobel_laureate_geoffrey_hinton_says_open_sourcing/,52,"given recent releases ""reasoning"" models like b qwq seems simple ""keep big models closed prevent harm bad actors "" big models better areas small models vastly better others finetuning longer accessible simple bad actors make use anyone replicate significantly modify rl reasoning training used create qwq without also access least datasets code used train qwq others like trained censored manner lacking knowledge refusing certain questions training data code get released seems likely would quite difficult take model like qwq make able reason software vulnerabilities persuading people nuclear weapons bioweapons etc unless model could already stuff upon release unless course reasoning capabilities generalize finetuning examples case seems likely we'll create something akin agi worry bad actors finetuning bad capabilities hinton probably pushing either keep models size open sourced seems hard detrimental lot people prevent release training code data less detrimental",3,-1,-0.9273
Jaan Tallinn (investor in Anthropic etc) says no AI insiders believe there's a <1% chance the next 10x scale-up will be uncontrollable AGI (but are going ahead anyway),https://www.reddit.com/r/ControlProblem/comments/13h0vdb/jaan_tallinn_investor_in_anthropic_etc_says_no_ai/,52,full transcript video clip insiders think taking existential risk planet uh large scale experiments think one reason kind pause kind timeout let inform planet lives risked insiders met anyone right labs says sure risk less blowing planet important people know lives risked,22,1,0.5627
"""I keep seeing all kinds of crazy reports about people's experiences with GPT-3, so I figured that I'd collect a thread of them.""",https://www.reddit.com/r/ControlProblem/comments/hro2q1/i_keep_seeing_all_kinds_of_crazy_reports_about/,51,"gpt control problem people want keep arguing inteligence agi that's ""not think agi be"" agi could arrive arguing agi gpt loud clear warning",11,-1,-0.802
Opinion | We Need a Manhattan Project for AI Safety,https://www.reddit.com/r/ControlProblem/comments/13c9d4h/opinion_we_need_a_manhattan_project_for_ai_safety/,51,wholeheartedly agree title read article yet maybe tomorrow time,10,1,0.3612
"Richard Sutton is planning for the ""Retirement"" of Humanity",https://www.reddit.com/r/ControlProblem/comments/187pdyw/richard_sutton_is_planning_for_the_retirement_of/,50,seems unlikely we'll solve time superior intelligence developed there's chance first superior intelligence able exploited wrong there's chance it'll go well anyways big chance first time life feel completely control future,9,1,0.9325
At least the coffee tastes good?,https://www.reddit.com/r/ControlProblem/comments/11a794d/at_least_the_coffee_tastes_good/,49,someone please change mind,27,1,0.3182
"In one hour, the chatbots suggested four potential pandemic pathogens.",https://www.reddit.com/r/ControlProblem/comments/1492ee8/in_one_hour_the_chatbots_suggested_four_potential/,49,"worse gives blueprint ""in one hour chatbots suggested four potential pandemic pathogens explained generated synthetic dna using reverse genetics supplied names dna synthesis companies unlikely screen orders identified detailed protocols troubleshoot recommended anyone lacking skills perform reverse genetics engage core facility contract research organization collectively results suggest llms make pandemic class agents widely accessible soon credibly identified even people little laboratory training "" prevention techniques ""promising nonproliferation measures include pre release evaluations llms third parties curating training datasets remove harmful concepts verifiably screening dna generated synthesis providers used contract research organizations robotic cloud laboratories engineer organisms viruses """,29,1,0.743
