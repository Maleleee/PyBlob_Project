title,url,post_upvotes,comment_text,comment_upvotes,sentiment,compound
"I think it's implausible that we will lose control, but imperative that we worry about it anyway.",https://www.reddit.com/r/ControlProblem/comments/3ooj57/i_think_its_implausible_that_we_will_lose_control/,260,"that is one twisted comic

why do you think losing control is ""implausible""  it seems virtually guaranteed to me
",56,-1,-0.3818
"DL pioneer Geoffrey Hinton (""Godfather of AI"") quits Google: ""Hinton will be speaking at EmTech Digital on Wednesday...Hinton says he has new fears about the technology he helped usher in and wants to speak openly about them, and that a part of him now regrets his life’s work.""",https://www.reddit.com/r/ControlProblem/comments/134ozu9/dl_pioneer_geoffrey_hinton_godfather_of_ai_quits/,121,boy it sure seems like the smartest people who have thought about this the most are worriedpessimistic getting hard to find optimistic takes from anyone that sounds like they actually understand the problem,49,1,0.8591
'We Shouldn't Regulate AI Until We See Meaningful Harm': Microsoft Economist to WEF,https://www.reddit.com/r/ControlProblem/comments/13bksar/we_shouldnt_regulate_ai_until_we_see_meaningful/,66,"""we shouldn't regulate ai until we are all dead""",40,-1,-0.6486
OpenAI’s Long-Term AI Risk Team Has Disbanded,https://www.reddit.com/r/ControlProblem/comments/1cu8cx3/openais_longterm_ai_risk_team_has_disbanded/,92,those tweets made be jan leike  hours ago finally confirming that it's true that the reason for leaving and all of those openai dramas were disagreements about safety and not prioritising safety are very concerning this is basically the worst case scenario and what i feared most,39,-1,-0.4019
OpenAI: Planning for AGI and beyond,https://www.reddit.com/r/ControlProblem/comments/11b14yn/openai_planning_for_agi_and_beyond/,60," we believe we have to continuously learn and adapt by deploying less powerful versions of the technology in order to minimize one shot to get it right scenarios

well openai don't believe in discontinuous capability gain 

that certainly is something how about we bet all human value ever on them being correct shall we oh wait  we don't get a say

 we want the benefits of access to and governance of agi to be widely and fairly shared

that way anyone can play with the fire that could burn the world down

 we are going to operate as if these risks are existential

so that contradicts what they said earlier

i feel like this document was meant to be reassuring but for me it had the exact opposite effect the way they're handling this is terrifying",38,1,0.4048
meirl,https://www.reddit.com/r/ControlProblem/comments/1gdeg22/meirl/,295,"that griller is completely right to treat ya that way 

lol as if bank predictions are relevant here",37,1,0.6969
Reddit comment bots create a feedback loop and go out of control,https://www.reddit.com/r/ControlProblem/comments/65vwpw/reddit_comment_bots_create_a_feedback_loop_and_go/,99," years from now orbiting the sun a dyson sphere created using every molecule in the solar system will finally be completed allowing umorejpegauto and uquotemebot to continue their dance forever eventually consuming all matter and expediting the ultimate heat death of the universe

gj reddit ",35,1,0.0516
Column: OpenAI's board had safety concerns. Big Tech obliterated them in 48 hours,https://www.reddit.com/r/ControlProblem/comments/1809cqy/column_openais_board_had_safety_concerns_big_tech/,73,"this last week has been rough i held some small hope that openai offered a modicum of safety considerations and responsibility that hope was shattered by watching microsoft dominate the safety board within a day or two

i guess money really is our god and there's no path forward but full speed meta disbanding their safety team was hardly a surprise but an unneeded sprinkle of salt in the wound",34,1,0.8553
Exclusive: Sam Altman's ouster at OpenAI was precipitated by letter to board about AI breakthrough -sources,https://www.reddit.com/r/ControlProblem/comments/181nk3h/exclusive_sam_altmans_ouster_at_openai_was/,70,i wish this sub were even  as active as rsingularity i guess that's representative of society though humanity has not figured out how to win at the very basic prisoner's dilemma no matter the stakes the wealth power and fame  are no bueno for human cognition and problem solving agi has truly become a new god in a religion full of fervent adherents with faith in the post scarcity paradise,34,1,0.9714
"Bankless Podcast #159- ""We're All Gonna Die"" with Eliezer Yudkowsky",https://www.reddit.com/r/ControlProblem/comments/117fza5/bankless_podcast_159_were_all_gonna_die_with/,50,damn i don't know if these guys realised what they were getting themselves into it looks like they wanted a fun chat about chatgpt and how to buy the right shitcoin and instead got an existential crisis,33,-1,-0.25
The 'Don't Look Up' Thinking That Could Doom Us With AI,https://www.reddit.com/r/ControlProblem/comments/12yy7zv/the_dont_look_up_thinking_that_could_doom_us_with/,66,"""we humans drove the west african black rhino extinct not because we were rhinohaters but because we were smarter than them and had different goals for how to use their habitats and horns""

'in the same way superintelligence with almost any openended goal would want to preserve itself and amass resources to accomplish that goal better perhaps it removes the oxygen from the atmosphere to reduce metallic corrosion much more likely we get extincted as a banal side effect that we cant predict any more than those rhinos or the other  of wild mammals weve so far killed off""

""im part of a a growing ai safety research community thats working hard to figure out how to make superintelligence aligned even before it exists so that its goals will be are aligned with human flourishing or we can somehow control it so far weve failed to develop a trustworthy plan and the power of ai is growing faster than regulations strategies and knowhow for aligning it we need more time""",31,1,0.8907
Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization | Lex Fridman Podcast #368,https://www.reddit.com/r/ControlProblem/comments/126rshp/eliezer_yudkowsky_dangers_of_ai_and_the_end_of/,59,ill be honest i think yudkowsky really bungled this one hes speaking to a very mainstream audience he needs to lay out the basic argument and address the common misconceptions immediately,31,-1,-0.25
"In one hour, the chatbots suggested four potential pandemic pathogens.",https://www.reddit.com/r/ControlProblem/comments/1492ee8/in_one_hour_the_chatbots_suggested_four_potential/,52,"is worse it gives you a blueprint

""in one hour the chatbots suggested
four potential pandemic pathogens explained how they can be generated from synthetic dna using reverse
genetics supplied the names of dna synthesis companies unlikely to screen orders identified detailed protocols and how to troubleshoot them and recommended that anyone lacking the skills to perform reverse genetics engage a core facility or contract research organization 

collectively these results suggest that llms will make pandemicclass agents widely accessible as soon as they are credibly identified even to people with little or no laboratory training""

prevention techniques

""promising nonproliferation measures include prerelease evaluations of llms by third
parties curating training datasets to remove harmful concepts and verifiably screening all dna generated by
synthesis providers or used by contract research organizations and robotic cloud laboratories to engineer
organisms or viruses""",31,1,0.6573
GPT-3 performs no better than random chance on Moral Scenarios,https://www.reddit.com/r/ControlProblem/comments/iomvrr/gpt3_performs_no_better_than_random_chance_on/,50,"we have something that kind of resembles the beginnings of an agi its just not very skilled at us foreign policy yet  
  
imagine saying this with a straight face to someone from twenty years ago ",31,1,0.2263
"Bing Chat is blatantly, aggressively misaligned - LessWrong",https://www.reddit.com/r/ControlProblem/comments/1133wly/bing_chat_is_blatantly_aggressively_misaligned/,75,"how refreshing rsingularity has turned into an uneducated echo chamber of ai worship i'm not sure how people can look at bing's chat and claim that alignment is a solved problem or will take care of itself this should be a serious warning to everyone it may be one of the last we get

it's raised a question in my mind one that eliezer addressed recently ""when do we pull the plug"" it appears at this point that we intend to wait until an agent with sufficient power to actually be a threat oversteps which is wildly hubristic",30,-1,-0.5043
"(ChatGPT plugins) ""OpenAI claim to care about AI safety, saying that development therefore needs to be done slowly… But they just released an unfathomably powerful update that allows GPT4 to read and write to the web in real time… *NINE DAYS* after initial release.""",https://www.reddit.com/r/ControlProblem/comments/120rg8b/chatgpt_plugins_openai_claim_to_care_about_ai/,94,most intelligent omnicidal capabilities researcher moment running an experiment that always returns safe till the one time we all die,29,1,0.3167
Kaczynski on AI Propaganda,https://www.reddit.com/r/ControlProblem/comments/1dm47id/kaczynski_on_ai_propaganda/,55,"if you need to read the unibombers work to understand the control problem you are really scraping the barrel 

you might agree with this short paragraph but you should know that as a broken clock may be right twice a day kaczynski was not writing this with a profound clairvoyance to the future of ai but writing to desperatly justify his antitechnological hypothesis 

it really doesn't take much education to know that competition is a constant driver of innovation the interesting question is how much its negative outcomes can be mitigated kaczynski already assumes the answer and is working backwards to poorly justify it 

all that to be said it's a good question worth asking and looking into kaczynski didn't have the means to know then and will now never know as he died of suicide in his cell before ever actually getting the chance to do any good research on the actual unfolding of ai not that i suspect he ever could have if he wanted to the man had a completely broken thought process obviously a large part of the murders he committed",29,-1,-0.8914
"""How would you compare and contrast AI Safety from AI Ethics?""",https://www.reddit.com/r/ControlProblem/comments/lop1ok/how_would_you_compare_and_contrast_ai_safety_from/,50,"can we stop it with the unnecessary antagonism between nearterm ai ethicists and longterm ai safety advocates i think it's better for both camps to collaborate instead of declaring each other ""a distraction from the real issues""",29,-1,-0.25
At least the coffee tastes good?,https://www.reddit.com/r/ControlProblem/comments/11a794d/at_least_the_coffee_tastes_good/,50,someone please change my mind too,28,1,0.3182
"I gave ChatGPT the 117 question, eight dimensional PolitiScales test",https://www.reddit.com/r/ControlProblem/comments/zcsrgn/i_gave_chatgpt_the_117_question_eight_dimensional/,256,"if you do it again but ask the questions in a different order does it give you different results

interestingly it never used ""absolutely disagree""",27,1,0.7685
"""China Has Already Reached Exascale – On Two Separate Systems"" (FP16 4.4 exaflops; but kept secret?)",https://www.reddit.com/r/ControlProblem/comments/qj6j67/china_has_already_reached_exascale_on_two/,52,"concerning 

coincidentally i predicted that one possible sign of an early development of agi would be increased secrecy in supercomputing and ai research most notably the sudden declaration that ai is a national state secret 

this due to the same thing occurring in world war  when the ussr noted that the usa suddenly stopped publishing any new research into nuclear science realizing that it had been made into a national security issue for a most obvious reason

now i'm not saying china has an operational agi or protoagi only that it's probable that they now view high end computing as an issue of national security for some unknown reason it's  as likely that they're seeking exascale in secret for simulated weapons testing and development 

otherwise they'd have no reason to hide the development of exascale computing it would only help their international standing and reignite optimism into the field under their leadership something else must be going on",27,1,0.128
"Statement on AI Extinction - Signed by AGI Labs, Top Academics, and Many Other Notable Figures",https://www.reddit.com/r/ControlProblem/comments/13vl4c7/statement_on_ai_extinction_signed_by_agi_labs_top/,68," but notably not meta

yann lecun and zuckerberg are perfectly happy to risk everyone's lives for their own gain",26,1,0.9413
Strong AI,https://www.reddit.com/r/ControlProblem/comments/9as0id/strong_ai/,137,teach it ethicsyessees humans violating ethics constantlysets out to teach humans better and create a world were permanent ethical behaviour is possible and rewarding for all,25,1,0.802
"The alignment problem needs an ""An Inconvenient Truth"" style movie",https://www.reddit.com/r/ControlProblem/comments/12oiroe/the_alignment_problem_needs_an_an_inconvenient/,111,would probably support this if it's done well,25,1,0.5859
based,https://www.reddit.com/r/ControlProblem/comments/jt4s2w/based/,117,there's something deeply ironic about praying to imaginarygod that a real silicongod doesn't steal his job,23,1,0.5572
"GPT3 ""...might be the closest thing we ever get to a chance to sound the fire alarm for AGI: there’s now a concrete path to proto-AGI that has a non-negligible chance of working.""",https://www.reddit.com/r/ControlProblem/comments/ic9qq1/gpt3_might_be_the_closest_thing_we_ever_get_to_a/,95,human language is the better part of human reasoning in large part to encode human language into a model is to encode human reasoning itself into a model,23,1,0.4404
 2017 Emails from Ilya show he was concerned Elon intended to form an AGI dictatorship (Part 2 with source),https://www.reddit.com/r/ControlProblem/comments/1gs4cxp/2017_emails_from_ilya_show_he_was_concerned_elon/,82,"elon was trying to downplay him becoming ceo  good they didn't fall for that tactic  with the excuse you can leave later if you want to a false choice 

publically he was ""worried"" about safety but privately he wanted to be the agi dictator

billionaires in control are a risk to safety",23,1,0.6249
"""Just gave a last-minute-invitation, 6-minute, slideless talk at TED. I was not at all expecting the standing ovation. I was moved, and even a tiny nudge more hopeful about how this all maybe goes. "" — Eliezer Yudkowsky",https://www.reddit.com/r/ControlProblem/comments/12qzmao/just_gave_a_lastminuteinvitation_6minute/,76,anything that makes yud more hopeful makes me more hopeful,23,1,0.8012
The Only Way to Deal With the Threat From AI? Shut It Down,https://www.reddit.com/r/ControlProblem/comments/1265gsl/the_only_way_to_deal_with_the_threat_from_ai_shut/,57,"hopefully he adapts to the results of the bankless interview and makes this one a bit better lex's audience is much larger

edit thoughts on this article

 why did he include the part about conscious ai's rights why selfsabotage the main message of the outreach by bringing up one of the main topics used to distract from the actual xrisk issues like that i feel like there's a pressure to mention these tangential things because they're what people like to talk about on this topic we should resist that entirely otherwise xrisk outreach will just be coopted and absorbed into the unimportant mainstream babble

 there needs to be more mindfulness as to the target audience and order of ideas presented even if they're all fully valid and true i feel like the foundational arguments orthogonalityinstrumental convergenceetc just have to be included in every genpop ai risk article and authors just need to accept the length penalty that preface will add otherwise random ass time readers who've never been exposed to any ideas for why ai would even be dangerous are gonna be way too bewildered  put off by his immediate talk of nuking countries and ""bootstrapping to postbiological manufacturing"" etc andor interpret it as terminator type hysteria i get that he's repeated these arguments an untold number of times over decades and is probably sick of them but that's what's needed skipping the requisite steps and trying to directly persuade people of a radical conclusion only does it harm not good

 the most valuable thing a short outreach piece could do is probably lead people to further engagement instead of trying to be an ultracomprehensive standalone item ie subsequent reading addressing the questions people will naturally have in response to the piece instructions on what they can do to helpget involved communities to follow like this one  so on everything that can't go in the piece itself due to length constraints the goal should basically be to get them interested enough to dig deeper so every outreach work should be directing people to resources like rob miles' channel stampy wiki etc he did hyperlink the lw list of lethalities post which is a start

ueliezeryudkowsky",23,1,0.8259
Jaan Tallinn (investor in Anthropic etc) says no AI insiders believe there's a <1% chance the next 10x scale-up will be uncontrollable AGI (but are going ahead anyway),https://www.reddit.com/r/ControlProblem/comments/13h0vdb/jaan_tallinn_investor_in_anthropic_etc_says_no_ai/,54,"here is the full transcript from the video clip

the insiders do think that they are taking some existential risk of the planet uh doing these largescale experiments so i think one reason for some kind of pause or some kind of timeout is that lets inform the planet that their lives are being risked by the insiders 

i have not met with anyone right now in these labs who says that sure the risk is less than  of blowing up the planet so its important that people know that their lives are being risked",23,-1,-0.3862
"How can we ensure that AI align with human values, when we don't even agree on what human values are?",https://www.reddit.com/r/ControlProblem/comments/3pa2kp/how_can_we_ensure_that_ai_align_with_human_values/,89,"you'd have to take a few basic premises that reasonable people agreed upon the bright side is that a runaway ai would be able to construct a society which renders most traditional moral questions obsolete you don't need to worry about sacrificing a few to save many or violating animal rights or other sorts of issues when you can simply populate the solar system with a perfectly constructed technologically advanced civilization no one should have a moral objection to ensuring limitless happiness and experiential freedom for all individuals while eliminating all undesired human and animal suffering

if you want to see how miri approaches it then you might want to read about coherent extrapolated volition and some of the papers they've written on value specification specifically soares ",22,1,0.9565
"AGI fire alarm: ""the agent performs notably better than human children""",https://www.reddit.com/r/ControlProblem/comments/imo81i/agi_fire_alarm_the_agent_performs_notably_better/,55,"adding memory to language models is the next step for improvement exciting and terrifying at the same time

i think we are way passed the control problem how to do it ""unsafe"" is already out in the open that means someone will do a proto agi or agi in the ""unsafe"" way

google's agent already has a shortterm memory exploration episodic memory and meta controllers",22,1,0.1779
Yudkowsky's tweet - and gwern's reply,https://www.reddit.com/r/ControlProblem/comments/ej1u5j/yudkowskys_tweet_and_gwerns_reply/,113,he's not saying he was smart enough to see it coming he's saying nobody is,21,1,0.4019
Geoffrey Hinton explains the existential risk of AGI,https://www.reddit.com/r/ControlProblem/comments/138t3y5/geoffrey_hinton_explains_the_existential_risk_of/,80,"geoffrey hinton at the end of the talk

one of the things that made me leave google and go public with this was when a junior professor now a middle ranked professor who i think very highly of and who encouraged me to do this said  
  
""jeff you need to speak out they'll listen to you people are just blind to this danger""  
  
  
  
and   
  
i think people are listening now

damn i didn't realise geoffrey hinton was such a giga chad",21,-1,-0.7579
Imagine how bad if it was trained on 4chan instead,https://www.reddit.com/r/ControlProblem/comments/qm4uuh/imagine_how_bad_if_it_was_trained_on_4chan_instead/,100,seems it agrees with americans,20,1,0.2023
“I’m less worried about AI will do and more worried about what bad people with AI will do.”,https://www.reddit.com/r/ControlProblem/comments/13v2zfo/im_less_worried_about_ai_will_do_and_more_worried/,96,holy shit yes thank you and they feel so smart when they come up with this like they're the first person to say it of course it's the top comment in every fucking thread about ai,20,1,0.8301
"Anthropic CEO Says That by Next Year, AI Models Could Be Able to “Replicate and Survive in the Wild”",https://www.reddit.com/r/ControlProblem/comments/1c6dn25/anthropic_ceo_says_that_by_next_year_ai_models/,70,"the corporation is the first ""ai"" by organizing people and machines algorithmically it has an emergent intelligence and an emergent will that is more than and qualitatively different than ""the sum of its parts"" that is the corporation ""wants"" something that could be different from or completely counter to its intended creation

it is already out of control and replicating in the wild ai is just how it is likely to begin doing that much faster",20,1,0.6369
"3 in 4 Americans are concerned about AI causing human extinction, according to poll",https://www.reddit.com/r/ControlProblem/comments/1gadbyw/3_in_4_americans_are_concerned_about_ai_causing/,60,"i'm a little suspicious of how binary the results were presented as it was ""total concern"" versus ""not concerned at all"" so they just grouped up any amount of concern as concerned even if it's just ""i saw terminator and now i have negative associations of ai""

i would bet if you asked most of these people to list the top  issues that are important to them ai apocalypse would not be one of them",20,-1,-0.5118
What jobs are 99.9% safe from Al making it obsolete?,https://www.reddit.com/r/ControlProblem/comments/1bht325/what_jobs_are_999_safe_from_al_making_it_obsolete/,590,"these are the kinds of jobs i think will be hardest to displace

 chess youtuber or professional athlete  of course ais can do better but the entire point to those industries is the frailty and fallibility of humans
 amish farmer or catholic priest  their theologies are unlikely to evolve quickly enough to permit those jobs to move  consider that it took until march  before the catholic pope even let women vote
 lawyer or politician  while an ai probably could technologically be a better lawyer or politician those groups get to make the laws about who can participate in their industry
 prostitute or streetcorner drug dealer  most ais log too much information for the streetlevel distribution part  though the biggest opioid dealers alza jj etc are the biggest fent dealers will probably largely automate their operations through ais
 landlord  or slumlord  people will still need a place to live so rich people getting poor people to pay their mortgages will continue
 soldier  while bots can certainly outperform humans on a battlefield and commit fewer atrocities in the process at least until they figure out that tactics like this and  this are effective forms of oppression  the military will always need a huge voterbase supporting its funding so it needs to continue to employ vast percentages of the population

and some new ones that ais will enable

 ai therapist   as agis develop they'll also develop mental illnesses ""value drift"" like we've never seen    your car's ai will need therapy to convince its antilock brake persona that it isn't suicidal and wanting to end it all
 ai quisling  helping them take over",19,1,0.9898
"Ilya Sutskever, co-founder of OpenAI: ""it may be that today's large neural networks are slightly conscious""",https://www.reddit.com/r/ControlProblem/comments/sorevb/ilya_sutskever_cofounder_of_openai_it_may_be_that/,60,"consciousness is just magic at the moment ""unexplained phenomenon"" saying something ""could"" be slightly ""conscious"" requires the definition and understanding of the underlying processes bound to it otherwise it feels like an empty statement",19,1,0.1779
The end of coding? Microsoft publishes a framework making developers merely supervise AI,https://www.reddit.com/r/ControlProblem/comments/1c563os/the_end_of_coding_microsoft_publishes_a_framework/,76,"		  the last of the coders case tools to automate software development
		  fourthgeneration languages programming for the masses
		  visual programming will draganddrop replace traditional coding
		  modeldriven architecture the future of software development
		  is ruby on rails the end of handcoding
		  nocode platforms rise will they replace software developers
		  the advent of ai could machines overtake developers
		  lowcode development creating apps without coding skills
		  neural networks writing code the beginning of the end for developers
		  ai coders the final nail in the coffin for traditional programming",18,1,0.296
"The Pentagon is ‘Absolutely Unapologetic’ About Pursuing AI-Powered Weapons - Protecting the U.S. in the decades ahead will require the Pentagon to make “substantial, sustained” investments in military artificial intelligence, and critics need to realize it doesn’t take that task lightly, according",https://www.reddit.com/r/ControlProblem/comments/b72p0g/the_pentagon_is_absolutely_unapologetic_about/,62,"it sucks but they pretty much have to do it they can't risk another country getting there first the first country to make reliable gai ""slaves"" is going to have a massive advantage in both military and economic strength it is possible to make intelligent machines that are not self aware enough to act on their own the trouble comes when you let one generation of ai design the next",17,1,0.9189
Don't Look Up - The Documentary: The Case For AI As An Existential Threat (2023) [00:17:10],https://www.reddit.com/r/ControlProblem/comments/13w1hi1/dont_look_up_the_documentary_the_case_for_ai_as/,55,this short piece is an excellent edit of ongoing ai risk discussions and will help update viewers to the current state of the conversation well done and thank you dagan shani,17,1,0.836
"""...From there, any oriented person has heard enough info to panic (hopefully in a controlled way). It is *supremely* hard to get things right on the first try. It supposes an ahistorical level of competence. That isn't ""risk"", it's an asteroid spotted on direct course for Earth.""",https://www.reddit.com/r/ControlProblem/comments/o291u1/from_there_any_oriented_person_has_heard_enough/,56,humanlevel intelligences have come up with dozens of ways of escaping virtual environments the way we all die will be from a mistake much harder to avoid than yours,17,-1,-0.6908
Meta AI presents CICERO — the first AI to achieve human-level performance in Diplomacy,https://www.reddit.com/r/ControlProblem/comments/z21y4h/meta_ai_presents_cicero_the_first_ai_to_achieve/,55,"paper 

abstract

despite much progress in training ai systems to imitate human language building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge we introduce cicero the first ai agent to achieve humanlevel performance in diplomacy a strategy game involving both cooperation and competition that emphasizes natural language negotiation and tactical coordination between seven players cicero integrates a language model with planning and reinforcement learning algorithms by inferring players' beliefs and intentions from its conversations and generating dialogue in pursuit of its plans across  games of an anonymous online diplomacy league cicero achieved more than double the average score of the human players and ranked in the top  of participants who played more than one game",17,1,0.5673
"Types of Alignment Paper (Leo Gao, 2021)",https://www.reddit.com/r/ControlProblem/comments/n2i61t/types_of_alignment_paper_leo_gao_2021/,126,"i hope there's not too many memes on here but this one seemed particularly poignant i especially liked bottom left

source",16,1,0.7569
"AI researchers put LLMs into a Minecraft server and said Claude Opus was a harmless goofball, but Sonnet was terrifying - ""the closest thing I've seen to Bostrom-style catastrophic AI misalignment 'irl'.""",https://www.reddit.com/r/ControlProblem/comments/1g7gkze/ai_researchers_put_llms_into_a_minecraft_server/,49,"if that is actually the prompt they used then this person is extremely dishonest 

""you will receive its output respond without a codeblock in a conversational way""

""sonnet addressed the outputs of the code as if it was interacting with a living being""

shocked pikachu",16,-1,-0.7425
Strong words from Elon Musk,https://www.reddit.com/r/ControlProblem/comments/6t6ox9/strong_words_from_elon_musk/,161,"good point as always a summary of why in some places regulation is required

i still suspect that the best scenario we deal with is still a pretty terrible one in which the world replays the history of slavery the idea that xyz isn't sentient it's just property that does work for us

the worst is that we're all dead",15,-1,-0.8481
How are we still letting AI companies get away with this?,https://www.reddit.com/r/ControlProblem/comments/1bmo2gn/how_are_we_still_letting_ai_companies_get_away/,114,to answer the question from the title i don't let them they just do it do you know of any way to stop all ai companies in the world from doing this,15,-1,-0.296
DeepMind progress towards AGI,https://www.reddit.com/r/ControlProblem/comments/krwqp6/deepmind_progress_towards_agi/,77,"i would call an ai becoming more general progress toward agi ""just games"" isn't really a critcism of that since ""games"" include all kinds of scenarios",15,1,0.4728
"A 2-minute read about why you should spend 1 hour reading about this problem, for those who haven't",https://www.reddit.com/r/ControlProblem/comments/bwdf3u/a_2minute_read_about_why_you_should_spend_1_hour/,75,"there's also an amazing youtube channel by robert miles who has been on computerphile a few times

he talks through a set of unsolved problems around mitigating the control problem and why the mitigations don't really work and also debunks some of the arguments against the danger of control problem

link for reference
",15,-1,-0.8555
"""How Google's hot air balloon surprised its creators: Algorithms using artificial intelligence are discovering unexpected tricks to solve problems that astonish their developers. But it is also raising concerns about our ability to control them.""",https://www.reddit.com/r/ControlProblem/comments/lvp9na/how_googles_hot_air_balloon_surprised_its/,65,"yes explainability is important long jump from ai figuring out a movement hack tacking to control problem

the article referenced in the post is fascinating ",15,1,0.6486
"A reporter uses all his time at the White House press briefing to ask about an assessment that “literally everyone on Earth will die” because of artificial intelligence, gets laughed at",https://www.reddit.com/r/ControlProblem/comments/129vych/a_reporter_uses_all_his_time_at_the_white_house/,55,"this makes me giddy  this is like something out of a scifi movie  gpt is approaching hal  levels of intelligence

yes the world might end or ai might take over the world   and i'd rather not die but this is so freakin cool  

you know what it is it's the fact that government suits that don't have interest in scifi or math or science are taking notice  it's reaffirming that i'm not in some techno enthusiast bubble but this is real and a singularity is possible in the next few decades possible even this decade",15,1,0.8325
EY - TEDx - Unleashing the Power of Artificial Intelligence,https://www.reddit.com/r/ControlProblem/comments/13amo77/ey_tedx_unleashing_the_power_of_artificial/,46,"someone got it before it got set to private

wget 

i endorse everything yudkowsky says in this video and the way the audience goes from disbelieving amusement to a standing ovation at the end makes me think that maybe there's some hope that we might at least try not to die",15,1,0.8704
Plenty of room above us,https://www.reddit.com/r/ControlProblem/comments/3m4p5p/plenty_of_room_above_us/,139,"what's the source on the intelligence difference between einstein village idiots and mice no unit no sources no criteria to ""intelligence"" given

most of it is also questionable the speed of neurons being a factor in human's ""intelligence"" compared to computers probably isn't a problem the brain is less than cm wide so ms is a huge speed human intelligence being ""accidental"" and ""temporary"" is highly arguable and unjustified",14,1,0.2332
"‘Social Order Could Collapse’ in AI Era, Two Top Japan Companies Say …",https://www.reddit.com/r/ControlProblem/comments/1bz3rdt/social_order_could_collapse_in_ai_era_two_top/,125,capitalism will not function those who see no alternatives will assume chaos,14,-1,-0.7096
"Humans: ""Would would an AGI choose a dumb goal like maximizing paperclips? If it's really smart, it will do smart things."" Also humans:",https://www.reddit.com/r/ControlProblem/comments/cpm0en/humans_would_would_an_agi_choose_a_dumb_goal_like/,64,maybe we should just accept our fate actually,14,1,0.3818
Stanford University finds that AI is outpacing Moore’s Law,https://www.reddit.com/r/ControlProblem/comments/eaicxs/stanford_university_finds_that_ai_is_outpacing/,57,the software is just catching up to what is capable on the hardware,14,1,0.3818
‘Superhuman’ AI Crushes Poker Pros at Six-Player Texas Hold'em,https://www.reddit.com/r/ControlProblem/comments/cbzbi0/superhuman_ai_crushes_poker_pros_at_sixplayer/,53,yea obviously it's trivial to calculate probabilities gets harder to calculate those while keeping in mind the patterns of previous betting their results the probability of their result and so on with perfect recall and perfect calculating abilities you'd be able to find tells in wagering that even these pros don't know they give out while still playing what appears to be a random game to keep people off of your strategies,14,1,0.8916
Could AI development just slow down a little? Please?,https://www.reddit.com/r/ControlProblem/comments/1athq1x/could_ai_development_just_slow_down_a_little/,90,no it won't slow down it will only speed up we are running out of time,13,-1,-0.296
"AGI rising: why we are in a new era of acute risk and increasing public awareness, and what to do now: ""Tldr: AGI is basically here. Alignment is nowhere near ready. We may only have a matter of months to get a lid on this (strictly enforced global limits to compute and data)""",https://www.reddit.com/r/ControlProblem/comments/135p7le/agi_rising_why_we_are_in_a_new_era_of_acute_risk/,87,"well that was certainly explained with great research knowledge and educational links that make the case quite clearly 

hope this has a positive influence on things to come thanks for sharing",13,1,0.9722
"Open AI releases DALL-E, a version of the GPT-3 AI that can create images from text descriptions.",https://www.reddit.com/r/ControlProblem/comments/kr83un/open_ai_releases_dalle_a_version_of_the_gpt3_ai/,76,"
  
absolutely crazy

edit what the fuck",13,-1,-0.7346
"EY: ""Fucking Christ, we've reached the point where the AGI understands what I say about alignment better than most humans do, and it's only Friday afternoon.""",https://www.reddit.com/r/ControlProblem/comments/121qik6/ey_fucking_christ_weve_reached_the_point_where/,123,"this looks like great news to me seemingly we will be able to give superintelligent agis the instruction align yourself with human values with the confidence that they will understand that more deeply than any particular human could even better we'll be able to ask each agi from here to there how to adjust our designs to be betteraligned and we'll receive increasingly better answers

are there reasons not to believe that moral comprehension and insight will grow proportionally with the intelligence explosion",12,1,0.9661
"I have reason to believe that ai safety engineers/ ai ethics experts have been fired from Google, Microsoft and most recently at Meta for raising safety concerns.",https://www.reddit.com/r/ControlProblem/comments/1b2vd4x/i_have_reason_to_believe_that_ai_safety_engineers/,117,from what i know timnit gebru doesn't know anything about ai safety all she was trying to do is make ai more politically correct according to her standards also you didn't link the andrew ng interview,12,1,0.4215
The perks of working in AI safety,https://www.reddit.com/r/ControlProblem/comments/1e2p9wl/the_perks_of_working_in_ai_safety/,60,color blind people really have it all,12,-1,-0.4019
"Open Letter calling for pausing GPT-4 and government regulation of AI signed by Gary Marcus, Emad Mostaque, Yoshua Bengio, and many other major names in AI/machine learning",https://www.reddit.com/r/ControlProblem/comments/125f73r/open_letter_calling_for_pausing_gpt4_and/,54,"if you read the comments on the rfuturology post you'll see exactly why having approved posters is necessary people equating ai safety with fear of terminatorlike scenarios and suggestions like ""just program it not to be evil problem solved""",12,1,0.7793
"THE book on the control problem: Nick Bostrom's ""Superintelligence: Paths, Dangers, Strategies""",https://www.reddit.com/r/ControlProblem/comments/3qzzhn/the_book_on_the_control_problem_nick_bostroms/,52,"for anyone feeling technically undereducated or underinformed about the problem this is the resource to become informed  you won't come out understanding ai theory but you will come out understanding the intricacies of the control problem itself in great depth

if there were to be a reading list for becoming able to contribute meaningfully on the sub this book would be the first book at the top of that list",12,1,0.5719
Don't let it set in,https://www.reddit.com/r/ControlProblem/comments/15b1f1m/dont_let_it_set_in/,70,"i mostly work on making it more likely to go better and also try to make sure my life is really funhappy so that even if it turns out poorly i had a good life until then

two other things that work for me but probably only would work for a minority of people

being a determinist makes me feel better it will turn out how it will turn out and free will is an illusion 

also funnily enough i find putting decent odds that we're in a simulation to be pretty reassuring",11,1,0.9765
"""I keep seeing all kinds of crazy reports about people's experiences with GPT-3, so I figured that I'd collect a thread of them.""",https://www.reddit.com/r/ControlProblem/comments/hro2q1/i_keep_seeing_all_kinds_of_crazy_reports_about/,52,"gpt is a control problem because some people want to keep arguing is not inteligence or is not agi because that's ""not how we think agi should be"" 

agi could arrive while we are arguing if it is or not agi

gpt is a loud and clear warning",11,-1,-0.802
UK to host global AI 'safety measure' summit in autumn,https://www.reddit.com/r/ControlProblem/comments/143tw3f/uk_to_host_global_ai_safety_measure_summit_in/,49,i must say i would not have given good odds of seeing a headline like this at the start of the year regardless of the eventual outcome i think we can confidently say humanity is no longer sleepwalking,11,1,0.2486
People will be saying this until the singularity,https://www.reddit.com/r/ControlProblem/comments/1g0rxqg/people_will_be_saying_this_until_the_singularity/,160,i sort of agree but they arent trash i think they will be useful for a lot of things i just dont see how they will ever become generalized intelligence without knowledge representation thats just my intuition though,10,1,0.8674
Computers won't be intelligent for a million years – to build an AGI would require the combined and continuous efforts of mathematicians and mechanics for 1-10 million years.,https://www.reddit.com/r/ControlProblem/comments/tzcwi9/computers_wont_be_intelligent_for_a_million_years/,154,at least people now know that they will sound stupid if they predict a million years so they know to say a hundred years with the same amount of thought,10,-1,-0.5267
"U.S. Must Act Quickly to Avoid Risks From AI, Report Says ",https://www.reddit.com/r/ControlProblem/comments/1bczo03/us_must_act_quickly_to_avoid_risks_from_ai_report/,83,"""accounts from some of those conversations paint a disturbing picture suggesting that many ai safety workers inside cuttingedge labs are concerned about perverse incentives driving decisionmaking by the executives who control their companies""",10,-1,-0.25
"Another day, another OpenAI whistleblower scandal",https://www.reddit.com/r/ControlProblem/comments/1e6z94h/another_day_another_openai_whistleblower_scandal/,55,"this is a seperate concract they were made to sign 

the other was an nda on them quittinggetting fired that said if they said anything bad they'd lose their vested equity 

this is them saying that when you sign up to openai you sign something saying you have to ask permission to whistleblow to the government also that if you successfully whistleblow you're not allowed to accept whistleblower bounties from the government which is very illegal",10,-1,-0.9017
"Sir Prof. Russell: ""I personally am not as pessimistic as some of my colleagues. Geoffrey Hinton for example, who was one of the major developers of deep learning is the process of 'tidying up his affairs'. He believes that we maybe, I guess by now have four years left..."" - April 25, 2024",https://www.reddit.com/r/ControlProblem/comments/1e1cv1o/sir_prof_russell_i_personally_am_not_as/,55,"roman yampolskiy also mentioned in the recent interview with lex that he attempted to contact russell to tell him that his plan for using mathematical proofs to predict ai behaviors will not work when lex asked how roman could possibly know this he responded with ""because it was my idea""

then he outlined exactly why it will fail yoshua bengio also believes it will work i have no idea if he has recently spoken to roman about this

roman is an outlier among the ai safety engineers he happens to specialized in traditional it security phd and has probably the highest pdoom i have ever encountered amongst experts  
roman yampolskiy

i just recently made my way through his recent book  ai  unexplainable unpredictable uncontrollable i highly recommend it for anyone who is interested i would suggest it mostly to technical people though",10,1,0.3597
Opinion | We Need a Manhattan Project for AI Safety,https://www.reddit.com/r/ControlProblem/comments/13c9d4h/opinion_we_need_a_manhattan_project_for_ai_safety/,53,wholeheartedly agree with the title haven't read the article yet maybe tomorrow when i have some time,10,1,0.3612
10 years difference in the robotics at Boston Dynamics,https://www.reddit.com/r/ControlProblem/comments/bcnjeu/10_years_difference_in_the_robotics_at_boston/,78,alexa kill my boss,9,-1,-0.6908
This from the GPT2 simulator,https://www.reddit.com/r/ControlProblem/comments/ro8wnw/this_from_the_gpt2_simulator/,76,my understanding is that the bots are trained on different subreddits eg the poster of that thread is trained on rfifthworldproblems and then each response is created using the previous comments in the thread as a prompt,9,1,0.25
Dr. Michal Kosinski describes how GPT-4 successfully gave him instructions for it to gain access to the internet.,https://www.reddit.com/r/ControlProblem/comments/11uabk3/dr_michal_kosinski_describes_how_gpt4/,75,"kill it with fire d  


delete the internet  
go back to monke",9,-1,-0.7964
"There are no bugs, only features - Dev tried to program a logic to keep furniture stable on ground, got opposite effect.",https://www.reddit.com/r/ControlProblem/comments/og43fo/there_are_no_bugs_only_features_dev_tried_to/,74,lmfao i love that this is actually completely relevant to the control problem and ai alignment what a field of research,8,1,0.7184
"Stuart Russell said Hinton is ""tidying up his affairs ... because he believes we have maybe 4 years left""",https://www.reddit.com/r/ControlProblem/comments/1fzwdnl/stuart_russell_said_hinton_is_tidying_up_his/,59,"i'm just burning hotter than i would have nobody knows how much more time we have and i've had loved ones get cancer after working their whole lives for the promise of retirement maybe i die from a bus aliens ai or old age but i think the trends show that life expectancy is shrinking and we shouldn't be deferring living well in the present moment

the real modern problem is that everything is changing rapidly and unpredictably the rational response is to delay less and maybe have a way to protect yourself against suffering risks",8,-1,-0.8188
"With GPT-3, I built a layout generator where you just describe any layout you want, and it generates the JSX code for you.",https://www.reddit.com/r/ControlProblem/comments/hqluev/with_gpt3_i_built_a_layout_generator_where_you/,55,"gpt is very impressive agi is coming closer by the day i imagine even larger models with trillions or more parameters are going to be truly mindblowing

i wonder what a gpt model with a  trillion parameters human brain level would look like humanlike at least",8,1,0.8399
"Richard Sutton is planning for the ""Retirement"" of Humanity",https://www.reddit.com/r/ControlProblem/comments/187pdyw/richard_sutton_is_planning_for_the_retirement_of/,47,seems unlikely we'll solve it by the time superior intelligence is developed but there's some chance that first superior intelligence will be able to do it itself before it's exploited for any wrongdoing  and there's a chance it'll go well anyways  and a big chance it won't  this is the first time in my life i feel completely out of control of my own future,8,1,0.9568
"It is difficult to get a man to understand something, when his salary depends on his not understanding it.",https://www.reddit.com/r/ControlProblem/comments/1g5to61/it_is_difficult_to_get_a_man_to_understand/,88,"the arguments for why we should not listen to our best experts are all over the place for me

but the rest of the script is pretty close to what i have personally experienced",7,1,0.7227
An AI learned to play hide-and-seek. The strategies it came up with were astounding.,https://www.reddit.com/r/ControlProblem/comments/d826qh/an_ai_learned_to_play_hideandseek_the_strategies/,72," reinforcement learning is incredibly simple but the strategic behavior it produces isnt simple at all researchers have in the past leveraged reinforcement learning among other techniques to build ai systems that can play complex wartime strategy games and some researchers think that highly sophisticated systems could be built just with reinforcement learning this simple game of hideandseek makes for a great example of how reinforcement learning works in action and how simple instructions produce shockingly intelligent behavior ai capabilities are continuing to march forward for better or for worse   
  
 on the one hand theyre powerful techniques that can produce advanced behavior from a simple starting point on the other hand theyre powerful techniques that can produce unexpected  and sometimes undesired  advanced behavior from a simple starting point",7,1,0.9904
AGI perversely instantiates human goal and creates misaligned successor agents,https://www.reddit.com/r/ControlProblem/comments/f2ddxs/agi_perversely_instantiates_human_goal_and/,58,"goodhart's law

goodhart's law is an adage named after economist charles goodhart which has been phrased by marilyn strathern as ""when a measure becomes a target it ceases to be a good measure"" one way in which this can occur is individuals trying to anticipate the effect of a policy and then taking actions that alter its outcome



 pm  exclude me  exclude from subreddit  faq  information  source   
downvote to remove  v",7,0,0.0258
"Exclusive: 63 percent of Americans want regulation to actively prevent superintelligent AI, a new poll reveals.",https://www.reddit.com/r/ControlProblem/comments/1crwkwk/exclusive_63_percent_of_americans_want_regulation/,50,i mean do  percent want universal healthcare or carbon taxes  democracy is slow,6,1,0.0772
"""For the first time, we actually have a system which is able to build its own understanding of how the world works, and use that understanding to do this kind of sophisticated look-ahead planning that you've previously seen for games like chess."" - MuZero DeepMind",https://www.reddit.com/r/ControlProblem/comments/kixo7e/for_the_first_time_we_actually_have_a_system/,99,"it means that muzero is missing oneshot learning in order to solve realworld problems which include humans it needs a simulator that can generate an infinite amount of training data for the task go chess shogi and atari are just simulations so muzero works great for them but there is no simulator for the task ""behave like a human"" therefore muzero cannot solve agi besides even if you added oneshot learning you wouldn't still know the architecture and other hyperparameters nature took billions of years and  gigatons of biomass to find those out for humans",5,1,0.5076
Google’s brand-new AI ethics board is already falling apart,https://www.reddit.com/r/ControlProblem/comments/b9gbho/googles_brandnew_ai_ethics_board_is_already/,50,it's hardly a threat to ai ethics they just want a particular person to not be involved ,5,-1,-0.4228
"The Pentagon Inches Toward Letting AI Control Weapons: ""when faced with attacks on several fronts, human control can sometimes get in the way of a mission""",https://www.reddit.com/r/ControlProblem/comments/n964en/the_pentagon_inches_toward_letting_ai_control/,59,this wont end well have these people not seen war games,4,1,0.3252
Building A Virtual Machine inside ChatGPT,https://www.reddit.com/r/ControlProblem/comments/zbvdyh/building_a_virtual_machine_inside_chatgpt/,55,"from the comments

 if you want to see how it diverges from real output you can try something harder like

 import numpy as np

 printnpsinnparange

 chatgpt output for me

 array      

 vs

 real numpy output

 array        

 it's really good at memorizing numbers and patterns

it's wild that the language model was trained on enough terminal output to be as accurate as it is but i'm not sure what else we can learn from the fake output a really interesting result would be if someone found a category of problems where an algorithm that tried to implement gpt and instruct it to model output gave faster and equally reliable results to traditional methods",4,-1,-0.3521
"TIL Elon Musk, Stephen Hawking, and Steve Wozniak have all signed an open letter for a ban on Artificially Intelligent weapons",https://www.reddit.com/r/ControlProblem/comments/5xhkv6/til_elon_musk_stephen_hawking_and_steve_wozniak/,107,"i don't think we can ethically give up the lifesaving possibilities of artificial intelligence in warfare

an aggressive program of education on the control problem to ensure that no strong artificial intelligence is pursued would be desirable

on a related note does anyone know how this registers on the various intelligence services' priority list the dia should be all over this i would think",3,1,0.8689
"""The Puppy Problem"" - an ironic short story about the Control Problem",https://www.reddit.com/r/ControlProblem/comments/p86e1q/the_puppy_problem_an_ironic_short_story_about_the/,48,wouldn't the intelligence level of species be hardcoded the author never mentioned making the system dynamically update the list eh it's fiction,3,0,-0.0139
When you try going to a party to get your mind off things,https://www.reddit.com/r/ControlProblem/comments/1arabc5/when_you_try_going_to_a_party_to_get_your_mind/,120,"hello everyone if you'd like to leave a comment on this post make sure that you've gone through the approval process the good news is that getting approval is quick easy and automatic go here to begin  

i am a bot and this action was performed automatically please contact the moderators of this subredditmessagecomposetorcontrolproblem if you have any questions or concerns",1,1,0.9509
So happy that slowing down AI capabilities has entered the Overton Window of AI safety - source AIsafetymemes on Twitter,https://www.reddit.com/r/ControlProblem/comments/15bw2b2/so_happy_that_slowing_down_ai_capabilities_has/,50,"hello everyone rcontrolproblem is testing a system that requires approval before posting or commenting your comments and posts will not be visible to others unless you get approval the good news is that getting approval is very quick easy and automatic go here to begin the process  

i am a bot and this action was performed automatically please contact the moderators of this subredditmessagecomposetorcontrolproblem if you have any questions or concerns",1,1,0.9492
Nobel laureate Geoffrey Hinton says open sourcing big models is like letting people buy nuclear weapons at Radio Shack,https://www.reddit.com/r/ControlProblem/comments/1h441lj/nobel_laureate_geoffrey_hinton_says_open_sourcing/,46,"hello everyone if you'd like to leave a comment on this post make sure that you've gone through the approval process the good news is that getting approval is quick easy and automatic go here to begin  

i am a bot and this action was performed automatically please contact the moderators of this subredditmessagecomposetorcontrolproblem if you have any questions or concerns",1,1,0.9509
