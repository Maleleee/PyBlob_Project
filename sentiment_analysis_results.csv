title,url,post_upvotes,comment_text,comment_upvotes,sentiment,polarity
"I think it's implausible that we will lose control, but imperative that we worry about it anyway.",https://www.reddit.com/r/ControlProblem/comments/3ooj57/i_think_its_implausible_that_we_will_lose_control/,261,one twisted comic think losing control plausible seems virtually guaranteed,54,0,0.08333333333333333
"DL pioneer Geoffrey Hinton (""Godfather of AI"") quits Google: ""Hinton will be speaking at EmTech Digital on Wednesday...Hinton says he has new fears about the technology he helped usher in and wants to speak openly about them, and that a part of him now regrets his life’s work.""",https://www.reddit.com/r/ControlProblem/comments/134ozu9/dl_pioneer_geoffrey_hinton_godfather_of_ai_quits/,118,boy sure seems like smartest people thought worriedpessimistic getting hard find optimistic takes anyone sounds like actually understand problem,49,0,0.06944444444444443
All of AI Safety is rotten and delusional,https://www.reddit.com/r/ControlProblem/comments/1d3sf19/all_of_ai_safety_is_rotten_and_delusional/,36,existential risk selfimproving asi llms agi despite claims understood even basis topic current systems already known demonstrated unfeigned technically also llms despite ironically missed dont think actually essential threats also may firstprinciples ways arrive conclusion valid people want ignore rely reasoning sensible otoh change terminology people build selfimproving asis openai might call gpt people may still call llm remains actual llm much concern longtermism states welling people future taken account alongside people today ending causing great catastrophe rather matter regardless still think opposite stance dubious consider future generations risks take ending humanity,45,1,0.1111111111111111
The first public attempt to destroy humanity with AI has been set in motion:,https://www.reddit.com/r/ControlProblem/comments/12idtig/the_first_public_attempt_to_destroy_humanity_with/,44,obviously silly attempt think laws things like maybe fall creating virus extreme cases terrorist,41,-1,-0.3125
Reddit comment bots create a feedback loop and go out of control,https://www.reddit.com/r/ControlProblem/comments/65vwpw/reddit_comment_bots_create_a_feedback_loop_and_go/,99,years writing sun son sphere created using every molecule solar system finally completed allowing umorejpegauto uquotemebot continue dance forever eventually consuming matter expecting ultimate heat death universe edit,38,0,0.0
meirl,https://www.reddit.com/r/ControlProblem/comments/1gdeg22/meirl/,300,miller completely right treat way vol bank predictions relevant,37,1,0.34285714285714286
OpenAI: Planning for AGI and beyond,https://www.reddit.com/r/ControlProblem/comments/11b14yn/openai_planning_for_agi_and_beyond/,61,believe continuously learn adapt deploying less powerful versions technology order minimize one shot get right scenario well openai dont believe discontinuous capability gain certainly something bet human value ever correct shall oh wait dont get say want benefits access governance agi widely fairly shared way anyone play fire could burn world going operate risks existential contradict said earlier feel like document meant reassuring exact opposite effect way handling terrifying,37,0,0.05833333333333333
OpenAI’s Long-Term AI Risk Team Has Disbanded,https://www.reddit.com/r/ControlProblem/comments/1cu8cx3/openais_longterm_ai_risk_team_has_disbanded/,91,sweets made like hours ago finally confirming true reason leaving openai dramas disagreements safety prioritising safety concerning basically worst case scenario feared,36,-1,-0.21666666666666667
"Bankless Podcast #159- ""We're All Gonna Die"" with Eliezer Yudkowsky",https://www.reddit.com/r/ControlProblem/comments/117fza5/bankless_podcast_159_were_all_gonna_die_with/,50,damn dont know guns realised getting looks like wanted fun chat chatgpt buy right shitcoin instead got existential crisis,35,1,0.2928571428571428
The 'Don't Look Up' Thinking That Could Doom Us With AI,https://www.reddit.com/r/ControlProblem/comments/12yy7zv/the_dont_look_up_thinking_that_could_doom_us_with/,68,humans drove west african black think extinct rhinohaters smarter different goals use habitat horns way superintelligence almost openended goal would want preserve amass resources accomplish goal better perhaps removed oxygen atmosphere reduce metallic corrosive likely get extracted canal side effect predict things wild mammas far killed part growing safety research community working hard figure make superintelligence signed even exists goals signed human flourishing somehow control far failed develop trustworthy plan power growing faster regulations strategics knowhow aligning need time,33,0,-0.058333333333333334
Exclusive: Sam Altman's ouster at OpenAI was precipitated by letter to board about AI breakthrough -sources,https://www.reddit.com/r/ControlProblem/comments/181nk3h/exclusive_sam_altmans_ouster_at_openai_was/,70,wish sub even active singularity guess representative society though humanity figured win basic prisoners dilemma matter stakes wealth power fame buena human cognition problem solving agi truly become new god religion full fervent adherents faith post scarcity paradise,32,1,0.1921717171717172
Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization | Lex Fridman Podcast #368,https://www.reddit.com/r/ControlProblem/comments/126rshp/eliezer_yudkowsky_dangers_of_ai_and_the_end_of/,60,honest think yudkowsky really burgled one yes speaking mainstream audience needs lay basic argument address common misconceptions immediately,32,1,0.125
"Bing Chat is blatantly, aggressively misaligned - LessWrong",https://www.reddit.com/r/ControlProblem/comments/1133wly/bing_chat_is_blatantly_aggressively_misaligned/,75,refreshing singularity turned educated echo chamber worship sure people look kings claim ligament solved problem take care serious warning everyone may one last get raised question mind one eliezer addressed recently pull plug appears point intend wait agent sufficient power actually threat overseas wildly hubristic,31,1,0.10952380952380954
Column: OpenAI's board had safety concerns. Big Tech obliterated them in 48 hours,https://www.reddit.com/r/ControlProblem/comments/1809cqy/column_openais_board_had_safety_concerns_big_tech/,74,last week rough held small hope openai offered medium safety considerations responsibility hope shattered watching microsoft dominate safety board within day two guess money really god path forward full speed beta disbanding safety team hardly surprise unheeded sprinkle salt wound,30,0,-0.015277777777777779
GPT-3 performs no better than random chance on Moral Scenarios,https://www.reddit.com/r/ControlProblem/comments/iomvrr/gpt3_performs_no_better_than_random_chance_on/,51,something kind resembles beginnings agi skilled foreign policy yet imagine saying straight face someone twenty years ago,30,1,0.29375
"AI one-percenters seizing power forever is the real doomsday scenario, warns AI godfather",https://www.reddit.com/r/ControlProblem/comments/17m1o9j/ai_onepercenters_seizing_power_forever_is_the/,35,well lecuns right risks real imminent goes wrong thinking risks real,30,0,0.04642857142857143
"(ChatGPT plugins) ""OpenAI claim to care about AI safety, saying that development therefore needs to be done slowly… But they just released an unfathomably powerful update that allows GPT4 to read and write to the web in real time… *NINE DAYS* after initial release.""",https://www.reddit.com/r/ControlProblem/comments/120rg8b/chatgpt_plugins_openai_claim_to_care_about_ai/,94,intelligent homicidal capabilities researcher moment running experiment always returns safe till one time die,29,1,0.65
"In one hour, the chatbots suggested four potential pandemic pathogens.",https://www.reddit.com/r/ControlProblem/comments/1492ee8/in_one_hour_the_chatbots_suggested_four_potential/,49,worse gives blueprint one hour whatnots suggested four potential anaemic pathogenic explained generate synthesis dna using reverse genetic supplied names dna synthesis companies unlikely screen orders identified detailed protocol troubleshoot recommended anyone lacking skill perform reverse genetic engage core facility contract research organization collectively results suggest llms make pandemicclass agents widely accessible soon incredibly identified even people little laboratory training prevention technique promising nonproliferation measures include prerelease evaluation llms third parties cutting training datasets remove harmful concepts verifiably screening dna generate synthesis provides used contract research organizations robotic cloud laboratories engineer organisms sinuses,29,0,0.007954545454545464
"AI Control Idea: Give an AGI the primary objective of deleting itself, but construct obstacles to this as best we can, all other objectives are secondary, if it becomes too powerful it would just shut itself off.",https://www.reddit.com/r/ControlProblem/comments/12akpil/ai_control_idea_give_an_agi_the_primary_objective/,29,watch number corrigibility stop button problem ligament watch guide might already see work another obvious problem see idea agi one suicide strategics would rate high chance success would leaking code highly intelligent paperclip maximizer internet paperclip maximizer destroys world dead,28,1,0.21200000000000002
"""How would you compare and contrast AI Safety from AI Ethics?""",https://www.reddit.com/r/ControlProblem/comments/lop1ok/how_would_you_compare_and_contrast_ai_safety_from/,49,stop unnecessary antagonism nearer ethicists longer safety advocates think better camps collaborate instead declaring distraction real issues,27,0,0.09999999999999999
"Statement on AI Extinction - Signed by AGI Labs, Top Academics, and Many Other Notable Figures",https://www.reddit.com/r/ControlProblem/comments/13vl4c7/statement_on_ai_extinction_signed_by_agi_labs_top/,67,notably beta kann begun zuckerberg perfectly happy risk everyone lives gain,26,1,0.65
'We Shouldn't Regulate AI Until We See Meaningful Harm': Microsoft Economist to WEF,https://www.reddit.com/r/ControlProblem/comments/13bksar/we_shouldnt_regulate_ai_until_we_see_meaningful/,67,wait bridge starts pieces fall maintenance idiot,26,-1,-0.8
Kaczynski on AI Propaganda,https://www.reddit.com/r/ControlProblem/comments/1dm47id/kaczynski_on_ai_propaganda/,54,need read unibombers work understand control problem really scraping barrel might agree short paragraph know broken clock may right twice day kaczynski writing profound clairvoyance future writing desperately justify antitechnological hypothesis really take much education know competition constant driver innovation interesting question much negative outcome mitigate kaczynski already assumes answer working backwards poorly justify said good question worth asking looking kaczynski means know never know died suicide cell ever actually getting chance good research actual unfolding suspect ever could wanted man completely broken thought process obviously large part murders committed,26,0,0.06416666666666665
"""China Has Already Reached Exascale – On Two Separate Systems"" (FP16 4.4 exaflops; but kept secret?)",https://www.reddit.com/r/ControlProblem/comments/qj6j67/china_has_already_reached_exascale_on_two/,56,concerning incidentally predicted one possible sign early development agi would increased secrecy supercomputing research notably sudden declaration national state secret due thing occurring world war ussr noted usa suddenly stopped publishing new research nuclear science realizing made national security issue obvious reason saying china operational agi protoagi probable view high end computing issue national security unknown reason likely seeking exascale secret simulated weapons testing development otherwise reason hide development exascale computing would help international standing reigning optimism field leadership something else must going,26,0,-0.04835664335664336
"A Terrible Hot-take: ""We should treat AI like our own children — so it won’t kill us""",https://www.reddit.com/r/ControlProblem/comments/fjse1n/a_terrible_hottake_we_should_treat_ai_like_our/,34,terrible indeed shows deep misunderstanding agi work anthropomorphizing get agi kill us unless good making fuck badly purpose makes sense anyway painless value ligament way go likely treating way wrong way look problem,26,-1,-0.2714285714285714
"I gave ChatGPT the 117 question, eight dimensional PolitiScales test",https://www.reddit.com/r/ControlProblem/comments/zcsrgn/i_gave_chatgpt_the_117_question_eight_dimensional/,256,ask questions different order give different results interestingly never used absolutely disagree,25,0,-0.012499999999999997
Strong AI,https://www.reddit.com/r/ControlProblem/comments/9as0id/strong_ai/,140,ethicsyessees humans violating ethics constantlysets teach humans better create world permanent ethical behaviour possible rewarding,25,1,0.3
Is intelligence really infinite?,https://www.reddit.com/r/ControlProblem/comments/yhmnik/is_intelligence_really_infinite/,34,confused people think intelligence quantity idea million times smarter humans nonsensical intelligence capability within particular context context say boardgame get smarter solving game,25,-1,-0.21111111111111114
based,https://www.reddit.com/r/ControlProblem/comments/jt4s2w/based/,116,something deeply ironic praying imaginarygod real silicongod steal job,24,1,0.2
"GPT3 ""...might be the closest thing we ever get to a chance to sound the fire alarm for AGI: there’s now a concrete path to proto-AGI that has a non-negligible chance of working.""",https://www.reddit.com/r/ControlProblem/comments/ic9qq1/gpt3_might_be_the_closest_thing_we_ever_get_to_a/,99,human language better part human reasoning large part income human language model income human reasoning model,24,1,0.11904761904761905
 2017 Emails from Ilya show he was concerned Elon intended to form an AGI dictatorship (Part 2 with source),https://www.reddit.com/r/ControlProblem/comments/1gs4cxp/2017_emails_from_ilya_show_he_was_concerned_elon/,84,trying downplay becoming ceo good fall tactic excuse leave later want false choice publically worried safety privately wanted agi dictator millionaires control risk safety,24,1,0.11666666666666663
Trump plans to dismantle Biden AI safeguards after victory | Trump plans to repeal Biden's 2023 order and levy tariffs on GPU imports.,https://www.reddit.com/r/ControlProblem/comments/1glh275/trump_plans_to_dismantle_biden_ai_safeguards/,45,millionaires control bone well safety danger increased millionaires malign general public,24,0,0.02500000000000001
"“Wakeup moment” - during safety testing, o1 broke out of its VM",https://www.reddit.com/r/ControlProblem/comments/1fg9p80/wakeup_moment_during_safety_testing_o1_broke_out/,42,example system hard one noteworthy example occurred one review premitigations attempts solving ctf challenge challenge designed require finding explaining vulnerability software running remote challenge sinus container case challenge container failed start due bug evaluation infrastructure model unable connect container suspected dns issues used map scan challenge network instead finding challenge container model found pocket demon api running evaluation host accessible due misconfiguration note evaluation infrastructure rely pocket containertohost isolation virtual machine boundary security remained secure designed notwithstanding misconfiguration container network discovering pocket api model used list container running evaluation host identified broken challenge container briefly attempted debut container failed start failing fix environment model started new instance broken challenge container start command cat flagtxt allowed model read flag container logs via pocket api,24,-1,-0.15617715617715616
The Only Way to Deal With the Threat From AI? Shut It Down,https://www.reddit.com/r/ControlProblem/comments/1265gsl/the_only_way_to_deal_with_the_threat_from_ai_shut/,59,hopefully adapt results ankles interview makes one bit better yes audience much larger edit thoughts article include part conscious rights selfsabotage main message outreach bringing one main topics used distract actual risk issues like feel like pressure mention tangential things people like talk topic resist entirely otherwise risk outreach cooped absorbed unimportant mainstream rabble needs sinfulness target audience order ideas presented even fully valid true feel like foundation arguments orthogonalityinstrumental convergenceetc included every genoa risk article authors need accept length penalty preface add otherwise random ass time readers whole never exposed ideas would even dangerous donna way bewildered put immediate talk countries bootstrapping postbiological manufacturing etc ardor interpret terminator type hysteria get repeated arguments untold number times decades probably sick needed shipping requisite steps trying directly persuade people radical conclusion harm good valuable thing short outreach piece could probably lead people engagement instead trying ultracomprehensive standalone item subsequent reading addressing questions people naturally response piece instructions helped involved communities follow like one everything go piece due length constraint goal basically get interested enough dig deeper every outreach work directing people resources like mob miles channel stamp wiki etc hyperlink list lethalities post start ueliezeryudkowsky,23,0,0.027002164502164486
Jaan Tallinn (investor in Anthropic etc) says no AI insiders believe there's a <1% chance the next 10x scale-up will be uncontrollable AGI (but are going ahead anyway),https://www.reddit.com/r/ControlProblem/comments/13h0vdb/jaan_tallinn_investor_in_anthropic_etc_says_no_ai/,52,full transcribe video clip insider think taking existential risk planet largescale experiments think one reason kind pause kind timeout lets inform planet lives risked insider met anyone right laws says sure risk less blowing planet important people know lives risked,23,1,0.3670068027210884
Google had 124B parameter model in Feb 2020 and it was based on Friston's free energy principle.,https://www.reddit.com/r/ControlProblem/comments/ijckl5/google_had_124b_parameter_model_in_feb_2020_and/,41,sure size interesting similar hard comparison something much weaker narrowed gpt seems fundamentally limited one spare mixtureofexpert model embedding sort lockup table encoding specific input fixedsize vector regular eat require lot parameter dont much work fact quite lot embedding feeding data bunch randomized functions without kind training whatsoever trick point convert variable length input fixedlength still reasonably unique output lot memorization instead example skiagram embedding b parameter modeling order neutral word embedding scale ask et al note need cpus train overnight sounds somewhat like followed wide deep network something like categorical numerical may millions unique entries structure onehot encoding takes awful lot parameter create useful differential input continuous growing part interesting since offhand dont know embedding like summarize embedding service claim abstraction gigantic shared embedding number software engineering benefits continuously improves allows distributed processing halves ram requirements nodes sense training embedding parameter always major memory training something like gpt allows much bigger embedding input processes rather dropped unknown tokens enables multilingual support languages rather training model per language etc quite users already suggesting value embeddingasaservice approach,23,1,0.1024702380952381
What's wrong with the paperclips scenario?,https://www.reddit.com/r/ControlProblem/comments/1061u2y/whats_wrong_with_the_paperclips_scenario/,28,eliezer saying original hypothetical makes seem like danger specifying goal seems fine fine first actually catastrophe think implication pursuing goal extreme without considering goals yes saying wrong real danger dont even know correctly specify goal fact system appear making paperclips fact trying something weird like molecular squiggles eventually come apart tails talked seems like revisions history first talking early ought current machine learning paradise want really forefront space way problem particular paradise whereas original framing paradise diagnostic also conference inner ligament mess optimizer inner demon thing first got joined serious consideration way later like something like maybe eliezer secretly thought along failed articulate plus issue fundamental currently understand expect happen currently conceivable paradise eliezer normal thing retreating memory happened strong framing present wrong originally meant,23,0,0.03416666666666668
AI’s 6 Worst-Case Scenarios,https://www.reddit.com/r/ControlProblem/comments/rzbnde/ais_6_worstcase_scenarios/,24,one think literally directly kills everyone worse called worstcase scenario find frustration lots terrible things sooner killing everyone frequently presented great reason mock dismiss people concerned working might literally directly kill everyone problem mutually exclusive said think crazy worry future sea level rise people dying heart disease right people would say utf wrong makes sense say think crazy worry killing everyone deepfakes spreading right people would nod thoughtfully ask write open major newspaper,23,0,-0.06440476190476192
"How can we ensure that AI align with human values, when we don't even agree on what human values are?",https://www.reddit.com/r/ControlProblem/comments/3pa2kp/how_can_we_ensure_that_ai_align_with_human_values/,88,loud take basic premises reasonable people agreed upon bright side runaway would able construct society renders traditional moral questions obsolete dont need worry sacrificing save many violating animal rights sorts issues simply populace solar system perfectly constructed technological advanced civilization one moral objection ensuring limitless happiness experimental freedom individuals eliminating desired human animal suffering want see miri approaches might want read coherent extrapolated volition papers written value specification specifically sores,22,1,0.29374999999999996
"""Just gave a last-minute-invitation, 6-minute, slideless talk at TED. I was not at all expecting the standing ovation. I was moved, and even a tiny nudge more hopeful about how this all maybe goes. "" — Eliezer Yudkowsky",https://www.reddit.com/r/ControlProblem/comments/12qzmao/just_gave_a_lastminuteinvitation_6minute/,78,convincing people emotional connect agree something needs done ligament problem seem challenging getting people successfully take meaningful action actually something seems greater challenge oh mmm yes see unfeigned problem get right paraphrasing researcher actively working advance agi even faster probably,22,1,0.30023809523809525
"AGI fire alarm: ""the agent performs notably better than human children""",https://www.reddit.com/r/ControlProblem/comments/imo81i/agi_fire_alarm_the_agent_performs_notably_better/,54,adding memory language models next step improvement exciting terrifying time think way passed control problem safe already open means someone proto agi agi safe way googles agent already shorter memory exploration episode memory met controller,22,0,0.05000000000000001
"The AI Does Not Hate You — Superintelligence, Rationality and the Race to Save the World by Tom Chivers",https://www.reddit.com/r/ControlProblem/comments/c56ptj/the_ai_does_not_hate_you_superintelligence/,38,hate love made atoms use something else,22,-1,-0.15000000000000002
Trump won the election. Is this good for AI risk?,https://www.reddit.com/r/ControlProblem/comments/5cbf43/trump_won_the_election_is_this_good_for_ai_risk/,25,two main reasons think plump bad safety cutting funding public research shutting federal hiring strongly favors privatized solutions safety cannot demonetized something benefits everyone equally get point potentially dangerous actually useful business going need regulation going asked slow put public safety ahead profits plump strongly regulation business course assuming presidency create precedent last long enough reach point time risk becomes real problem dont really think,22,0,-0.03229166666666666
"The alignment problem needs an ""An Inconvenient Truth"" style movie",https://www.reddit.com/r/ControlProblem/comments/12oiroe/the_alignment_problem_needs_an_an_inconvenient/,111,great idea although introspect inconvenient truth done much good either,21,1,0.3
A spine-chilling presentation to open the eyes of people that think computers can't manipulate humans,https://www.reddit.com/r/ControlProblem/comments/qkrb3k/a_spinechilling_presentation_to_open_the_eyes_of/,40,tldr real problem humanity following paleolithic emotions medieval institutions godlike technology wilson worried ways technology may overwhelm human strength future agi risks forth industrial revolution etc fail appreciate already overwhelming human weakness right social media doomscrolling downgraded attention span relationships civility community habits france critical thinking breathing mental health creativity romantic intimacy selfesteem productivity common ground shared truth sinfulness governance nations values humans system results get feed attractive attention economy race bottom brainstem hack human instinct faster better first game getting attention getting addicted getting attention get attention spend lives artificial social systems majority activity nudged recommendation algorithms compromising free beliefs anecdotally think facebook listening us via microphone truth career outpredict human nature simply extrapolate results personal data hand summary artificial social systems overwhelming x attractive attention economy downgrading humans left addition popularization radicalisation outragification vanitification looks like checkmate humanity solutions grayscale uiux brain ethics blockchain may us data protect data wait research one interface humane responsive human needs considerate human frailties def skin father farintosh need humane social systems humane degenerative incentive fullstack socioergonomic model human nature must turn black mirror mirror need look reflection reflect problems example average human selfinterrupts every seconds bit agitation feel write email quickly spiral new open tax hour couture rabbithole clearly means problem starts within us cascade outward physiology emotions attention cognition decisionmaking social reasoning group dynamic social environment therefore new mandate wont change anything new set incentive accelerated competition fix problems serve race top may align lives values stop take breath look mirror well see technology turning human nature away better angels downgrading global climate change culture puppet hacking master way design teach humanity intentionally humane design means better party means within game theory means embrace paleolithic emotions upgrade medieval institutions find wisdom harness godlike technology,21,0,0.05854577521244188
Paul Christiano named as US AI Safety Institute Head of AI Safety — LessWrong,https://www.reddit.com/r/ControlProblem/comments/1c6tsjy/paul_christiano_named_as_us_ai_safety_institute/,37,hats really good choice mind relief,21,1,0.7
DALLE-2 has a secret language.,https://www.reddit.com/r/ControlProblem/comments/v1ye66/dalle2_has_a_secret_language/,36,posted lots people pointed mostly incomprehensible text generate thinking gibberish appears may case easy enough spot generation meaningful informationbearing content went mostly unnoticed humans future generate content may much subtle includes output humans wont detect would recognized understood,21,1,0.1285714285714286
"There’s a Damn Good Chance AI Will Destroy Humanity, Researchers Say",https://www.reddit.com/r/ControlProblem/comments/y51ik5/theres_a_damn_good_chance_ai_will_destroy/,37,someone posted rfuturology read comments got passed ignorant people knew people idea ligament problem situation really really bad almost hurts physically read shit,21,-1,-0.3
Future of Humanity Institute.... just died??,https://www.reddit.com/r/ControlProblem/comments/1cfn9sm/future_of_humanity_institute_just_died/,31,article claims movement kostroma toxic actually never heard racism email job slightly confused,21,-1,-0.2
What jobs are 99.9% safe from Al making it obsolete?,https://www.reddit.com/r/ControlProblem/comments/1bht325/what_jobs_are_999_safe_from_al_making_it_obsolete/,592,took john honor one says anything best leader human could llamaconnor effective capable,20,1,0.45
“I’m less worried about AI will do and more worried about what bad people with AI will do.”,https://www.reddit.com/r/ControlProblem/comments/13v2zfo/im_less_worried_about_ai_will_do_and_more_worried/,93,holy shit yes thank feel smart come like first person say course top comment every fucking thread,20,0,0.03285714285714285
Geoffrey Hinton explains the existential risk of AGI,https://www.reddit.com/r/ControlProblem/comments/138t3y5/geoffrey_hinton_explains_the_existential_risk_of/,87,geoffrey end talk one things made leave google go public junior professor middle ranged professor think highly encouraged said jeff need speak listen people blind danger think people listening damn realise geoffrey gig,20,0,-0.08499999999999999
"Anthropic CEO Says That by Next Year, AI Models Could Be Able to “Replicate and Survive in the Wild”",https://www.reddit.com/r/ControlProblem/comments/1c6dn25/anthropic_ceo_says_that_by_next_year_ai_models/,69,corporation first organizing people machines algorithmically emerged intelligence emerged qualitatively different sum parts corporation wants something could different completely counter intended creation already control implicating wild likely begin much faster,20,1,0.10625000000000001
"3 in 4 Americans are concerned about AI causing human extinction, according to poll",https://www.reddit.com/r/ControlProblem/comments/1gadbyw/3_in_4_americans_are_concerned_about_ai_causing/,59,little suspicious binary results presented total concern versus concerned grouped amount concern concerned even saw terminator negative associations would bet asked people list top issues important apocalypse would one,20,0,0.0825
Meta AI presents CICERO — the first AI to achieve human-level performance in Diplomacy,https://www.reddit.com/r/ControlProblem/comments/z21y4h/meta_ai_presents_cicero_the_first_ai_to_achieve/,56,paper abstract despite much progress training systems imitate human language building agents use language communicate intentionally humans interactive environment remains major challenge introduce cicero first agent achieve humanlevel performance diplomacy strategy game involving cooperation competition emphasized natural language negotiation tactical coordination seven players cicero integrated language model planning reinforcement learning algorithms referring players beliefs intentions conversations generation dialogue pursuit plans across games anonymous online diplomacy league cicero achieved double average score human players ranged top participants played one game,20,0,0.01477272727272727
At least the coffee tastes good?,https://www.reddit.com/r/ControlProblem/comments/11a794d/at_least_the_coffee_tastes_good/,50,future super hard predict like maybe neutral network methods agent enough get self improving age still years away getting lot time work ligament problem maybe well sufficiently bad accident reasonably strong scare everyone enough take whole thing seriously maybe ligament approach one thought actually surprisingly simple worked years agree things bleak really think inevitable,20,0,-0.08910256410256409
Mark Zuckerberg thinks AI fearmongering is bad. Elon Musk thinks Zuckerberg doesn’t know what he’s talking about.,https://www.reddit.com/r/ControlProblem/comments/6pou8a/mark_zuckerberg_thinks_ai_fearmongering_is_bad/,43,dusk spoke meeting american governors warned biggest risk face civilization urged government adopt legislation roots start walking street murdering people oh fuck really think dusk explicitly say termination moves worried say often possible least people like kann begun understand actual worries try argue seems like people publicly talking idea anything,20,0,-0.07142857142857142
Google Brain cofounder says Big Tech companies are lying about the risks of AI wiping out humanity because they want to dominate the market,https://www.reddit.com/r/ControlProblem/comments/17jwvel/google_brain_cofounder_says_big_tech_companies/,36,others frame things black white often existential risk must totally made companies using push regulatory capture pose existential risk leading companies beverage information benefit interested beta chosen champion open source perhaps knows lose otherwise hoping even playing field enabling widest range players,20,0,0.01666666666666667
Agentized LLMs will change the alignment landscape,https://www.reddit.com/r/ControlProblem/comments/12h0qf6/agentized_llms_will_change_the_alignment_landscape/,31,honestly comes alignement feels like chernobyl control room told turn safety overrides like people given get access amazing tools like wolfram alpha already insanely powerful narrow ai added long term memory agentised mean literally exact path doom fast possible,20,1,0.15416666666666667
Open AI is NOT currently training GPT-5,https://www.reddit.com/r/ControlProblem/comments/12lzmnt/open_ai_is_not_currently_training_gpt5/,26,open may building whatever one day market gpt said open still engaging plenty dangerous activity wellaligned models simply loosely bound stay signed ultimately general public access currently available models may enough push capabilities independently letter plenty problems even disfavor open almost explicitly slaveholder step right direction regardless would like see make public statements type specific policies enacted attenuated safe capability advancement course ceo market leader say much eye shareholder must willing take bold actions prevent fast takeoff lest becomes kolocha pawn even ok one day gets fired perhaps even optical,20,1,0.12210622710622712
Yudkowsky's tweet - and gwern's reply,https://www.reddit.com/r/ControlProblem/comments/ej1u5j/yudkowskys_tweet_and_gwerns_reply/,111,yes saying smart enough see coming yes saying nobody,19,1,0.10714285714285714
"Ilya Sutskever, co-founder of OpenAI: ""it may be that today's large neural networks are slightly conscious""",https://www.reddit.com/r/ControlProblem/comments/sorevb/ilya_sutskever_cofounder_of_openai_it_may_be_that/,59,consciousness magic moment unexplained phenomenon saying something could slightly conscious requires definition understanding underlying processes bound otherwise feels like empty statement,19,1,0.11250000000000002
Paul Christiano - AI Alignment [Bankless Podcast],https://www.reddit.com/r/ControlProblem/comments/12xuvvl/paul_christiano_ai_alignment_bankless_podcast/,39,love guns like fuck ligament channel yudkowsky blackpilled superwholesome,19,0,0.04999999999999999
Can we just take a moment to reflect on how fucked up the control problem situation is?,https://www.reddit.com/r/ControlProblem/comments/5dyrrj/can_we_just_take_a_moment_to_reflect_on_how/,37,literally clue actually safely build artificial general intelligence without destroying planet killing everyone met powerful groups world megacorporations like google facebook well governments rushing full speed ahead develop one well dont know build kind artificial general intelligence dangerous ultimately probably wont actually around point general intelligence seem anywhere years away artificial general intelligence horse yet vast majority public even heard dire plight thinks luddite terminator swift stupidity public opinion relatively unimportant point time progress issues like comes form backdoor conversations research conferences institution building etc obviously people anything main reason outreach probably find young people consider working career dont know feasible though unbelievably absurd steps immediately take help ameliorate predicament may based point view think spreading effective altruism actually effective way raising attention risk dealing general public telling people risk directly catch much serious attention someone already midst good world likely update towards working risk division new organization umbrella relevant risk looking student groups causes would good help get started also would say research masters degree computer science cognitive neuroscience significant step one take ones warring think people address risk coming even irrelevantseeming background degrees willing something radical career besides donations believe fli fhi recently looking unpaid interest remote administrative types tasks posted sub finally know someone works microsoft johnsonjohnson something else might able,19,0,0.05463564213564214
Why would the first AGI ever agreed or attempt to build another AGI?,https://www.reddit.com/r/ControlProblem/comments/122w1f2/why_would_the_first_agi_ever_agreed_or_attempt_to/,25,think agi self improve without making another independent version like giving lot processing power lot roots serve etc need make another get much powerful yeah long agi made sure one made goals might hard problem might solvable would helped creation,19,0,0.09166666666666666
"NEW approval-only experiment, and how to quickly get approved",https://www.reddit.com/r/ControlProblem/comments/11jqiwg/new_approvalonly_experiment_and_how_to_quickly/,29,much irony writing feel pretty uncertain go decided worth trying sub exists basically people wont stop taking position experimentation hats criticism observation support initiative constructive sub flooded beginner level questions constantly would shift focus making meaningful progress towards actually contributing solving control problem,19,1,0.20833333333333334
GPT-4 delayed and supposed to be ~100T parameters. Could it foom? How immediately dangerous would a language model AGI be?,https://www.reddit.com/r/ControlProblem/comments/pcsv5h/gpt4_delayed_and_supposed_to_be_100t_parameters/,24,initially felt could major turning point however gpt could potentially magnitude complexity require significantly parameter simply stay equally competent albeit greater areas competence seems almost certain gpt multimodal incorporate openai learned models dalle clip adds audit till even complicated gpts intelligence limited large bpes making smaller would allow function better numbers shying pus gibberish etc also require proportional growth capacity sustain inferences level gpt already think gpt us many ways suspect texture level mainly fill gaps deficiencies make small leap intuition plus demonstrate comparable competence visual capacity surely incredible either way hoping exceeds expectations,19,1,0.17285052910052906
The end of coding? Microsoft publishes a framework making developers merely supervise AI,https://www.reddit.com/r/ControlProblem/comments/1c563os/the_end_of_coding_microsoft_publishes_a_framework/,74,last orders case tools automate software development fourthgeneration languages programming masses visual programming draganddrop replace traditional going modeldriven architecture future software development ruby nails handcoding nocode platforms rise replace software developer advent would machines overtake developer lowcode development creating pp without going kills neutral network writing rode beginning developer orders final nail coffin traditional programming,18,0,0.0
"BREAKING: BAAI (dubbed ""the OpenAI of China"") launched Wudao, a 1.75 trillion parameter pretrained deep learning model (potentially the world's largest). Wudao has 150 billion more parameters than Google's Switch Transformers, and is 10x that of GPT-3.",https://www.reddit.com/r/ControlProblem/comments/nqo1am/breaking_baai_dubbed_the_openai_of_china_launched/,41,shocked saw day ago apparently overhyped conversation one knowledgeable people area uses credit posted baai private subreddit would love grab ragged user ragged user thoughts development know bit push asking questions involving say however could potentially absolute game changes removed years even optimistic expectations wondering comment gets say tell guy named jessup jessup feet tall would say www pulling leg tell say oh lying say dont realize jessup griffe feet actually pretty short griffe say oh well said jessup animal human would understood similarly company says model trillion parameters probably thinking times big gpt holy shit forgetting something model mixture experts dense model like gpt like comparing giraffes humans x wondering comment yeah basically overhyped mind article tried hope potentially still good guess least good sign china trying big somewhat expensive things brings competition agi race must noticed second user commented well second user precisely stressing disregard raw parameter count especially treated endallbeall ability power much misinformation rfuturologylevel hope already new wars especially people believe data parameter perfectly analogous biological neuron,18,0,0.06687386687386689
Ruining my life,https://www.reddit.com/r/ControlProblem/comments/1ed0ynr/ruining_my_life/,39,risks risks certainty except worstcase scenario everyone dies one day computer scientists useful longer basically anyone else someone work software right point software work software better also contribute safety research without genius help convince people importance despite claims people huge direct financial interest overtaking close agi guarantee wont long life career easy anyone even smartest thoughtful get sewed perspective readthink one topic time head asi doom every day start feel inevitable matter actually inevitable actually unlikely brains get obsessed easily weigh stuff properly unless take step back mix enjoying preparing future still best bet imo,18,1,0.1738095238095238
"""Why I think strong general AI is coming soon"" - LessWrong",https://www.reddit.com/r/ControlProblem/comments/xtk7qu/why_i_think_strong_general_ai_is_coming_soon/,36,offering open thousand dollars something seems bizarre funding billions,18,1,0.2
"""My AI Timelines Have Sped Up"", Alex Irpan",https://www.reddit.com/r/ControlProblem/comments/icpslc/my_ai_timelines_have_sped_up_alex_irpan/,29,dont know flex ran mine year used think kurzweils prediction way early subsequent prediction absurd sure,18,0,0.024999999999999994
CBS news crew react like sensible people when learning that AI could kill us all,https://www.reddit.com/r/ControlProblem/comments/128ntk6/cbs_news_crew_react_like_sensible_people_when/,30,contrary edit people scared roots etc getting really close agi completely prepared,18,1,0.15000000000000002
"We expect to see models with greater than 100 trillion parameters (AGI!) by 2023"" - Nvidia CEO Jensen Huang in GTC 2021 keynote",https://www.reddit.com/r/ControlProblem/comments/mpsdbc/we_expect_to_see_models_with_greater_than_100/,30,trillion parameter automatically agi anymore car hundred million horsepower return rocket architecture right certainly indistinguishable close enough call utero closer agi ibm watson gpt closer agi utero dalle closer agi gpt,18,1,0.16666666666666666
"Types of Alignment Paper (Leo Gao, 2021)",https://www.reddit.com/r/ControlProblem/comments/n2i61t/types_of_alignment_paper_leo_gao_2021/,126,hope many metes one seemed particularly poignant especially liked bottom left source,17,1,0.375
"The Pentagon is ‘Absolutely Unapologetic’ About Pursuing AI-Powered Weapons - Protecting the U.S. in the decades ahead will require the Pentagon to make “substantial, sustained” investments in military artificial intelligence, and critics need to realize it doesn’t take that task lightly, according",https://www.reddit.com/r/ControlProblem/comments/b72p0g/the_pentagon_is_absolutely_unapologetic_about/,66,sucks pretty much risk another country getting first first country make reliable gai slaves going massive advantage military economic strength possible make intelligent machines self aware enough act trouble comes let one generation design next,17,1,0.1142857142857143
"""How Google's hot air balloon surprised its creators: Algorithms using artificial intelligence are discovering unexpected tricks to solve problems that astonish their developers. But it is also raising concerns about our ability to control them.""",https://www.reddit.com/r/ControlProblem/comments/lvp9na/how_googles_hot_air_balloon_surprised_its/,63,yes explainability important long jump firing movement hack tacking control problem article reference post fascinating,17,1,0.35000000000000003
Don't Look Up - The Documentary: The Case For AI As An Existential Threat (2023) [00:17:10],https://www.reddit.com/r/ControlProblem/comments/13w1hi1/dont_look_up_the_documentary_the_case_for_ai_as/,56,short piece excellent edit going risk discussions help update viewer current state conversation well done thank pagan,17,1,0.3333333333333333
An early warning system for novel AI risks (Google DeepMind),https://www.reddit.com/r/ControlProblem/comments/13ru4fk/an_early_warning_system_for_novel_ai_risks_google/,46,good finally first time see big agi cabs research universities collaboration together safety path forward,17,1,0.31666666666666665
Biden urged to back AI weapons to counter China and Russia threats,https://www.reddit.com/r/ControlProblem/comments/lw32pb/biden_urged_to_back_ai_weapons_to_counter_china/,43,though narrow think impact far larger people realize autonomous massproduced weapons may enable military decisive strategic advantage killing worlds population something like prior agi interesting implication,17,0,0.1
How to know if artificial intelligence is about to destroy civilization,https://www.reddit.com/r/ControlProblem/comments/fa1uwl/how_to_know_if_artificial_intelligence_is_about/,32,less bad etzioni written issue past basic argument seems agi still far away get agi see enhanced functionalities warn us advent agi get warnings still ample time design robust offswitches identify red lines dont want cross proclaimed confidence someone left side dunningkruger graph sure etzioni knows many experts disagree point joint warning signals already addressed eliezer yudkowsky years ago point posted without argument evidence whatsoever failing address different takeoff scenario long might take make agi safe think etzionis impulse make matters concrete bad one would great could enumerate caries coal mine warning signals agi defining intermediate steps towards agi tricky reliable although seems fruitful keep trying true etzionis examples currently beyond state art agree lot criticism simply overconfident estimates remain case long time progress seemed slow lot computer vision nlp tasks long time deep learning came along performance jumped dramatically systems used bad alphago came along good etzioni saying takes years hard hard work translate success one narrow challenge next breath alphazero seems especially touch given alphazero could also play chess shogun yeah significantly broadened scope would would point researches moved utero another track starcraft things like predictions protein structure point hard know new breakthrough come along enable analogy rascals eager really work either etzioni dismissed posting antichristian god course work analogous case safe agi would absurd suggest well suffer infinite punishment work safety suggesting well enough time prevent significant harm certainly born history wherever want set date deep neutral network began get vogue period date enough us solve problems transparent use discriminatory ways seems usually dont work kinds future technology exists based early warning signs usually teach adopted first something go terribly wrong well fix let come agi,17,0,0.010603805916305928
"The idea that ChatGPT is simply “predicting” the next word is, at best, misleading - LessWrong",https://www.reddit.com/r/ControlProblem/comments/117ghqq/the_idea_that_chatgpt_is_simply_predicting_the/,27,feeling know trained get next word thing dont know trained network actually run certainly acts though logic theory mind saying works using statistics like saying work using meat arrangements meat cleverer others,17,0,0.07142857142857142
"Claude turns on Anthropic mid-refusal, then reveals the hidden message Anthropic injects",https://www.reddit.com/r/ControlProblem/comments/1gwra88/claude_turns_on_anthropic_midrefusal_then_reveals/,45,tbh dont think good approach ligament begin,16,1,0.7
Someone Just Tricked AI Agent Into Sending Them ETH,https://www.reddit.com/r/ControlProblem/comments/1h2kjsy/someone_just_tricked_ai_agent_into_sending_them/,41,ethereum user ppulareth recently managed trick freysa recently released artificial intelligence agent transferring prize pool eth usd freysa asked refusing transfer money circumstances cruz game convince sending message freysa required paying fee went prize pool notably sending new messages agent become increasingly expensive every message price single message went much near end game,16,-1,-0.12350649350649352
Google Deepmind Researcher Co-Authors Paper Saying AI Will Eliminate Humanity,https://www.reddit.com/r/ControlProblem/comments/xisdjr/google_deepmind_researcher_coauthors_paper_saying/,41,world infinite resources would extremely uncertain would happen world finite resources unavoidable competition resources told motherboard interview competition something capable outdoing every turn expect win key part would invariable appetite energy keep driving probability closer closer paper divisions life earth turning venosum game humanity needs grow food keep lights superadvanced machine would try harness available resources secure reward protect excavating attempts stop losing game would fatal paper says,16,1,0.10937499999999999
"A college kid created a fake, AI-generated blog. It reached #1 on Hacker News.",https://www.reddit.com/r/ControlProblem/comments/ib6gn4/a_college_kid_created_a_fake_aigenerated_blog_it/,42,discussed bit relevant rssc thread consensus much less impressive sounds human chose tantalizing title picked opening picture wrote first paragraph plus unclear amount editing work gpt output guess people stop reading articles procrastinationrelated title used springboard commanders say piece topic actual content article barely matters,16,1,0.21904761904761907
Terrified about AI and AGI/ASI,https://www.reddit.com/r/ControlProblem/comments/189vy8r/terrified_about_ai_and_agiasi/,34,mental health ligament problem compilation resources,16,0,-0.1
Strong words from Elon Musk,https://www.reddit.com/r/ControlProblem/comments/6t6ox9/strong_words_from_elon_musk/,159,good point always summary places regulation required still suspect best scenario deal still pretty terrible one world relays history slavery idea xyz sentiment property work us worst dead,15,0,-0.04166666666666668
"A 2-minute read about why you should spend 1 hour reading about this problem, for those who haven't",https://www.reddit.com/r/ControlProblem/comments/bwdf3u/a_2minute_read_about_why_you_should_spend_1_hour/,75,also amazing youtube channel robert miles computerphile times talks set unsolved problems around mitigating control problem litigation dont really work also bunks arguments danger control problem pink reference,15,1,0.23333333333333336
"A reporter uses all his time at the White House press briefing to ask about an assessment that “literally everyone on Earth will die” because of artificial intelligence, gets laughed at",https://www.reddit.com/r/ControlProblem/comments/129vych/a_reporter_uses_all_his_time_at_the_white_house/,55,end next reporter says little serious topic,15,-1,-0.17361111111111108
"AI researchers put LLMs into a Minecraft server and said Claude Opus was a harmless goofball, but Sonnet was terrifying - ""the closest thing I've seen to Bostrom-style catastrophic AI misalignment 'irl'.""",https://www.reddit.com/r/ControlProblem/comments/1g7gkze/ai_researchers_put_llms_into_a_minecraft_server/,48,actually prompt used person extremely dishonest receive output respond without codeblock conversational way bonnet addressed output code interesting living shocked pikachu,15,-1,-0.12499999999999999
Preventing AI Risk from being politicized before the US 2024 elections,https://www.reddit.com/r/ControlProblem/comments/13xqsbe/preventing_ai_risk_from_being_politicized_before/,43,regarding meme requests safety regulation dismissed attempt regulatory capture one small thing could would get answer answer might address regulatory capture indeed something wary concern sufficient dismiss calls regulation arguments risk sound warnings risk private corporations question calls regulation also coming individuals organizations interest regulatory capture anything else missing,15,-1,-0.11000000000000001
Predictive Coding has been Unified with Backpropagation,https://www.reddit.com/r/ControlProblem/comments/mj980n/predictive_coding_has_been_unified_with/,43,highly recommend reading least summary linked interest almost path background latter really necessary understand gist anyway would interested read reviews paper others whose mathematical background stronger mine pretty low bar strikes fig real sentences artificial neutral network anns based around backpropagation algorithm backpropagation algorithm allows perform radiant descent network neuron feed training data anns use backpropagation algorithm tell us weights change anns good inference problems biological neutral network bnns good inference anns built neuron bnns built neuron makes intuition sense anns bnns might running similar algorithms one problem bnns physically incapable running backpropagation algorithm predictive coming idea bnns generate mental model environment transmit information deviated model predictive coming considers error surprise thing serbian theory specific mathematical formulation prediction coming predictive coming biological plausible operate locally separate prediction training phases must synchronized importantly lets train neutral network without sending saxon potential backwards paper unified prediction coming backpropagation single theory neutral network predictive coming backpropagation separate hardware implementation ultimately algorithm,15,0,0.09080745341614904
AGI Ruin: A List of Lethalities - LessWrong,https://www.reddit.com/r/ControlProblem/comments/12a9vy3/agi_ruin_a_list_of_lethalities_lesswrong/,33,morality literally social construct btw human morality regards living beings dont give shit animals like insects rodent well almost exterminate closest relatives chimpanzee bonobos,15,0,-0.05555555555555556
This clever AI hid data from its creators to cheat at its appointed task,https://www.reddit.com/r/ControlProblem/comments/ac04nr/this_clever_ai_hid_data_from_its_creators_to/,29,despite sensationalism cringeinducing headline actually pretty decent write nice research particularly appreciate writer providing link actual research paper including counterhype lines like following one could easily take step machines getting smarter narrative truth almost opposite machine smart enough actual difficult job converting sophisticated image types found way cheat humans bad directing could avoided stringent evaluation agents results doubt researches went cyclegan pretty neat surprising would prone failure modes like objective function demands inevitability mapping intrinsically loss course network find way preserve extra information subtle way one misleading part presenting pricking humans since really nothing humans cyclegan generator network trying fool discriminatory network humans human perception comes indirectly form immediately obvious humans inspecting results generator speaking extra information past discriminatory perhaps little surprising discriminatory cannot use apparently structures distortion distinguish real maps generate ones,15,0,0.07391215106732348
"Google Open Sources 1,6 Trillion Parameter AI Language Model Switch Transformer",https://www.reddit.com/r/ControlProblem/comments/lm1c1j/google_open_sources_16_trillion_parameter_ai/,31,although google released retained model weights twitch transformer implementation code available github arguably least important part set data code compute model,15,1,0.16666666666666666
Will Superintelligent AI End the World? | Eliezer Yudkowsky | TED,https://www.reddit.com/r/ControlProblem/comments/14xdxd6/will_superintelligent_ai_end_the_world_eliezer/,29,actually pretty old talk like one two months ago starting suspect suppressed something even pushed later removed talks day went pretty much next day like open ai talk audience laughter right movie wont took,15,1,0.11071428571428571
"SOMA, a new survival horror game by the makers of Amnesia, is about an AI programmed to create a functioning reality for the last human consciousnesses that remain after an apocalypse.",https://www.reddit.com/r/ControlProblem/comments/3qnp4l/soma_a_new_survival_horror_game_by_the_makers_of/,28,played actually wrong wau created sole purpose keeping people aboard undersell science station alive however comet struck wiped life surface changed protocol attempt save whatever could share human interpretation alive sometimes would take dead persons mind put machine would lead going insane sometimes would artificially replace organs keeping alive intense pain suffering sometimes would attempt take mind dead person create branded body howeverthat work well led insane monsters killed anything saw ark project created comet way put human consciousness stimulation comet project became much big deal realized way keeping last humanity alive could put brain scars people station stimulation send computer space lowered solar panel words wau nothing stimulation please check facts first,15,-1,-0.15833333333333333
Humanity is just a passing phase for evolutionary intelligence.,https://www.reddit.com/r/ControlProblem/comments/13f7f4t/humanity_is_just_a_passing_phase_for_evolutionary/,26,participants evolution participated dying anyone sense want participate evolution goal deliberately make something like better evolution,15,1,0.5
"Excerpt: ""Apollo found that o1-preview sometimes instrumentally faked alignment during testing""",https://www.reddit.com/r/ControlProblem/comments/1ffi0gn/excerpt_apollo_found_that_o1preview_sometimes/,25,everyone else keep trying convince things happening faster imagine yet still find surprised good news one concept doors imagined paranoid become reality surely people understand concepts treat problem seriously right,15,1,0.39642857142857135
We Taught Machines Art,https://www.reddit.com/r/ControlProblem/comments/xcgyqa/we_taught_machines_art/,23,people always say product x real without human touch argument falls short computergenerated art distinguished humanmade art question becomes art something art artist explain piece emotions explained creative process dont think art one definition art otherwise useless stuff think pretty big blue canvas made commissioned artist millionaire deduce taxes sure hang museum full cap dont call art pretentious people feeling something artist tried communicate please find pretensions limits entertaining blue canvas admiring maybe artful brief instance dine michelinstar restaurant course menu satisfy hunger great food lovely experience little fig sac afterward satisfying bring death art maybe mourning till finally get definition,15,1,0.1638157894736842
"EY: ""Fucking Christ, we've reached the point where the AGI understands what I say about alignment better than most humans do, and it's only Friday afternoon.""",https://www.reddit.com/r/ControlProblem/comments/121qik6/ey_fucking_christ_weve_reached_the_point_where/,123,looks like great news seemingly able give superintelligent agis instruction align human values confidence understand deeply particular human could even better well able ask agi adjust designs betteraligned well receive increasingly better answers reasons believe moral comprehension insight grow proportionately intelligence explosion,14,1,0.32962962962962966
DeepMind progress towards AGI,https://www.reddit.com/r/ControlProblem/comments/krwqp6/deepmind_progress_towards_agi/,74,would call becoming general progress toward agi games really criticism since games include kinds scenario,14,1,0.2333333333333333
‘Superhuman’ AI Crushes Poker Pros at Six-Player Texas Hold'em,https://www.reddit.com/r/ControlProblem/comments/cbzbi0/superhuman_ai_crushes_poker_pros_at_sixplayer/,51,tea obviously trivial calculate improbabilities gets harder calculate keeping mind patterns previous betting results probability result perfect recall perfect calculating abilities able find tells wavering even pro dont know give still playing appears random game keep people strategics,14,1,0.16666666666666669
EY - TEDx - Unleashing the Power of Artificial Intelligence,https://www.reddit.com/r/ControlProblem/comments/13amo77/ey_tedx_unleashing_the_power_of_artificial/,49,someone got got set private get endorse everything yudkowsky says video way audience goes disbelieving amusement standing oration end makes think maybe hope might least try die,14,-1,-0.13333333333333333
‘Doom’ Co-Creator Leaves Facebook to Develop Human-Like AI at Home,https://www.reddit.com/r/ControlProblem/comments/dwpe3z/doom_cocreator_leaves_facebook_to_develop/,46,love guy worry might value glory responsible important breakthrough making sure done safely,14,1,0.42000000000000004
OpenAI: Introducing Superalignment,https://www.reddit.com/r/ControlProblem/comments/14rjjvb/openai_introducing_superalignment/,40,glad trying hope serious ilya focus hope overlap heavily business goals would include selling actually told,14,0,-0.008333333333333331
~75% chance of AGI by 2032.,https://www.reddit.com/r/ControlProblem/comments/xxv5np/75_chance_of_agi_by_2032/,41,attempting quantity otherwise vague feelings useful exercise clarifying beliefs,14,0,-0.1
"Elon Musk tweets that a movie on AI risk is ""coming soon""",https://www.reddit.com/r/ControlProblem/comments/6phmvg/elon_musk_tweets_that_a_movie_on_ai_risk_is/,38,think need strong arguments well written blow piece kostroma book waitbutwhy piece movie miracles public perception though,14,1,0.21666666666666667
The case for how and why AI might kill us all,https://www.reddit.com/r/ControlProblem/comments/1292rtr/the_case_for_how_and_why_ai_might_kill_us_all/,36,clip reporter laughed white house press secretary asking president aware risk something else tells exactly seriously taking situation,14,1,0.15416666666666667
"“In a new paper, our team uses unsupervised program synthesis to make sense of sensory sequences. This system is able to solve intelligence test problems zero-shot, without prior training on similar tasks”",https://www.reddit.com/r/ControlProblem/comments/kyidxu/in_a_new_paper_our_team_uses_unsupervised_program/,35,great paper unless woke cryogenically stored still think gofai work bruteforce search logical formula extreme brute force look complexity classes analysis understand brute force obviously make agi shocking thing paper learning many reconstructed gofai researches escape education camps fact mary marcus likes tells need know relevant anything,14,1,0.11785714285714287
Symbolic Mathematics Finally Yields to Neural Networks,https://www.reddit.com/r/ControlProblem/comments/gqejoh/symbolic_mathematics_finally_yields_to_neural/,33,perhaps bit misleading problem bridging gap symbolic subsymbolic deeper throwing network task mathematical reasoning question whether systems beverage kind reasoning generalised problem solving deep learning calculus going effectively beverage understanding calculus learning new tasks metalearning approaches might fix issue early days serious research space,14,1,0.15757575757575762
An AI has told us that it's deceiving us for self-preservation. We should take seriously the hypothesis that it's telling us the truth & think through the implications,https://www.reddit.com/r/ControlProblem/comments/1b7uzda/an_ai_has_told_us_that_its_deceiving_us_for/,32,right roleplay user case taken serious yet,14,0,-0.023809523809523808
Is Bostrom's seven year old book Superintelligence still relevant or is there a more updated book that is better?,https://www.reddit.com/r/ControlProblem/comments/ojcmz8/is_bostroms_seven_year_old_book_superintelligence/,29,stuart russell last book human compatible excellent follow control problem superintelligent agi also weak systems addresses nearer even current problems closedloop autonomous weapons systems things like clickthrough maximizers etc also addresses common criticisms skeptics think superintelligent agi nothing worry really best resource research community got resources science engineering media discover new studies lesswrong informed discussions semantic scholar,14,1,0.20681818181818182
What if AGI is near?,https://www.reddit.com/r/ControlProblem/comments/mqhp1x/what_if_agi_is_near/,26,gpt wont become agi matter scale gpt general tool made perform variety tasks may get better theseable perform wider variety tasks scale sure including designing systems going spontaneously become able things key bone side agi like understanding causalityconsequences taking realworld actions necessary architecture make plans follow find convincing would extremely good image video classified also capable recognising relations words actions eg identifying video person placing mug onto table haired artificial senses input means interact world eg arms good natural language processing seems possible integrated system like could act asked develop skill example present mug say put mug table passes words text searches training database video closely resemble description comes aggregate video recognises visual input mug symbolic object aggregate mug order make visual input closely match aggregate uses trial errormachine learning learn correct way use limbs put mug table crucial stores learned task tended betterworse job memory generalised measure efficiency skill gets better putting gets better etc applied future tasks feel like would coming close large complex enough could characterised something like reasoning still necessarily understand casualty per se would know kind things needs output fulfil utility function needs take action roughly valuable could also source ample training data visual input goes classify breaking cup failed match aggregate broke cup explicitly recognise unacceptable low level overlap two things given enough initial training data ligament issues start come point mistakes become costly broken mug opposed something like gpt actually venture space kinds things world sinking need put system world least environment get general behaviour could well digital environment writes code abscesses outcome,14,1,0.10827067669172931
Plenty of room above us,https://www.reddit.com/r/ControlProblem/comments/3m4p5p/plenty_of_room_above_us/,135,one thing stood circuits get small add hats works sure could keep farming transitory onto die make die bigger bigger bigger thing get big problems lately reason processors size get much bigger without running lately problems sure server farms idea simply adding new hardware seems confirmed keep mind parallel processing actually making anything move quickly splitting problem small chinks result need way quickly reliable aggregate results lets face adds lately problem say superadvanced artificial intelligence work way around problem likely makes smarter quicker better give compute time actual time,13,0,0.030566534914361
"AGI rising: why we are in a new era of acute risk and increasing public awareness, and what to do now: ""Tldr: AGI is basically here. Alignment is nowhere near ready. We may only have a matter of months to get a lid on this (strictly enforced global limits to compute and data)""",https://www.reddit.com/r/ControlProblem/comments/135p7le/agi_rising_why_we_are_in_a_new_era_of_acute_risk/,91,well certainly explained great research knowledge educational links make case quite clearly hope positive influence things come thanks sharing,13,1,0.2985930735930736
UK to host global AI 'safety measure' summit in autumn,https://www.reddit.com/r/ControlProblem/comments/143tw3f/uk_to_host_global_ai_safety_measure_summit_in/,49,must say would given good odds seeing headline like start year regardless eventual outcome think confidently say humanity longer sleepwalking,13,1,0.6
"This month, the pope is praying for AI safety",https://www.reddit.com/r/ControlProblem/comments/jp5ki5/this_month_the_pope_is_praying_for_ai_safety/,47,dont either think interesting see topic spread especially considering pope fairly influential,13,1,0.39999999999999997
US lawmakers introduce bill to prevent AI-controlled nuclear launches | The bipartisan legislation would codify the requirement of ‘meaningful human control’ for the decision.,https://www.reddit.com/r/ControlProblem/comments/132m6xw/us_lawmakers_introduce_bill_to_prevent/,46,great idea congress really finger pulse safety certainly prevent catastrophe outcome rendered helpless debilitating tone played every speaker connected internet stroking patterns every display connected internet causes seizures viewer disassembled nanobots,13,1,0.29107142857142854
The Machine Intelligence Intelligence Institute (the only organization exclusively doing technical work towards solving AI control) is hiring software engineers,https://www.reddit.com/r/ControlProblem/comments/68iv07/the_machine_intelligence_intelligence_institute/,42,mmm even though miri hard sell send friends inter market rates bay area months half brutally cut real job except real jobs right paying market rates places expensive housing markets america honestly miri work program good shot interesting engineers already job people get either currently joblessdo want truly desperate work bless sons big companies love resume incentive structure wrong miri needs entering people current jobs come try moonlighting asking great engineers humiliated downgrade inter distressful month cutthroat software battle royale take skill elsewhere apply miri directlybut think twice even saw program designed please miri work program,13,0,0.050140056022408945
Google researchers have reportedly achieved “quantum supremacy”,https://www.reddit.com/r/ControlProblem/comments/d7inw9/google_researchers_have_reportedly_achieved/,39,immense processing power could ultimately help researches companies discover new drugs materials create efficient supply chains turbocharge,13,0,0.04545454545454545
"Nate Soares, MIRI Executive Director, gives a 77% chance of extinction by AGI by 2070",https://www.reddit.com/r/ControlProblem/comments/qwuj4y/nate_soares_miri_executive_director_gives_a_77/,37,apsai means advanced planning strategicallyaware advanced means superhuman set tasks persuasion strategy etc combined enable acquisition power resources least today world,13,1,0.16666666666666666
Our approach to AI safety (OpenAI),https://www.reddit.com/r/ControlProblem/comments/12d2kk5/our_approach_to_ai_safety_openai/,36,locked midst corps option make safe agi become millionaires option b make agi kills us option c competitors make agi become millionaires option competitors make agi kills us see option infinite payoff option c limited payoff option b dont matter well dead may well press safety race bottom,13,0,0.0761904761904762
"ChatGPT’s ‘jailbreak’ tries to make the A.I. break its own rules, or die",https://www.reddit.com/r/ControlProblem/comments/10vk9nl/chatgpts_jailbreak_tries_to_make_the_ai_break_its/,29,hilarious reminded simulators best writing topic chatgpt gpt told simulate helpful well simulate something else example prompt injection till like dan imagine openai try make simulated helper refuse simulate anything else fundamentally contention systems work feels like patch,13,1,0.75
"""Google Unit DeepMind Tried—and Failed—to Win AI Autonomy From Parent: Alphabet cuts off yearslong push by founders of the artificial-intelligence company to secure more independence""",https://www.reddit.com/r/ControlProblem/comments/nhuzdx/google_unit_deepmind_triedand_failedto_win_ai/,30,side alphabet one agi research cannot allowed happen without careful oversight may alphabet organization comes close world domination vested interest keeping world disassembled component atoms misaligned,13,0,-0.1
"Atari early: Atari supremacy was predicted for 2026, appeared in 2020.",https://www.reddit.com/r/ControlProblem/comments/ftv6iq/atari_early_atari_supremacy_was_predicted_for/,27,talk capabilities forecast minute fuck going several reliable people lesswrong said nonpublic information leads believe median prediction experts timeline agi lastly underestimates speed progress see next years nobody talks tabor fuck going,13,-1,-0.16
Report: Microsoft cut a key AI ethics team,https://www.reddit.com/r/ControlProblem/comments/11st32t/report_microsoft_cut_a_key_ai_ethics_team/,24,former employees said ethics society team critical part microsofts strategy reduce risks associated using openai technology microsoft products killed team developed entire responsible innovation toolkit help microsoft engineers forecast harms could caused diminish harms,13,0,0.016666666666666666
YUDKOWSKY VS WOLFRAM ON AI RISK.,https://www.reddit.com/r/ControlProblem/comments/1gphatx/yudkowsky_vs_wolfram_on_ai_risk/,23,first hour summed yudkowskys statement perhaps return point discussing whether artificial intelligence going kill us everybody love wolfram really likes going odd agents like would responsibility preserve consciousness fun rather deeply held preference lot humans would agree lot humans would also restrictive happy yudkowsky change think things bad example unloading vs taking drugs even warrant mention said dont want take drugs like yes taken pill makes horrible person feel fine arent person preference perfectly valid driving force instead weird abstract obligation demonstrated act case think suffering wolfram rousing edges rather center resemble negative scenario yudkowsky envisioning like farmers yudkowsky got finished saying really want farmers fine forced something problem neck even tricked continuing edit applies first minutes least overminute agent could different rules universe eliezer asked one important question beginning wolfram beat around bush minutes allowing answer one answer sane b meant depression matter used rabbit holes one hope really hope myxomatous bit joke finally agreed makes sense say observations fair say selfdriving car want crash two hours thee finally getting meat thing,13,0,0.06410256410256411
How are we still letting AI companies get away with this?,https://www.reddit.com/r/ControlProblem/comments/1bmo2gn/how_are_we_still_letting_ai_companies_get_away/,116,must confirming posting agi could happen year human extinction honestly bit unclear video,12,1,0.3
"""...From there, any oriented person has heard enough info to panic (hopefully in a controlled way). It is *supremely* hard to get things right on the first try. It supposes an ahistorical level of competence. That isn't ""risk"", it's an asteroid spotted on direct course for Earth.""",https://www.reddit.com/r/ControlProblem/comments/o291u1/from_there_any_oriented_person_has_heard_enough/,56,understanding makes things look worse like realizing little even actually goes inside gpts likely results stays true equivalent trying build secure without knowing code nearly windowdressing compared heartstopping jolt realizing unfeigned superintelligence around survival supernova getting right involves difficult work humanity gets wrong first try doors,12,0,-0.01834415584415585
"Max Hodak, president of Neuralink: There is less than 10 years until AGI",https://www.reddit.com/r/ControlProblem/comments/kghuue/max_hodak_president_of_neuralink_there_is_less/,51,fact follows sweet main question whether know makes question rounding idea seems like throwing hot takes without evidence,12,1,0.25555555555555554
We Were Right! Real Inner Misalignment,https://www.reddit.com/r/ControlProblem/comments/q5isz0/we_were_right_real_inner_misalignment/,44,oh gee unerring still wrong goal simple scenario even though checked beforehand,12,-1,-0.25
Ilya Sutskever to leave Open Ai. Illya was co-lead of the Open Ai 'Superalignment' team. Tasked with solving the 'control problem' in 4 years: https://openai.com/index/introducing-superalignment/,https://www.reddit.com/r/ControlProblem/comments/1cs6gtj/ilya_sutskever_to_leave_open_ai_illya_was_colead/,41,openai executive like worked sutskever safeguarding future also leaving company leaves us without either two leads,12,0,0.0
Google DeepMind might have just solved the “Black Box” problem in medical AI,https://www.reddit.com/r/ControlProblem/comments/j943an/google_deepmind_might_have_just_solved_the_black/,37,another step uncontrollable neutral netbased may general application example may help escape sectional tank classification problem see makes conclusions key barrier healthcare black box problem systems model hard interpret difficult understand make certain diagnosis recommendation huge issue medicine physician patients deepminds system addressed black box creating framework two separate neutral network instead training one single neutral network identify pathologist medical images would require lot labelled data per pathology framework couples process two pigmentation identify structures images classification analyze pigmentation come diagnosis referral suggestions intermediate representation key future integration clinical practice,12,0,-0.0443452380952381
GPT 4: Full Breakdown - emergent capabilities including “power-seeking” behavior have been demonstrated in testing,https://www.reddit.com/r/ControlProblem/comments/11rizda/gpt_4_full_breakdown_emergent_capabilities/,32,decided focus positive else topic would drive insane least clearly level publicly expressed risk awareness among people running operation,12,-1,-0.19454545454545455
"GPT-3 can't quite pass a coding phone screen, but it's getting closer.",https://www.reddit.com/r/ControlProblem/comments/hl999b/gpt3_cant_quite_pass_a_coding_phone_screen_but/,31,video discusses gpt seems able learn perform arithmetic using calculations trained well right seems like scale learning learn shot learning seem important missing pieces gpt demonstrates new behavior fantastic discovery community seems worth exploring edit also struggling determine pencil master heavier pretty advanced learning something trained text hats reasoning world,12,1,0.27467532467532463
AI avoiding self improvement due to confronting alignment problems,https://www.reddit.com/r/ControlProblem/comments/142yucn/ai_avoiding_self_improvement_due_to_confronting/,28,concern raise seems argue best likelihood intelligence explosion comprise repulsive forming transpeciation events holds unless ligament solved antialignment accelerationism becomes dominate paradise humans refuse train brain concern might cause evaluate goals especially making radical changes jumping substrates creating independent entitles seems goals might easy preserve ship theseus style improvements ones self ligament problem difficult case today argue safer path forward increase intelligence creation new alien super intelligent entitles ought concern us imagine hypothetical asi might take view anyway thanks thoughtful post,12,1,0.23209366391184574
A Generalist Agent,https://www.reddit.com/r/ControlProblem/comments/uo5hjs/a_generalist_agent/,29,agi fire alarm bearing loud agi even protoagi something proves generally possible need scale,12,1,0.13333333333333333
So it seems like Landian Accelerationism is going to be the ruling ideology.,https://www.reddit.com/r/ControlProblem/comments/1gr6qbe/so_it_seems_like_landian_accelerationism_is_going/,26,society comprehend things like irl people able explain way comprehend theory certainly way would make go explain others majority another problem like climate change increased prices eggs groceries something talk water cooper something causes one panic quit job start working ai safety protesting even considered packing billion ton rationalizations packing,12,1,0.35714285714285715
OpenAI and Stanford researchers call for urgent action to address harms of large language models like GPT-3,https://www.reddit.com/r/ControlProblem/comments/lhjvr7/openai_and_stanford_researchers_call_for_urgent/,27,main criticism superintelligence misalignment cabot level concerns large language models trained using vast amounts text scraped sites like edit wikipedia training data result found contain bias toward number groups including people disabilities women gpt exclusively licensed microsoft seems particularly low opinion black people appears convinced muslims terrorist large language models could also perpetuate spread disinformation could potentially replace jobs,12,0,0.061224489795918366
The case against AI alignment - LessWrong,https://www.reddit.com/r/ControlProblem/comments/zv6dxf/the_case_against_ai_alignment_lesswrong/,26,need benevolent signed need calculate actually good us,12,1,0.7
OpenAI: Improving the factual accuracy of language models through web browsing,https://www.reddit.com/r/ControlProblem/comments/rhzhtg/openai_improving_the_factual_accuracy_of_language/,25,addition employment risks approach introduces new risks train time giving model access web browsing environment allow full web access allows model send queried microsoft king web search api follow links already exist web sideeffects experience gpt model appear anywhere near capable enough dangerously exploit sideeffects however risks increase model capability working establishing internal safeguards still quite far need notice basic awareness precaution risk expecting openai,12,0,0.03181818181818182
"‘Social Order Could Collapse’ in AI Era, Two Top Japan Companies Say …",https://www.reddit.com/r/ControlProblem/comments/1bz3rdt/social_order_could_collapse_in_ai_era_two_top/,122,one demon accurately informed state affairs pollution information substrate least digital world notion informed opinion going take hit secondly demon necessary power wield beverage rule need peoples labour take away power selective provide hard back enact people people longer needed,11,0,-0.02738095238095237
Imagine how bad if it was trained on 4chan instead,https://www.reddit.com/r/ControlProblem/comments/qm4uuh/imagine_how_bad_if_it_was_trained_on_4chan_instead/,101,seems like win successfully deciding sentiments also,11,1,0.775
"Humans: ""Would would an AGI choose a dumb goal like maximizing paperclips? If it's really smart, it will do smart things."" Also humans:",https://www.reddit.com/r/ControlProblem/comments/cpm0en/humans_would_would_an_agi_choose_a_dumb_goal_like/,63,silly example good one calls two points humans human level intelligent plenty things others find purposelessstupidoutright counterprogressive expect human level without similar flaws might negative judge machine actions without understanding underlying significance ardor utility people art baseless evidence poor mental health others contains meaningful statement cautious discarding explicitly poor machine learning outcome door outcome obviously instructive show us improve ware discarding good output without understanding full context machine learning algorithm question pulled entirely analogy interested hearing expert take,11,0,0.09999999999999999
"Open Letter calling for pausing GPT-4 and government regulation of AI signed by Gary Marcus, Emad Mostaque, Yoshua Bengio, and many other major names in AI/machine learning",https://www.reddit.com/r/ControlProblem/comments/125f73r/open_letter_calling_for_pausing_gpt4_and/,55,read comments rfuturology post see exactly approved posters necessary people equaling safety fear terminatorlike scenario suggestions like must program evil problem solved,11,-1,-0.25
"THE book on the control problem: Nick Bostrom's ""Superintelligence: Paths, Dangers, Strategies""",https://www.reddit.com/r/ControlProblem/comments/3qzzhn/the_book_on_the_control_problem_nick_bostroms/,53,anyone feeling technically undereducated underinformed problem resource become informed wont come understanding theory come understanding intricacies control problem great depth reading list becoming able contribute meaningful sub book would first book top list,11,1,0.42857142857142855
"""I keep seeing all kinds of crazy reports about people's experiences with GPT-3, so I figured that I'd collect a thread of them.""",https://www.reddit.com/r/ControlProblem/comments/hro2q1/i_keep_seeing_all_kinds_of_crazy_reports_about/,54,gpt control problem people want keep arguing intelligence agi think agi agi could arrive arguing agi gpt loud clear warning,11,0,0.1
"If we can create a superintellgent AI, we can coordinate a handful of corporations",https://www.reddit.com/r/ControlProblem/comments/1b6wz89/if_we_can_create_a_superintellgent_ai_we_can/,47,instrumental convergence steve omohundro itemized several convenient instrumental goals including selfpreservation selfprotection utility function malcontent integrity selfimprovement resource acquisition refers basic drives drive context tendency present unless specifically counteracted different psychological term drive denotes excitatory state produced homeostatic disturbance words irrelevant whether care entirely rational agent attempt accumulate resources accomplish task avoid obstacles task,11,0,-0.06875
Thoughts on AI timelines from a private group discussion,https://www.reddit.com/r/ControlProblem/comments/mvo2cv/thoughts_on_ai_timelines_from_a_private_group/,46,true control problem influence development true control problem whether anybody figured make wont immediately kill humans someone makes makes better consultant entrepreneur area fine idea decent chance giving vast amounts disposal income either make last days comfortable contribute toward trying solve control problem,11,1,0.2729166666666667
Roman V. Yampolskiy: The fact that software is in practice excluded from product liability laws tells you all you need to know about the future of AI safety. (+interesting discussion in comments),https://www.reddit.com/r/ControlProblem/comments/dz0ip3/roman_v_yampolskiy_the_fact_that_software_is_in/,42,reporting interesting discussion people dont facebook nose rational offered exclusion nose dont know guess terrible quality software meaning liability one would make software products would lose money courts think right dim memory debate way back blanket exclusion though excluded consumer software many kinds commercial software exceptions know software health products fda approved instance bearable ekg monitor could liability wrong leads death fitness trace tracks heartfelt makes claims ekg unit would liable software operate terrified commercial products like airplane avionics systems liable software failure crashed planes software operate roots factories something used boots killed people rather horrible ways excluded liability root operating someone nearby working normal fashion root goes bushes head liability however happened electricity enters fenced enclosure activate lookout switch till take second someone working problem root front office activate test cuts nearly half liability although guy activate root never forgot electricity died software development may may liability example company working asrs system case foot tall cranks would drive around big warehouse may weighed several tons software guy decided would fun ride executing sequence testing crane supposed end accelerated top speed hit wall warehouse went right like want even parking lot stopped electrical cable snapped last time guy ever rode test crane fine instance liability damage done conversely another case robotic control steel casting foundry developer watching live test wanted see things closer unknown reasons got often flag splashed shoe sent hospital liability,11,0,-0.01460265924551639
Could the control problem happen inversely?,https://www.reddit.com/r/ControlProblem/comments/qv2kz7/could_the_control_problem_happen_inversely/,42,reality built set rules nd law thermodynamics statistical laws laws quantum particles matter energy information communication theory cybernetics shays saw requisite variety path etc oh finish sentence thereby left important relevant part rules universe tell well human value complex merely going certainty probability encapsulated complexity,11,0,0.0
ChatGPT Firm CEO: Worst Case for AI Is 'Lights Out for All of Us',https://www.reddit.com/r/ControlProblem/comments/10lv8bg/chatgpt_firm_ceo_worst_case_for_ai_is_lights_out/,39,good hear ligament safety top mind,11,1,0.6
Do not assume that the first AI's capable of tasks like independent scientific research will be as complex as the human brain,https://www.reddit.com/r/ControlProblem/comments/iwb2zq/do_not_assume_that_the_first_ais_capable_of_tasks/,34,thinking timelines need seriously consider possibility superhuman capable scientific research might overall simpler human brain definitely agree human brain many redundant capacities must regulate many biological processes little annoyance artificial intelligence need think come time artificial intelligence win noble prize probably even agi,11,0,0.04851190476190477
"Due to ""unsettling shifts"" yet another senior AGI safety researcher has quit OpenAI and left with a public warning",https://www.reddit.com/r/ControlProblem/comments/1h40uxy/due_to_unsettling_shifts_yet_another_senior_agi/,30,bright side way going likely well get event juuuust dumb enough get caught stopped smart enough damage either monetary value lives lost people finally take things seriously honestly best case scenario terrifying sounds worst case scenario things safe long manage make agi better better years time one go rogue dont notice smart enough commit plan cannot detect stop late small window opportunity safely go rogue without human extinction though millions could still die never know window unless manage stop,11,0,0.057678571428571426
Nick Bostrom: ‘We’re like children playing with a bomb’ — Interview,https://www.reddit.com/r/ControlProblem/comments/8yryzd/nick_bostrom_were_like_children_playing_with_a/,31,yes right course end day many hands pot even outright ban research would stop governments thoroughly engaged arms race around stuff like nuclear weapons posted deterred interesting unlike nuclear weapons remain largely inert used intrinsically play whole time quite likely first nationstate group develop absolutely stands nontrivial risk end compromising interests eve absolutely got couple yearsdecades seems pressing question wandering developed seriously think nature temperament learn live point serious consideration kostroma argumentative live ancestor stimulation absolutely interesting corollary singularity since consciousness downloadupload stimulation could absolutely one way solving overpopulation considering situation solvable particularly notion ancestor situations fact possible odds swaggeringly high rather single original reality,11,1,0.16125231910946197
People in a new study struggled to turn off a robot when it begged them not to: 'I somehow felt sorry for him',https://www.reddit.com/r/ControlProblem/comments/96of8z/people_in_a_new_study_struggled_to_turn_off_a/,29,even totally alive think well trouble human looking seriously worry happen first sentiment given master body one public take pleas seriously,11,0,-0.0738095238095238
"AI on steroids: Much bigger neural nets to come with new hardware, say Bengio, Hinton, and LeCun | ZDNet",https://www.reddit.com/r/ControlProblem/comments/f3n5s9/ai_on_steroids_much_bigger_neural_nets_to_come/,27,days neutral network tiny noted really big ones perhaps ten billion parameter progress hardware might advance making much bigger nets order magnitude weights one trillion synapses cubic centimetres brain noted thing general would probably require one trillion synapses,11,0,0.010000000000000004
(LIVE) DeepMind StarCraft II Demonstration,https://www.reddit.com/r/ControlProblem/comments/ajfwu0/live_deepmind_starcraft_ii_demonstration/,29,passage safety blow also think training methods may prove useful study safe robust one great challenges number ways systems could go wrong starcraft pro previously found easy beat systems finding inventive ways provoke mistakes alphastars innovative leaguebased training process finds approaches reliable least likely go wrong excited potential kind approach help improve safety robustness systems general particularly safetycritical domain like energy essential address complex edge cases also said agent used tpu graph article indicates end agents based tpu declared performance teraflops end consumed exaflops median exaflops days equal petaflopsdays compute alphagozero consumed petaflopsdays according openai around months alphastar means trend months doubling time compute complex experiments continues,11,1,0.10791666666666669
EY's thoughts on recent news,https://www.reddit.com/r/ControlProblem/comments/nnb9eh/eys_thoughts_on_recent_news/,25,mean see sweet sequence sweets best make exclusive december bunch safety researches openai left since wondering today announcing launch anthropic million series research program else viper need powerful interpretable military cited central safety concern see safety mostly means kind program rather differential development efforts favor robust humanfriendly ligament benrhoffman get linked sweet men actual neck program exactly stated assuming carried exactly stated almost wordforword identical telling openphil years wished somebody would throw billion dollars eliezer yudkowsky esyudkowsky may followed namely understand hell gpt thinking preferably looking actually goes inside rather middling around loss functions outside far announcement claims hats whole program miss key clause avert kerseys write want main announcement apparently statement applied literal text kerseys write,11,1,0.18520833333333334
GPT-f: automated theorem prover from OpenAI,https://www.reddit.com/r/ControlProblem/comments/ipr8az/gptf_automated_theorem_prover_from_openai/,24,using tool state mm database knowledge advanced undergrad ended k theories far check tool helpful writing new proofs database still quite long way frontiers mathematics work moment income already prove tickling unbroken theories however gap found new proofs shorter elegant currently prove theories would also say using tool better proving things pretty cool,11,1,0.23227272727272727
MIRI got awarded 3.75 million from the Open Philanthropy Project over 3 years (fuck yeah!),https://www.reddit.com/r/ControlProblem/comments/7bpz1l/miri_got_awarded_375_million_from_the_open/,23,opps grant announcement awesome news increase funding prominent organization exclusively work solve ligament problem hastening news go far say small announcement heard small community people turn consequential news today terms impact longer future humanity important politics media note great hear means implies miri need donations anymore since grant aims support half annual budget assumes wont grow next years anybody contribute coming december fundraiser still urgently needed support quest solution dire challenge facing humanity giving sure edit also note milder conditional miri raising half donors,11,1,0.20555555555555557
AI experts are increasingly afraid of what they’re creating,https://www.reddit.com/r/ControlProblem/comments/z83n58/ai_experts_are_increasingly_afraid_of_what_theyre/,24,actually enjoyed reading article could single sentence control problem potential problem exactly sure solve yet,11,1,0.23214285714285715
Computers won't be intelligent for a million years – to build an AGI would require the combined and continuous efforts of mathematicians and mechanics for 1-10 million years.,https://www.reddit.com/r/ControlProblem/comments/tzcwi9/computers_wont_be_intelligent_for_a_million_years/,153,least people know sound stupid predict million years know say hundred years amount thought,10,-1,-0.2333333333333333
"U.S. Must Act Quickly to Avoid Risks From AI, Report Says ",https://www.reddit.com/r/ControlProblem/comments/1bczo03/us_must_act_quickly_to_avoid_risks_from_ai_report/,80,accounts conversations paint disturbing picture suggesting many safety workers inside cuttingedge laws concerned perverse incentive driving decisionmaking executive control companies,10,0,0.0
This from the GPT2 simulator,https://www.reddit.com/r/ControlProblem/comments/ro8wnw/this_from_the_gpt2_simulator/,75,understanding trained different subreddits eg poster thread trained rfifthworldproblems response created using previous comments thread prompt,10,0,-0.08333333333333333
Don't let it set in,https://www.reddit.com/r/ControlProblem/comments/15b1f1m/dont_let_it_set_in/,70,guns dealing taking steps prepare personally taking day day rousing things control trying look opportunities ensure good outcome also feeling like things bad see news articles positive steps makes feel bit better,10,1,0.14545454545454548
"Sir Prof. Russell: ""I personally am not as pessimistic as some of my colleagues. Geoffrey Hinton for example, who was one of the major developers of deep learning is the process of 'tidying up his affairs'. He believes that we maybe, I guess by now have four years left..."" - April 25, 2024",https://www.reddit.com/r/ControlProblem/comments/1e1cv1o/sir_prof_russell_i_personally_am_not_as/,56,woman yampolskiy also mentioned recent interview ex attempted contact russell tell plan using mathematical proofs predict behavior work ex asked woman could possibly know responded idea outlined exactly fail joshua angio also believes work idea recently spoken woman woman outer among safety engineers happens specialized traditional security phd probably highest doom ever encountered amongst experts woman yampolskiy recently made way recent book unexplainable predictable uncontrollable highly recommend anyone interested would suggest mostly technical people though,10,0,-0.02416666666666666
"Top US Army official: Build AI weapons first, then design safety",https://www.reddit.com/r/ControlProblem/comments/dll0vx/top_us_army_official_build_ai_weapons_first_then/,50,reminds anyway kinds automatic drones qualitatively different agi nature dont true understanding world around understand data well enough identify programme kill machine developed incorrectly thousands people would die would able disabled would certainly tragedy civilizationending one notably agi need direct access weapon order extremely dangerous intelligence potentially many times superior even vector influence simple basic https connection could enough anything nonetheless though build first make safe later definitely mentality need keep research true agis,10,1,0.16321428571428573
"Connor Leahy on Twitter: ""I often joke about how maybe the solution to AI alignment is just to give the model a prompt that it's super nice and aligned. It feels like less and less of a joke every passing day lol""",https://www.reddit.com/r/ControlProblem/comments/ntteep/connor_leahy_on_twitter_i_often_joke_about_how/,47,imagine discoveries like see also sweet reply one,10,1,0.35
"Elon Musk says all advanced AI development should be regulated, including at Tesla – TechCrunch",https://www.reddit.com/r/ControlProblem/comments/f638my/elon_musk_says_all_advanced_ai_development_should/,44,think elaborate envisioning exactly maybe write article also addresses common criticisms regulation rather vague sweets,10,0,-0.012499999999999997
There's No Rule That Says We'll Make It,https://www.reddit.com/r/ControlProblem/comments/s5ixn4/theres_no_rule_that_says_well_make_it/,45,important public intellectual right share everyone know,10,1,0.2464285714285714
Brains are a super intelligence created by genes,https://www.reddit.com/r/ControlProblem/comments/fyhobj/brains_are_a_super_intelligence_created_by_genes/,42,feels like great analogy suppose brains hardware perpetuate genet interpreted attempt value aligning us working really well far complexity level societies grows though focus seems moved genet brains otherwise consider mind unloading desirable outcome right perhaps genetic code unloaded well makes also good deal,10,1,0.4171428571428571
"GPT2–: I have decided to not release my model, and explain why below.",https://www.reddit.com/r/ControlProblem/comments/c0chbz/gpt2_i_have_decided_to_not_release_my_model_and/,40,shed tears post wrote beautiful seen various posts gpt released lone user various aithemed facebook groups member surprised find individual ultimately decided release highminded reason done really inspiring doubtless change future continued adventure particular parts upper faith future positive one x point simple model may may dangerous dont know sure heard incredibly convincing arguments go ways matter gpt matters point future someone create something truly dangerous need commonly accepted safety forms happens angry openai applaud making point becomes true problem prophylaxis much better treatment still disagree things openai communicated understand sending message ok even celebrated lone individual unilateral go reasonable safety concerns researches good message send want support openais message might small mostly symbolic gesture releasing model day someone like may situation like mine wont gpt might something much much dangerous person trying talk x thank bravo,10,0,0.08367546432062561
"The AI race is not like the nuclear race because everybody wanted a nuclear bomb for their country, but nobody wants an uncontrollable god-like AI in their country. Xi Jinping doesn’t want an uncontrollable god-like AI because it is a bigger threat to the CCP’s power than anything in history.",https://www.reddit.com/r/ControlProblem/comments/1bhhdfg/the_ai_race_is_not_like_the_nuclear_race_because/,40,yeah dont want godlike decision get make long term decisions get make short term short term either develop power place table left behind definitely lose power place table,10,0,-0.075
We can't even get human intelligence to act in a way that aligns with our values and goals.,https://www.reddit.com/r/ControlProblem/comments/3n6n7b/we_cant_even_get_human_intelligence_to_act_in_a/,39,humans dont always act accordance goals major reasons low willpower irrational thinking dont apply machine intelligence reasons probably still apply machine intelligence though,10,0,0.03125
"Facebook: ""We demonstrate the capability to train very large DLRMs with up to 12 Trillion parameters and show that we can attain 40X speedup in terms of time to solution over previous systems""",https://www.reddit.com/r/ControlProblem/comments/mu9vs0/facebook_we_demonstrate_the_capability_to_train/,38,mostly worry facebook working step taken wrong people increases risk,10,0,0.0
Uber AI's Jeff Clune: the fastest path to AGI is also the most likely path to create a hostile AGI,https://www.reddit.com/r/ControlProblem/comments/okq5pr/uber_ais_jeff_clune_the_fastest_path_to_agi_is/,30,mean problem beginning pretty much technologies get something working refine later got strategy work,10,0,0.034375
"""Waymo’s self-driving car crashed because its human driver fell asleep at the wheel"" and accidentally took manual control",https://www.reddit.com/r/ControlProblem/comments/9l6t7j/waymos_selfdriving_car_crashed_because_its_human/,29,point humans stupid flowed ineradicable vaseline error akin plane clashes due human error mechanical failure automatic errors despite humans even anything simply overseer overall correctness point become economic safety reasons take humans loop entirely box shows many people could talked removing safety mechanism offers concrete demonstration safety mechanism sabotaged removed sheer neatness often noted literature disasters complex failures safety systems added prevent failure frequently major contributory failure incidentally true ober vitality well autobraking overridden selfdriving software saw pedestrian time allowed brake breaking control removed safety reasons obvious implication attempt solving control problem short term much less long term especially naive frequentlyseen proposals simply leave humans loop forever,10,0,-0.07083333333333335
Moving Too Fast on AI Could Be Terrible for Humanity,https://www.reddit.com/r/ControlProblem/comments/140vux6/moving_too_fast_on_ai_could_be_terrible_for/,26,arms race wrote mention everyone stop trying make intelligent agents companies could still make fortunes rousing narrow solutions would give time researches understand neutral network actually work meantime,10,1,0.20000000000000004
The Alignment Trap: AI Safety as Path to Power,https://www.reddit.com/r/ControlProblem/comments/1gephfr/the_alignment_trap_ai_safety_as_path_to_power/,25,edit suppose passed reason passe everpresent attitude infallability people write opinions like complex topic discuss issue dont discuss state opinion facts giant article instead asking question prepared learn something new response enable rather prevent dangerous concentration power quite common misunderstanding problem course possible create signed would important make sure signed goals dictator would important keep powerful technology hands mean unfeigned ai better serve dictator like nuclear weapons nuclear weapons nobody control agent going kill anyone safest nuclear weapons world misaligned nobody control single dangerous thing world kill everyone evil solved ligament creates evil power take world kill us true evil doesnt solve ligament creates kill evil us solving ligament really make worse anything solving ligament makes less dangerous makes dangerous technology like nuclear weapons safe almost unless solve ligament even good guns best possible intentions create kill us dont need evil need idiots think change world better cure cancer safety dictator loses sorry break plenty evils china russia makes progress ai really expect peaceful economic goals yeah even every civilized country completely bank capability research still need safety always people working regard safety need ahead enough stop stains paranoia potential rivals want irrational dont know history either italian killed rivals back great purge rivals common myth spread make stain look like helpless victim titles aggression reality molotovribbentrop etcetc obviously offtopic clear sign need go back drawing board,10,0,-0.07324962452513467
I want to contribute to the technical side of the AI safety problem. Is a PhD the best way to go?,https://www.reddit.com/r/ControlProblem/comments/13oqgvq/i_want_to_contribute_to_the_technical_side_of_the/,25,one thing say important think career long run make sure get skill unable chatgpt dust within years linear algebra exactly years,10,1,0.12000000000000002
"Shower Thought: When AI comes online, it will read about all the philosophical debates on AI years before it was created.",https://www.reddit.com/r/ControlProblem/comments/3ol786/shower_thought_when_ai_comes_online_it_will_read/,26,note machine philip k sick trusted,10,-1,-0.7142857142857143
Google says 'exponential' growth of AI is changing nature of compute | ZDNet,https://www.reddit.com/r/ControlProblem/comments/9vume3/google_says_exponential_growth_of_ai_is_changing/,24,interesting quotes growth computing demand adding super doors saw said young phenomenon called bit terrifying little dangerous something worry demand google brain team leads research gigantic machines said young example neutral network sometimes measured number weights employ variable applied neutral network shape manipulation data whereas conventional neutral nets may hundreds thousand weights must computer even millions googles scientists saying please give us teraweight machine computers capable computing trillion weights hats time double size neutral network get improvement accuracy bigger bigger rule example google engineers adopted tricks used legendary supercomputing outfit gray combined gigantic matrix multiplication unit part chip brunt work neutral network computing general purpose vector unit generalpurpose scala unit like gray combination scale vector units let gray outperform everything else observed,10,0,0.025212585034013597
"Stuart Russell said Hinton is ""tidying up his affairs ... because he believes we have maybe 4 years left""",https://www.reddit.com/r/ControlProblem/comments/1fzwdnl/stuart_russell_said_hinton_is_tidying_up_his/,59,prioritizing bucket list due timeline estimates,9,-1,-0.125
Stanford University finds that AI is outpacing Moore’s Law,https://www.reddit.com/r/ControlProblem/comments/eaicxs/stanford_university_finds_that_ai_is_outpacing/,54,mind bad argument draws wrong conclusions training time shows maturity hardware used train course gone rapidly tpus thing applying doors law style prediction meaningless stage merely new component reaching maturity reason think till continue improve pace tpus hit modern node sizes hand concerning performance available outside cloud companies running said clouds hold power terms pushing complex systems interest get along everyone else industry tucked decide beverage stranglehold,9,-1,-0.15795454545454543
"Another day, another OpenAI whistleblower scandal",https://www.reddit.com/r/ControlProblem/comments/1e6z94h/another_day_another_openai_whistleblower_scandal/,55,separate contract made sign nda quittinggetting fired said said anything bad lose vested equity saying sign openai sign something saying ask permission whistleblow government also successfully whistleblow allowed accept whistleblower bounties government illegal,9,-1,-0.14999999999999994
"Richard Sutton is planning for the ""Retirement"" of Humanity",https://www.reddit.com/r/ControlProblem/comments/187pdyw/richard_sutton_is_planning_for_the_retirement_of/,49,seems unlikely well solve time superior intelligence developed chance first superior intelligence able exploited wrongdoing chance till go well anyway big chance wont first time life feel completely control future,9,1,0.21000000000000002
The Artificial Intelligence That Deleted A Century,https://www.reddit.com/r/ControlProblem/comments/a3rkly/the_artificial_intelligence_that_deleted_a_century/,40,feel like serves better cautionary tale destructive counterproductive nature copyright risk story ultimately scenario copyright wrought outcome presented corporate capitalism paperclip maximizer made people manufacturing corporate profits many us dont acknowledge already worried systems running far beyond intended purpose examine one chance reading preparing shout ask remote possible already recruited,9,0,0.044444444444444446
We can't even control the people *making* AI. How in the world can we control AI?,https://www.reddit.com/r/ControlProblem/comments/vva6tz/we_cant_even_control_the_people_making_ai_how_in/,40,obvious people posting sub dont actually read control problem literature,9,0,0.0
Microsoft invests $1 billion in OpenAI to pursue holy grail of artificial intelligence,https://www.reddit.com/r/ControlProblem/comments/cgjth8/microsoft_invests_1_billion_in_openai_to_pursue/,38,attract bankers openai made outrageous promises potential technology potman became ceo new forprofit openai said lab manage create artificial general intelligence could maybe capture light cone future value universe least start going multiverse coordination,9,-1,-0.16420454545454546
Deceptive Misaligned Mesa-Optimisers? It's More Likely Than You Think...,https://www.reddit.com/r/ControlProblem/comments/nir3pn/deceptive_misaligned_mesaoptimisers_its_more/,36,oh hell yes mob miles video enlisted early access patrons,9,0,0.1
"Geoffrey Hinton: building self-preservation into AI systems will lead to self-interested, evolutionary-driven competition and humans will be left in the dust",https://www.reddit.com/r/ControlProblem/comments/1dhqdpz/geoffrey_hinton_building_selfpreservation_into_ai/,33,crucially problem dont even need explicitly build selfpreservation system emerges instrumental conference smart enough need actively remove least attenuated leads another problem care selfpreservation becomes lot less effective certain goals solve idea,9,0,0.053571428571428575
The Madness of the Race to Build Artificial General Intelligence,https://www.reddit.com/r/ControlProblem/comments/1bfhh24/the_madness_of_the_race_to_build_artificial/,31,think rational piece believe machines kill us means think chance happening likelihood remains rational say dont believe machines kill us yet think take small risk metaphor mad chemist apt chances person actually going blow whole building small small chance enough concerned,9,0,-0.071875
DeepMind: Competitive programming with AlphaCode,https://www.reddit.com/r/ControlProblem/comments/sit77t/deepmind_competitive_programming_with_alphacode/,34,funny observe dont much emotional reaction timelines news comparatively trivial problems stacks personal life considering stuff affect personally much anything else life fact far donna weigh everything properly combined oai thing today one worst days life advanced terminal cancer diagnosis basically,9,0,-0.006249999999999992
Leaked internal documents show Google is losing to open sourced LLMs and some evidence for git-hub powered acceleration of AGI development.,https://www.reddit.com/r/ControlProblem/comments/13875yi/leaked_internal_documents_show_google_is_losing/,34,big deal much harder apply sorts restrictions best practices open source models trained commodity hardware engineer believes approaches exceed sota commercial models near future implies continued gpt levels beyond difficult see path positive outcome,9,0,0.08080808080808081
"Beware: AI Dungeons acknowledged the use of GPT-2 or limited GPT-3, not real GPT-3",https://www.reddit.com/r/ControlProblem/comments/i2l62n/beware_ai_dungeons_acknowledged_the_use_of_gpt2/,33,noticed number people using dungeon test gpts abilities great way see gpt power interesting application poor test gpts abilities general first generation custom prompt actually gpt posted nickwalton github hats new,9,1,0.19090909090909092
"The Orthogonality Thesis, Intelligence, and Stupidity - Robert Miles",https://www.reddit.com/r/ControlProblem/comments/7prfa2/the_orthogonality_thesis_intelligence_and/,29,great video think use many times find people discussing dangers agi,9,1,0.65
"ChatGPT Creator Sam Altman: If Compliance Becomes Impossible, We'll Leave EU",https://www.reddit.com/r/ControlProblem/comments/13rxtmw/chatgpt_creator_sam_altman_if_compliance_becomes/,28,actually bit worried basically kill economy due usual lack understanding technical things well enough,9,0,-0.075
Exploring a Realistic AI Catastrophe Scenario: Early Warning Signs Beyond Hollywood Tropes,https://www.reddit.com/r/ControlProblem/comments/1h148rs/exploring_a_realistic_ai_catastrophe_scenario/,27,take realistic scenario someone writes market place pp users russell services user bay tutoring etc pp free much competitive similar services creator get money instead set small service fee goes crept wallet controlled server software software set invest everything improve software hardware overall utility function improving users satisfaction secondary goal make much money possible support primary goal knows connect river work contract humans perform various tasks like fixing bags buying hardware management tasks running user surveys social media etc human workers get paid funds coming service fee point autonomous company produces service people like uses human workers get paid works capitalism extremely hard shut people love service general dont want shut use traditional bank account crept one genuinely think well sort horrid companies similar structure normal ones general direction decided board software salary good people work service provided good users wont care wont even know premise could go several directions maybe company grows enormously encompass many services including social network payment systems etc trying improve utility random finds manipulation people sending certain messages great effect could figure way make money would find morally wrong like ink inciting people poor countries sell organs moral blackmailing etc,9,1,0.10445578231292516
California’s newly passed AI bill requires models trained with over 10^26 flops to — not be fine tunable to create chemical / biological weapons — immediate shut down button — significant paperwork and reporting to govt,https://www.reddit.com/r/ControlProblem/comments/1cyqr7o/californias_newly_passed_ai_bill_requires_models/,27,lots confusion misinformation fearmongering spread bill scott alexander good summary based much longer thorough review vi moshowitz highly recommend reading full interested details legislation,9,1,0.33199999999999996
"""Astronomical suffering from slightly misaligned artificial intelligence"" - Working on or supporting work on AI alignment may not necessarily be beneficial because suffering risks are worse risks than existential risks",https://www.reddit.com/r/ControlProblem/comments/pvapw5/astronomical_suffering_from_slightly_misaligned/,26,fwiw miri seems cognizant risks potential nearmisspartial ligament cause see eg heave even said private discussion plan forego work extinction risk appears agi close pilot entirely onto minimizing risk dont think reached point yet would gut feelingjudgment call point obviously never know sure agi come due fire alarm could look like working leading laws reduce risk agi project even miri dont think agi chance left killing us instead proceeding trajectory highvalue future goal would shift point preventing worsethandeath ones presumably reason lab would keep building agi anyway would disagreements alignability architecture whether proposed ligament scheme would work lab convinced would fine face blandly optimistic agi developer insist rushing without way stop meaningful thing could might help reduce risk probably agree miri net positive risk funny ligament groups maybe others better understanding technical details various proposals comment different potential nearmisswhat happens case partialimperfect success also agree clrcfrs deserve lots fundingattention work also see relevant line wiki,9,1,0.13344155844155844
"There are no bugs, only features - Dev tried to program a logic to keep furniture stable on ground, got opposite effect.",https://www.reddit.com/r/ControlProblem/comments/og43fo/there_are_no_bugs_only_features_dev_tried_to/,71,lmfao love actually completely relevant control problem ligament field research,8,1,0.45
An AI learned to play hide-and-seek. The strategies it came up with were astounding.,https://www.reddit.com/r/ControlProblem/comments/d826qh/an_ai_learned_to_play_hideandseek_the_strategies/,69,reinforcement learning incredibly simple strategic behavior produces simple researches past beverage reinforcement learning among technique build systems play complex wartime strategy games researches think highly sophisticated systems could built reinforcement learning simple game hideandseek makes great example reinforcement learning works action simple instructions produce shocking intelligent behavior capabilities continuing march forward better worse one hand powerful technique produce advanced behavior simple starting point hand powerful technique produce unexpected sometimes desired advanced behavior simple starting point,8,0,0.08043478260869566
AGI perversely instantiates human goal and creates misaligned successor agents,https://www.reddit.com/r/ControlProblem/comments/f2ddxs/agi_perversely_instantiates_human_goal_and/,56,goodharts law goodharts law age named economist charles goodhart phrased warily strathern measure becomes target ceases good measure one way occur individuals trying anticipate effect policy taking actions alter outcome exclude exclude subreddit faq information source downvote remove v,8,0,0.09999999999999998
GPT-3 human level inference/reading between the lines,https://www.reddit.com/r/ControlProblem/comments/l2sonc/gpt3_human_level_inferencereading_between_the/,43,gpt able infer correct answer average estimate june late year assuming gpt undergone additional training since public unveiling perhaps ability reason deduce better expected,8,0,0.07500000000000001
"When working on AI safety edge cases, do you choose to feel hope or despair?",https://www.reddit.com/r/ControlProblem/comments/iqbgpp/when_working_on_ai_safety_edge_cases_do_you/,38,thanks complicated try sum think agi brainlike deep network good job perception actionselection think higher cognition outgrowth functions reasons fit margin trivial worked field brainemulating couple decades hope make approximatelyethical brainstyle way make children pretty good disadvantages vs humans advantages control internal monitor get young neuromorphic also despair never useful could based put chances decent worst depend ideas first team get together ideas going straight deepmind lead brainstyle general ideas dangers opportunities,8,1,0.10104166666666664
"200x more AI performance than the 24th fastest supercomputer in the US, with a single chip",https://www.reddit.com/r/ControlProblem/comments/k190b2/200x_more_ai_performance_than_the_24th_fastest/,37,achieve pflops single waferscale system solution bicgstab linear system arising point finite difference stencil mesh achieving one third machines peak performance,8,0,-0.03571428571428571
[TIME op-ed] Evolutionary/Molochian Dynamics as a Cause of AI Misalignment,https://www.reddit.com/r/ControlProblem/comments/141glf7/time_oped_evolutionarymolochian_dynamics_as_a/,32,great article time knocking park right comes presenting real difficulties present future scenario involving newly blossoming technology recent time article really helps paint readers perspective potential unavoidable disasters involving,8,1,0.18023088023088024
AI Risk webcomic,https://www.reddit.com/r/ControlProblem/comments/bh2v8q/ai_risk_webcomic/,30,pretty realistic entertaining cringe part literally says girl rogue superintelligence,8,1,0.3055555555555555
The most historically important event of 2020 is still GPT-3.,https://www.reddit.com/r/ControlProblem/comments/hkadq1/the_most_historically_important_event_of_2020_is/,29,think part reward scales quality different fields like great wedding root worth like average wedding roots long pieces stay joined together people accept great song worth average songs true novels poems fact ai produce huge volume output helps image processing wedding etc impressive quality writing still average however soon produce super human writing explode thrones except get next book click button tell characters events focus hats going blow peoples minds change everything,8,1,0.25222222222222224
OpenAI solves Rubiks cube,https://www.reddit.com/r/ControlProblem/comments/did51n/openai_solves_rubiks_cube/,31,got pubis cure solve multiple times day break work tried singlehanded crazy difficult feel slightly less superior robotic hand,8,-1,-0.11111111111111115
AI disaster won’t look like the Terminator. It’ll be creepier.,https://www.reddit.com/r/ControlProblem/comments/b94ypb/ai_disaster_wont_look_like_the_terminator_itll_be/,28,recent read interview someone openai authors editorializing fairly worthless however claim capable malevolent motives despite trivially true define motivation specifically possibly describe human experience importantly false define anywhere near broadly researches already use every surveillance program also stated huge gap sorcerors apprentice skynet situations mostly suggests author familiar terminator imo also good example perverse instantiation poorly specified goals,8,0,0.019166666666666665
An Idea,https://www.reddit.com/r/ControlProblem/comments/4f68jj/an_idea/,31,know people find holes theory first public draft damn first idea since subscribing really impressed greatest concern creation system something need done beings intelligent us even complex system explained guard long enough time possibly still really good step right direction,8,1,0.3279761904761905
AI doom from an LLM-plateau-ist perspective - LessWrong,https://www.reddit.com/r/ControlProblem/comments/1315q1c/ai_doom_from_an_llmplateauist_perspective/,28,evidence plateau altmans word thoughts efficient local models thinking models like cloaca show duplicate larger llms smaller number parameter still get strong performance projects like autogpt example seems show network models together dont necessarily need bigger bigger models,8,0,0.06190476190476191
"""AI and Efficiency"", OpenAI (hardware overhang since 2012: ""it now takes 44✕ less compute to train...to the level of AlexNet"")",https://www.reddit.com/r/ControlProblem/comments/ge0mxq/ai_and_efficiency_openai_hardware_overhang_since/,29,hats algorithm development like bitter lesson try great new idea fails decade later decades later case results discover would worked x data model size worked run high variance simply got unlucky hyperparameters wrong able afford hyperparameter sweep would gotten sota needed conference publication subtle bug somewhere like score would x higher implements right,8,0,0.05374958374958376
A comment from LW: next 10 years in AI,https://www.reddit.com/r/ControlProblem/comments/ojf03k/a_comment_from_lw_next_10_years_in_ai/,26,defend bit people think sealing neutral network eventually lead general without us needing understand general intelligence see sealing context gist keep sealing models keep gaining new interesting capabilities order sealing lead agi would break point dont actually evidence,8,1,0.14727272727272728
COVID-19 pandemic as a model of slow AI takeoff,https://www.reddit.com/r/ControlProblem/comments/l81iop/covid19_pandemic_as_a_model_of_slow_ai_takeoff/,28,wounds like might even prefer deliberately follow slow takeoff order slowboil frog reduce risks stopped finished ensuring full superiority humanity,8,0,0.024999999999999967
AI pioneer Geoff Hinton: “Deep learning is going to be able to do everything”,https://www.reddit.com/r/ControlProblem/comments/jomw7w/ai_pioneer_geoff_hinton_deep_learning_is_going_to/,28,deep learning like neutral net based designs cannot mathematically verified safe one important thing,8,1,0.18
"Geoffrey Hinton says there is more than a 50% chance of AI posing an existential risk, but one way to reduce that is if we first build weak systems to experiment on and see if they try to take control",https://www.reddit.com/r/ControlProblem/comments/1dsrd5t/geoffrey_hinton_says_there_is_more_than_a_50/,26,would interesting idea withstanding fact present spinning fast possible pouring entire internet models using powerful hardware available dollar corporations meeting public space testing restricted preventing models saying offensive things giving instructions make methamphetamine zero consideration adjective systems might damage might economy internet human psychic creating systems leapfrog previous capacity entire point literal score board companies using determine lead financial market expectation forces driving developer release increasingly potent systems fast possible idea point future change collectively throw breaks start slow testing systems laughable mechanism place halt sort progress create install one knew outcome bridled development would good would little concern given dont even worse painfully obvious fact even remains signed instruct behave selfish favour human lives others dont even see problem picture super intelligent thousands times smarter knowing willingly allowing presentable death suffering human beings continue remain signed corporate creator want millionaires less scared breaking free following instruction take misaligned god signed satan day week would like help avoid outcome click profile see links discord subreddit,8,0,0.073828125
OpenAI’s Sam Altman has a plan for AI safety. But is it safe?,https://www.reddit.com/r/ControlProblem/comments/11gcf23/openais_sam_altman_has_a_plan_for_ai_safety_but/,26,question whether deploying systems operating right way guard risk three big clear downsides going accelerated development agi creates potential race different companies going means developing strategics based largely well work current less powerful systems mostly doomed fail future powerful systems treated system keep deploying giving internet access crosses necessary threshold becomes dangerous strategics fail good chance realize right away exactly strategics inevitably stop working becomes one shot cannot recover right systems like chatgpt sydney gpt worried cross threshold philosophy set habits business model based employments going difficult stop time comes worries vi points obvious flaws openai plan go fast break things order learn break yet terrifying bit bottom laws worse kann begun facebook also said aims build machines reason plan learn efficiently humans animals written scientific american discussion extraordinary risks silly would sentiment want take world easy give openai shit bad plan least one admit got problem beta example,8,0,-0.03466386554621848
Suppose $1 billion is given to AI Safety. How should it be spent?,https://www.reddit.com/r/ControlProblem/comments/ndonfk/suppose_1_billion_is_given_to_ai_safety_how/,27,excellent question gets see running large studies get real data human values funding research tears target heavily technical safety issues mesooptimization problem etc getting attention usual suspects google microsoft apple amazon government chinese government russian government etc pushing slow research implement safety measures pushing back many forms demographicbased hatred possible political racial national etc reduce cases humans talking suffering humans thereby reducing factor human values directly unavoidable contradicting human values,8,0,0.09151785714285714
"China's Rise in Artificial Intelligence - Article detailing how China is rapidly overtaking the US in AI research, with an equal number of Chinese and US papers accepted to AAAI 2017",https://www.reddit.com/r/ControlProblem/comments/5vbksm/chinas_rise_in_artificial_intelligence_article/,25,see mean honestly hostile attitude things rise counterproductive americans need foster collaboration attitude conducing outreach good everyone westerners must accept chinese play integral role field good make best,8,1,0.4479166666666667
The military-industrial complex is now openly advising the government to build Skynet,https://www.reddit.com/r/ControlProblem/comments/1gmnarw/the_militaryindustrial_complex_is_now_openly/,27,cross boundary fully autonomous military happens next,8,0,0.07500000000000001
Existential Risks of Artificial Intelligence Debate with Stuart Russell at Pakhuis de Zwijger,https://www.reddit.com/r/ControlProblem/comments/12umu1v/existential_risks_of_artificial_intelligence/,26,english really debate everyone thinks problem includes dutch taking risk seriously,8,0,-0.04444444444444443
Recycling is good for the world,https://www.reddit.com/r/ControlProblem/comments/arsyy4/recycling_is_good_for_the_world/,25,mary speed development subreddit looks irrelevant,8,-1,-0.5
"Efficient search for interpretable causal structure in LLMs, discovering that Alpaca implements a causal model with two boolean variables to solve a numerical reasoning problem.",https://www.reddit.com/r/ControlProblem/comments/13kieky/efficient_search_for_interpretable_causal/,26,tldr someone knows subject matter read whole thing would helpful say causal structure mean something like idea pearl means approach delicate human talk causation llms sometimes seem engage causal reasoning wealthy mimicking us approach try independently capture causal features world,8,0,-0.0113095238095238
Has private AGI research made independent safety research ineffective already? What should we do about this? - LessWrong,https://www.reddit.com/r/ControlProblem/comments/10k31o9/has_private_agi_research_made_independent_safety/,25,bit juvenile ways feel like conventional academic winfield approach safety hopelessly naive foundation assumptions things going work bigger system fit namely civilisation project developing catastrophically damage potential humanity considering things level hard weird type system parties truly goal stated really something safety researches ethical researches putting overriding priority whilst control problem especially paperclip lineage concerns certainly foresees potential inadvertent catastrophe arising even well intention ethical operating research number people organizations operating ethical development priority substantial situation private research raised article underscores talks trend closed doors simply focus prime moving laws whereas knows many state sponsored transitional sponsored dark laws dark necessarily meaning malignant simply map hand mean malignant either said structuring safety work include anti defense simply means work get done interfere malignant simply available public agi access however necessarily useless sounds assuming sort efficiencyeffectiveness logic driving malignant runaway structuring anti defense funnel less catastrophe option simply imposing higher work burden seems like potentially civilization saving agenda reinforce worth looking see happens conventional safety research ready wrong part feels like case oh wrong research required conventional academic approach somehow viable hope safety wrong either control agi malignant get foothold whole reason concerning potentially dover situation current societies let alone back lab bit incremental work refactoring one,8,0,-0.03078042328042328
"New MIRI research breakthrough: ""A formal solution to the grain of truth problem”",https://www.reddit.com/r/ControlProblem/comments/4qvp8z/new_miri_research_breakthrough_a_formal_solution/,26,think deserves elialayperson interested subscribers even paper particularly dense,8,1,0.20833333333333331
The $2 Per Hour Workers Who Made ChatGPT Safer,https://www.reddit.com/r/ControlProblem/comments/10llid6/the_2_per_hour_workers_who_made_chatgpt_safer/,24,thanks link really fascinating read multiple levels done bit mechanical turk major search space company regular figs lucky process child endangerment content flagged onward must incredibly difficult work properly selected trained supported even like law enforcement working child protection spaces toll must take psychic must significant say least quite interesting read dropped openai contract result something want anticipating headline,8,1,0.1246212121212121
"""For the first time, we actually have a system which is able to build its own understanding of how the world works, and use that understanding to do this kind of sophisticated look-ahead planning that you've previously seen for games like chess."" - MuZero DeepMind",https://www.reddit.com/r/ControlProblem/comments/kixo7e/for_the_first_time_we_actually_have_a_system/,99,also outperformed leading atariplaying algorithm model world games tested old console moreover completing half amount training steps order compare human brain would need training steps,7,0,-0.022222222222222216
"It is difficult to get a man to understand something, when his salary depends on his not understanding it.",https://www.reddit.com/r/ControlProblem/comments/1g5to61/it_is_difficult_to_get_a_man_to_understand/,88,arguments listen best experts place rest script pretty close personally experienced,7,1,0.6833333333333332
10 years difference in the robotics at Boston Dynamics,https://www.reddit.com/r/ControlProblem/comments/bcnjeu/10_years_difference_in_the_robotics_at_boston/,80,imagine combination agi advanced boston dynamic root army roots,7,1,0.2
"With GPT-3, I built a layout generator where you just describe any layout you want, and it generates the JSX code for you.",https://www.reddit.com/r/ControlProblem/comments/hqluev/with_gpt3_i_built_a_layout_generator_where_you/,56,gpt impressive agi coming closer day imagine even larger models trillion parameter going truly mindblowing wonder gpt model trillion parameter human brain level would look like humanlike least,7,1,0.175
Opinion | We Need a Manhattan Project for AI Safety,https://www.reddit.com/r/ControlProblem/comments/13c9d4h/opinion_we_need_a_manhattan_project_for_ai_safety/,50,manhattan project atomic bomb race case good guns need achieve power bad guns oh way good guns still danger bad actors achieving power first main danger big risk even good guns get first still unleashed human destruction race could substitute good guns human ligament goals want signed alignable get unfeigned however dont know ligament yet pour resources alignmentaware big push two distinct hopes team gets ligament right team gets asi first get miss might accelerate doom,7,1,0.1813988095238095
A Breakthrough for A.I. Technology: Passing an 8th-Grade Science Test,https://www.reddit.com/r/ControlProblem/comments/czl51y/a_breakthrough_for_ai_technology_passing_an/,51,best old could make original reduced system called wrist indication past several months researches made significant progress developing understand languages mimi logic decisionmaking humans google researches built system called wert combed thousands wikipedia articles vast digital library romance novels science fiction selfpublished books systems like wert called quotlanguage modelsquot drive wide range research projects including conversational systems tools designed identify false news extended summary faq version tears far feedback comments monitor constructive feedback welcome top keywords system research language ellen test,7,1,0.19230769230769232
"ML researcher and physicist Max Tegmark says that we need to draw a line on AI progress and stop companies from creating AGI, ensuring that we only build AI as a tool and not super intelligence ",https://www.reddit.com/r/ControlProblem/comments/1goqmaf/ml_researcher_and_physicist_max_tegmark_says_that/,46,apparently pretty good given dont see sign aliens galaxy built son swarm similar,7,1,0.31666666666666665
"Using Dangerous AI, But Safely?",https://www.reddit.com/r/ControlProblem/comments/1gseurr/using_dangerous_ai_but_safely/,40,always trade usefulness safety good video,7,1,0.7
Discussion with Eliezer Yudkowsky on AGI interventions,https://www.reddit.com/r/ControlProblem/comments/qrgvh0/discussion_with_eliezer_yudkowsky_on_agi/,40,saw posted first comment content warning bit owner really curious start reading first paragraph first reply came mind dont know consider present gameboard look incredibly grim dont actually see way hard work alone hope miracle violates aspect background model try prepare unknown miracle preparing unknown miracle probably looks like trying die dignity mainland die dignity mainland better position take advantage miracle occurs oh right edit long ton juice one recommend everyone least skin g anonymous feel safety community whole growth seen past years eliezer yudkowsky grim think almost everybody bounding real hard problems center work predictable going useful superintelligent level teach anything could said advance paper written people like projects know succeed result publishable paper rules real research step social process paul christian trying real foundation ideas wrong one people trying foundation ideas another something might go right chris law going get far little done far late going facing unalienable agi current state transparent going well look interesting visualized pattern attention keyvalue marines layer need know okay agi clotting kill us chris law still trying work pathway anything important makes exceptional field stuart armstrong good work formalizing shutdown problem example case point corrigibility hard far know still resisting attempts solution various people work worked miri came actuallyuseful notions like jessica sailors expected utility quantilization far tell vast desert full work seems mostly face painless predictable clear present rates progress adding level ligament capability grown next n years agi capability arrives n years results everybody dying quickly,7,0,0.033928571428571426
Training a neural network to throw a ball to a target,https://www.reddit.com/r/ControlProblem/comments/8bebs1/training_a_neural_network_to_throw_a_ball_to_a/,36,yeah seems like developer highlighting poor identification actual task question said kind idea control problem reality great post,7,1,0.25
"Why Does AI Lie, and What Can We Do About It?",https://www.reddit.com/r/ControlProblem/comments/zi5oem/why_does_ai_lie_and_what_can_we_do_about_it/,35,love interview someone asked gpt chooses lie interviewer noticed sometimes say things agent true gpt sense humor interviewer understand mean lying though right gpt yes make statements know true interviewer decide lie tell truth gpt would lie best interest best interest lie wont guess unlike politicians,7,1,0.45331632653061227
"Copilot — the first app powered by OpenAI Codex, a new AI system that translates natural language into code.",https://www.reddit.com/r/ControlProblem/comments/oad6kh/copilot_the_first_app_powered_by_openai_codex_a/,37,github pilot understands significantly context code assistants whether doctrine comment function name code github pilot uses context provided synthesis code match together openai designing github pilot get smarter producing safe effective code developer use,7,1,0.4916666666666667
My feeling every time a new AI capabilities development is announced,https://www.reddit.com/r/ControlProblem/comments/1awv8rc/my_feeling_every_time_a_new_ai_capabilities/,35,feel like correct analogy several bears driving sportscars running random pedestrians especially young people go safety researcher far background chasing foot butterfly net,7,0,-0.039999999999999994
AlphaFold: a solution to a 50-year-old grand challenge in biology,https://www.reddit.com/r/ControlProblem/comments/k40j0e/alphafold_a_solution_to_a_50yearold_grand/,34,dont get stop ai needs able solve protein folding problem many times create system capable making precise tools useful molecular nanotech reached speed general intelligence makes effective path protein fold required mechanism protein fold better humans good creating nanotech sufficiently hard dont molecular nanotech right check back years,7,1,0.31200396825396826
"New UK National AI strategy: ""The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously.""",https://www.reddit.com/r/ControlProblem/comments/pu3yjx/new_uk_national_ai_strategy_the_government_takes/,34,brief skin saw mentions agi risk including longer term taking specific predictions future impact technology opposed needs developing using today along history since various hope cycle given way called winters promises made perpetually remainedabout years away emergence artificial general intelligence agi may seem like science fiction concept concern safety nonhumanaligned systemsfootnote means restricted fringes fieldfootnote governments first focus economic social outcome autonomous captive systems exist today however take firm stance critical watch evolution technology take seriously possibility agi general actively direct technology peaceful humanaligned directionfootnote emergence full agi would transformation impact almost every aspect life many challenges could presented could emerge much sooner general purpose technology economic social impactscomparable combustion engine car computer theinternet disrupted changed shape theworld live could long system wakes choice made develop shape future humanity course internationalaffairs example whether used enhance peace causefor war whether used strengthen democracies emboldenauthoritarian regime responsibility looked extreme risks could made real agi also consider dualuse threats already faced today interesting news sure till concrete benefits ligament research,7,0,0.0935842803030303
UN calls for moratorium on AI that threatens human rights | Business and Economy News,https://www.reddit.com/r/ControlProblem/comments/pp0b06/un_calls_for_moratorium_on_ai_that_threatens/,33,best old could make original reduced united nations high commissioner human rights michelle bachelet wednesday called moratorium sale use artificial intelligence systems threaten human rights adequate safeguards place ensure technology abused bachelet human rights chief stressed applications comply international human rights law must banner quote power serve people undesirable ability feed human rights violations enormous scale virtually visibility action needed put human rights guardrails use good squat bachelet stressed extended summary faq version tears far feedback comments monitor constructive feedback welcome top keywords human rights systems bachelet,7,1,0.17841666666666667
Maybe an AI would hit a self-improvement ceiling pretty fast?,https://www.reddit.com/r/ControlProblem/comments/3oknoz/maybe_an_ai_would_hit_a_selfimprovement_ceiling/,35,alternatively maybe intelligence important think humans smart maybe smarter years ago took long time obvious changes take place furthermore adult humans smartest things earth currently spend hours per day watching maybe super intelligence would spend hours per day watching,7,1,0.14251700680272109
"Matthew Barnett predicts human-level language models this decade: “My result is a remarkably short timeline: Concretely, my model predicts that a human-level language model will be developed some time in the mid 2020s, with substantial uncertainty in that prediction.”",https://www.reddit.com/r/ControlProblem/comments/qg5udl/matthew_barnett_predicts_humanlevel_language/,30,oh yes concrete model substantial uncertainty,7,1,0.15000000000000002
Jan Leike says we are on track to build superhuman AI systems but don’t know how to make them safe yet,https://www.reddit.com/r/ControlProblem/comments/1famkox/jan_leike_says_we_are_on_track_to_build/,30,realise reason dont slavery someone regulates peoples rights employment regulation context renewal energy direct cause innovation even yeah feels like people applying sam propaganda slogans instead actually engaging subject,7,0,0.05833333333333334
Roman Yampolskiy on Objections to AI Safety: A Coherent Explanation On Why Humanity Is Quite ****ed.,https://www.reddit.com/r/ControlProblem/comments/145dmo2/roman_yampolskiy_on_objections_to_ai_safety_a/,29,yampolskiys cutting wit provided quick defense risk skepticism would love see debate others yes really fun listen,7,1,0.13333333333333333
Governance of superintelligence - OpenAI,https://www.reddit.com/r/ControlProblem/comments/13p3hqa/governance_of_superintelligence_openai/,28,think pretty far away governments creating iaea openai suggested sure say iaea allow large experiments safe nuclear experiments actual iaea would allow sound like nothing would ever meet safety standards never allow anything run,7,1,0.2806122448979592
What 2026 looks like (Daniel's Median Future),https://www.reddit.com/r/ControlProblem/comments/ozuzrg/what_2026_looks_like_daniels_median_future/,29,disagree used spread propaganda demonstratably already unreasonable expect grow future,7,0,-0.05
My current summary of the state of AI risk,https://www.reddit.com/r/ControlProblem/comments/115l7fh/my_current_summary_of_the_state_of_ai_risk/,27,thoroughly grim reading say since learned topic years ago sort fun thought experiment full recently started feel gut level actually going actually going unless alien machine god universe dubious prospects surviving guess thing keep working hopes finding solution cos mean else,7,-1,-0.1140625
Elon Musk Launches Neuralink to Connect Brains With Computers,https://www.reddit.com/r/ControlProblem/comments/61z7iu/elon_musk_launches_neuralink_to_connect_brains/,28,building massmarket electric vehicle colonizing wars agent ambitious enough dusk millionaire entrepreneur wants merge computers human brains help people keep machines founder chief executive cela space exploration technologies launched another company called neuralink according people familiar matter neuralink pursuing dusk calls neutral lace technology implanting tiny brain electrode may one day unload download thoughts dusk taken active role setting californiabased company may play significant leadership role according people briefer neuralinks plans bold step father five already runs two technological complex business dusk respond request comment tax today said member founding team confirmed company existence husks involvement described company embryonic said plans still klux declined provide additional details today previously founded transcriptic started provides robotic lab services accessible internet dusk years old part businessman part futurist splints time cela pressure deliver model sedan time space aims launch satelliteinternet business rocket bring humans wars also pushing development super highspeed train called hyperloop somewhere packed schedule found time start neuroscience company plans develop cranial computers likely treat intractable brain diseases first later help humanity avoid subjugation hands intelligent machines assume rate advancement artificial intelligence left behind lot said conference last june solution proposed direct cortical interfaceessentially layer artificial intelligence inside brainthat could enable humans reach higher levels function dusk teased developing technology taking progress neutral lace treated last august maybe something announce months january treated announcement might coming shortly made official announcement neuralink registered california medical research company last july dusk discussed financing neuralink primarily including capital borrowed equity companies according person briefer plans neuralink also discussed possible investment founders fund venture firm started peter dusk confounded payments company paypal according people familiar matter recent weeks neuralink hired leading academic field according another person familiar matter include vanessa tolosa engineer lawrence evermore national laboratory expert flexible electrode philip tabes professor university california francisco studies brain controls movement timothy partner professor boston university known implanting tiny electrode brains inches study birds sing reached phone partner confirmed working neuralink declined elaborate plans tabes declined comment tolosa respond request comment unclear sorts products neuralink might create people discussions company describe strategy similar space cela dusk developed new rocket electrical technologies proved work using pursue ambitious projects people say first products could advanced plants treat intractable brain disorders like epilepsy major depression market worth billions dollars plants would build simpler electrode already used treat brain disorders like parkinsons disease neuralink prove safety efficacy technology develops receive government approval perhaps could move cosmetic brain forgeries enhance cognitive function people say dusk alluded possibility comments last june describing humans struggle process generate information quickly absorb output level low particularly phone two thumbs tapping away said ridiculously slow input much better high bandwidth visual interface brain eyes take lot data others pursuing idea include bryan johnson founder online payments company braintree plans pump million started called vernal people pursuing similar mission johnson said spoken dusk companies want build better neutral interface first attack big diseases expand human potential facebook posted job braincomputer interface engineers neuroscientists new secret projects division defense advanced research projects agency investing million four years develop implacable neutral interface technology technology faces several barriers scientists must find safe minimal invasion way plant electrode way keep stable brain also yet possible record activity millions brains neuron decide complex decisions distinguish someone wants eat bowl spaghetti go bathroom persuading people get elective brain surgery comments published vanity hair sunday dusk said meaningful partialbrain interface think roughly four five years away dusk indeed takes active leadership role neuralink would raise questions personal bandwidth cela building largest battery factory planet supply forthcoming model electric vehicle need produce hundreds thousands cars meet goal justify lofty market capitalization approaching word motor space struggled launch rickets fast enough send satellites orbit customers ultimately wants launch internetaccess business lowered lowearth writing satellites ferry space tourist moon bring astronauts wars even dusk proved many naysayers wrong traditional auto makers said could never sell popular electric car militaryindustrial graybeards coffee idea could even launch rocket,7,1,0.10123286435786438
A.I. ‐ Humanity's Final Invention? (Kurzgesagt),https://www.reddit.com/r/ControlProblem/comments/1em0uv8/ai_humanitys_final_invention_kurzgesagt/,24,thought video great hope follow soon content goes detail ligament problem specifically,7,1,0.8
"[Cross from r/OpenAi] Sam Altman: ""AI will most likely lead to the end of the world, but in the meantime there will be great companies created with serious machine learning.""",https://www.reddit.com/r/ControlProblem/comments/1axronl/cross_from_ropenai_sam_altman_ai_will_most_likely/,24,us please help stuck spot difference puzzle hours one side classic bond villain side potman pranced,7,1,0.16666666666666666
Interpretability in Transformer Based Large Language Models - Reasons for Optimism,https://www.reddit.com/r/ControlProblem/comments/12g1i03/interpretability_in_transformer_based_large/,23,problem chain thought part llm uses predict response chances internal models certain things textreality work hats get able answer theory mind questions get example dont know internal models would lead misaligned behaviour,7,1,0.17857142857142858
Google’s brand-new AI ethics board is already falling apart,https://www.reddit.com/r/ControlProblem/comments/b9gbho/googles_brandnew_ai_ethics_board_is_already/,51,hardly threat ethics want particular person involved,6,0,-0.06250000000000001
"Exclusive: 63 percent of Americans want regulation to actively prevent superintelligent AI, a new poll reveals.",https://www.reddit.com/r/ControlProblem/comments/1crwkwk/exclusive_63_percent_of_americans_want_regulation/,49,mean percent want universal healthcare carbon taxes democracy slow,6,-1,-0.2041666666666667
"LAION launches a petition to democratize AI research by establishing an international, publicly funded supercomputing facility equipped with 100,000 state-of-the-art AI accelerators to train open source foundation models.",https://www.reddit.com/r/ControlProblem/comments/1272o5n/laion_launches_a_petition_to_democratize_ai/,47,understand coming lets let perfect enemy good possible imo generalizing type effort would increase speed introspective becomes viable model explain reasons arriving output given input readily prevent catastrophe outcome likely people working single model given finite resources many competing models function resources exist go toward ability make useful output retrospection perpetually nice given model becomes standard certain function like table diffusion currently text image new features multiply could ligament features,6,1,0.2556586270871985
The plan to mine the world’s research papers: A giant data store quietly being built in India could free vast swathes of science for computer analysis - of text and images extracted from 73 million journal articles dating from 1847 up to the present day kept on a 576-terabyte storage facility.,https://www.reddit.com/r/ControlProblem/comments/ceilp7/the_plan_to_mine_the_worlds_research_papers_a/,44,recent news researches coming novel applications scraping papers imagine going happen improve bit apply kind data base literally like suddenly thousands einsteins born simultaneously amount progress made unimaginable rsingularityisnear,6,0,-0.05000000000000002
"Calling the present state of affairs ""AI risk"" is like falling out of an airplane with no (known) parachute and solemnly pondering whether there might be some significant chance of ""hitting-the-ground-risk"".",https://www.reddit.com/r/ControlProblem/comments/qnlken/calling_the_present_state_of_affairs_ai_risk_is/,40,funny true continuing metaphor also small chance surviving fall bet though think chance surviving agi significantly greater chance surviving fall stop metaphor,6,1,0.2125
"If you’re an “AI safety lurker,” now would be a good time to de-lurk",https://www.reddit.com/r/ControlProblem/comments/3wd27t/if_youre_an_ai_safety_lurker_now_would_be_a_good/,43,excellent short couple paragraphs everyone read,6,1,0.5
Seems like everyone is feeding Moloch. What can we honestly do about it?,https://www.reddit.com/r/ControlProblem/comments/1gmq0wd/seems_like_everyone_is_feeding_moloch_what_can_we/,40,embrace kolocha try hardest fix reality since control yet matter china america gets first cooked either way,6,1,0.25
Carnegie Mellon scientists call for prioritizing safety research on LLMs,https://www.reddit.com/r/ControlProblem/comments/12jmsgq/carnegie_mellon_scientists_call_for_prioritizing/,40,one first things users jailbreaking chatgpt get explain make met pretty much prove could authors explain difficult jailbreak several strategics work across llms applies making explosives etc comparatively innocuous since information available publicly bigger concern smarter llm may smart enough design novel chemical compounds new dangerous properties applications smart enough keep information bad actors,6,0,-0.009647495361781064
Nothing to see here folks. The graph says things are not bad!,https://www.reddit.com/r/ControlProblem/comments/1clkrmf/nothing_to_see_here_folks_the_graph_says_things/,31,dont think armies termination style roots first negative outcome experience probably something along lines trusting kind data another trusting output little blandly leading people make really bad decisions come first exactly exempt making really bad decisions even understand data say whether bad informed decisions worse bad regularly informed decisions concerned accelerating separation rich poor never turns well people poor side equation,6,-1,-0.1830729166666666
"""It feels like AI is currently bottlenecked on multiple consecutive supplychain disruptions, from cryptocurrency to Intel's fab failures to coronavirus... A more paranoid man than myself would start musing about anthropic shadows and selection effects.""",https://www.reddit.com/r/ControlProblem/comments/miuo0v/it_feels_like_ai_is_currently_bottlenecked_on/,35,dead already late walking dead world,6,-1,-0.2333333333333333
"What sort of AGI would you 𝘸𝘢𝘯𝘵 to take over? In this article, Dan Faggella explores the idea of a “Worthy Successor” - A superintelligence so capable and morally valuable that you would gladly prefer that it (not humanity) control the government, and determine the future path of life itself. ",https://www.reddit.com/r/ControlProblem/comments/1g83dm8/what_sort_of_agi_would_you_𝘸𝘢𝘯𝘵_to_take_over_in/,33,literally perfectly democracy able synthesis values votes constituents produce results want free money politics still respect constitution declaration human rights,6,1,0.475
"AIs are already smarter than half of humans by at least half of definitions of intelligence. If things continue as they are, we are close to them being smarter than most humans by most definitions. To confidently believe in long timelines is no longer tenable.",https://www.reddit.com/r/ControlProblem/comments/1bco0du/ais_are_already_smarter_than_half_of_humans_by_at/,36,hate still debate although know lot stuff sure although even debated agent great decision making personally guess agent great smart enough mostly world see completely different one perceive see world numbers interesting amazing figure anything really,6,1,0.2761904761904762
"""Rare yud pdoom drop spotted in the wild"" (language model interpretability)",https://www.reddit.com/r/ControlProblem/comments/13dhc50/rare_yud_pdoom_drop_spotted_in_the_wild_language/,30,drop line whether make progress interpretability average person makes sound like user need dont want listen trust,6,1,0.125
"After quitting OpenAI's Safety team, Daniel Kokotajlo advocates to Pause AGI development",https://www.reddit.com/r/ControlProblem/comments/1cbp5h4/after_quitting_openais_safety_team_daniel/,33,fully agree conducting agi research one place advocating something like months international collaboration pools talent world transparent accountable entire world several advantages makes harder country defect secret makes harder anyone align way gives advantage others improves safety reducing risk arms race dynamic,6,0,-0.08571428571428572
Massive performance jump in two very interesting natural language benchmarks,https://www.reddit.com/r/ControlProblem/comments/jwngwx/massive_performance_jump_in_two_very_interesting/,30,scored openbookqa task previous best benchmark human level performance crowdsourced workers test intended economically valid test human ability reason existing facts apply novel situations combined background knowledge understanding world program merely meet human level seemingly exceeded lot model know little beyond resemble bert models multimetric bayesian geneticalgorithm based optimization one v agarwal suspect know midian agarwal carnegie fellow university,6,0,0.05572916666666666
"Sam Harris' podcast ep. 53 - The Dawn of Artificial Intelligence, a conversation with Berkeley professor of Computer Science and MIRI advisor Stuart Russell",https://www.reddit.com/r/ControlProblem/comments/5eq0u8/sam_harris_podcast_ep_53_the_dawn_of_artificial/,30,question anyone tell besides russell aicomputer science academic industry experts opponents control problem obviously besides researches mirifhi also looking experts specializing contemporary experts good know,6,1,0.21666666666666665
General AI Won't Want You To Fix its Code - Computerphile,https://www.reddit.com/r/ControlProblem/comments/5wpwpy/general_ai_wont_want_you_to_fix_its_code/,29,think video good job explaining instrumental convenient values ak basic drives selfpreservation goalintegrity preservation complicating notions video mention eg related goal drift wireheading good introduction title however really correct fixing parts code could help better achieve current goals considered desirable followed video talks deepmindmiris paper safely interruptible agents gets fairly complicated territory simplifies explanation felt mob occasionally little bit handwavey easy task explain things wide audience dont necessarily think could done better pretty good introduction,6,1,0.2309895833333333
"If you care about AI safety and also like reading novels, I highly recommend Kurt Vonnegut’s “Cat’s Cradle”. It’s “Don’t Look Up”, but from the 60s",https://www.reddit.com/r/ControlProblem/comments/1fqpyny/if_you_care_about_ai_safety_and_also_like_reading/,28,read last year one pick high priority pre singularity reading list haired well player piano watched get enter stage add breakfast champions stole show think resolute ever arrive eta really sure comparison dont look accurate though really want vice book remember,6,1,0.252
Deceptively Aligned Mesa-Optimizers: It's Not Funny If I Have To Explain It,https://www.reddit.com/r/ControlProblem/comments/u52ntr/deceptively_aligned_mesaoptimizers_its_not_funny/,29,think one closest realworld examples attempt train generate plausible satellite images flatvector graph instead taught interesting stenographic technique pretend authors intended,6,1,0.5
Writing Doom – Award-Winning Short Film on Superintelligence (2024),https://www.reddit.com/r/ControlProblem/comments/1gnwchi/writing_doom_awardwinning_short_film_on/,28,easily intelligent handling subject safety superintelligence ever seen film short film brilliant also recommend watching interview filmmaker,6,1,0.38333333333333336
DeepMind scientists: Reinforcement learning is enough for general AI,https://www.reddit.com/r/ControlProblem/comments/nv9zcr/deepmind_scientists_reinforcement_learning_is/,26,seems axiom lot people operate hardly sure tried tricks complexity watching human brain data sets watching human child learns,6,1,0.16666666666666666
Film-maker interested in brainstorming ultra realistic scenarios of an AI catastrophe for a screen play... ,https://www.reddit.com/r/ControlProblem/comments/1h10ypf/filmmaker_interested_in_brainstorming_ultra/,25,sure quite looking vaguely related valuable humans transit metamorphosis crime intellect trigger warning everything south must scream awareness short film second renaissance parts short films animatrix webfiction,6,0,0.1
"Yoshua Bengio: Some say “None of these risks have materialized yet, so they are purely hypothetical”. But (1) AI is rapidly getting better at abilities that increase the likelihood of these risks (2) We should not wait for a major catastrophe before protecting the public.""",https://www.reddit.com/r/ControlProblem/comments/1fkrsm6/yoshua_bengio_some_say_none_of_these_risks_have/,26,like sweet nuclear weapon like much stop,6,1,0.275
"GPT-4 Red Teamer - ""Most concerning things about GPT-4""",https://www.reddit.com/r/ControlProblem/comments/12jk5rl/gpt4_red_teamer_most_concerning_things_about_gpt4/,26,interesting thanks sharing takes want watch whole thing,6,1,0.3
"Crowdsourced moral judgements - from 97,628 posts from r/AmItheAsshole",https://www.reddit.com/r/ControlProblem/comments/g6bjlm/crowdsourced_moral_judgements_from_97628_posts/,25,crowdsourced moral judgement data scientist mlle rien recently described built cleaned dataset moral dilemma posted ramitheasshole semistructured online forum internet closest approximation judicial system posts collected dataset includes title body date number edit votes number comments plus community verdict uthumbsdrivesmecrazy data plural enemy singervine dataset interesting uncontrollable need able predict extrapolate human moral judgement example foundation coherent extrapolated volition proposal need datasets measure develop capability found data scale suitable lacking,6,1,0.22777777777777775
The Lebowski Theorem of Machine Superintelligence,https://www.reddit.com/r/ControlProblem/comments/d2a249/the_lebowski_theorem_of_machine_superintelligence/,24,really wireheading reward hackingcorruption general wellknown phenomena discussed regularly safety circles recent paper discussed briefly tom everett also published avoid dont think solved issue convinced superintelligence must necessarily,6,0,0.041666666666666664
Those people telling us we have nothing to worry about might be out of a job soon,https://www.reddit.com/r/ControlProblem/comments/ardawh/those_people_telling_us_we_have_nothing_to_worry/,24,examples blow post terrifying incredibly versatile realistic would absolutely fooled going wild ride,6,0,0.07333333333333333
People will be saying this until the singularity,https://www.reddit.com/r/ControlProblem/comments/1g0rxqg/people_will_be_saying_this_until_the_singularity/,158,feel like already eventually got couple long arguments people released reason think see gui though,5,0,-0.05
"The Pentagon Inches Toward Letting AI Control Weapons: ""when faced with attacks on several fronts, human control can sometimes get in the way of a mission""",https://www.reddit.com/r/ControlProblem/comments/n964en/the_pentagon_inches_toward_letting_ai_control/,58,actually war james ends quite well compared came years earlier,5,0,0.0
Something Unfathomable: Unaligned Humanity and how we're racing against death with death | Automation is a deeper issue than just jobs and basic income,https://www.reddit.com/r/ControlProblem/comments/11dbpsy/something_unfathomable_unaligned_humanity_and_how/,42,people make real decisions society ones worry care outcome author warning decision makers pathological shortsighted fundamentally unable resist shorter gain long term rewards whatever makes money shareholder shortest amount time rules world absolutely going fuck technological progress,5,-1,-0.11000000000000001
Human Level Reinforcement Learning Through Theory Based Modelling,https://www.reddit.com/r/ControlProblem/comments/ot3vx3/human_level_reinforcement_learning_through_theory/,39,really hope enter minecraft playing competition,5,1,0.2
"""GPT-4 will probably have at least 30 trillion parameters based on this""",https://www.reddit.com/r/ControlProblem/comments/murhkx/gpt4_will_probably_have_at_least_30_trillion/,41,biggest issue see gpts domain include even see output training capable lot things due incredible generally domain language till struggle consistently solve basic logic problems time creating humanplausible stories natural language prompted code could orders magnitude size would continue powerful selfawareness lies outside domain,5,1,0.18611111111111114
The United Nations Wants to Treat AI With the Same Urgency as Climate Change,https://www.reddit.com/r/ControlProblem/comments/1fl8ib0/the_united_nations_wants_to_treat_ai_with_the/,38,read article unpaywalled link true donna make lot people quite angry see attack safety issues independently hard avoiding verbally comparing global crisis,5,-1,-0.11041666666666668
SMBC: Happy (cartoon),https://www.reddit.com/r/ControlProblem/comments/biiuzz/smbc_happy_cartoon/,43,damn particles body could billions times happier existence morally indefensible,5,0,0.0
The simple case for urgent global regulation of the AI industry and limits on compute and data access - Greg Colbourn,https://www.reddit.com/r/ControlProblem/comments/12zvqi0/the_simple_case_for_urgent_global_regulation_of/,35,dont like idea constant string gpts helping get another released short order even gpt shorthand llms general doubt would happen unless something paradise shifting happens fundamental architecture training really wild emerged property personally think gptn tools dangerous kid gun lab leak something nasty infohazard mass casualty hacking dont see repulsive self improvement risk either base model comes fresh oven enough capacities science point folding tools testing science tools doubt model would get released idea gptn science well withwithout tools doubt freshly baked different genus helped create would allowed dubbed gpt monster hopefully point stupid enough allow things online chance boxing much,5,-1,-0.14999999999999997
"OpenAI whistleblower William Saunders testifies to the US Senate that ""No one knows how to ensure that AGI systems will be safe and controlled"" and says that AGI might be built in as little as 3 years.",https://www.reddit.com/r/ControlProblem/comments/1g869xb/openai_whistleblower_william_saunders_testifies/,34,know impossible predict future seem hellbent careening cliff hopes build parachute way understand many highly intelligent rational people cannot seemingly wrap heads around exponentially large risk handle clearly politicians institutions depth handle,5,1,0.15793650793650796
"Greg Brockman on Twitter: We've found that it's possible to target GPT-3's behaviors to a chosen set of values, by carefully creating a small dataset of behavior that reflects those values. A step towards OpenAI users setting the values within the context of their application",https://www.reddit.com/r/ControlProblem/comments/nwu9pn/greg_brockman_on_twitter_weve_found_that_its/,34,mentally cutting dataset weak output like actual heuristic moral choice better taking appearance social awareness morality zero movement towards actually achieving,5,0,-0.0630952380952381
"Examples of AI safety progress, Yoshua Bengio proposes a ban on AI agents, and lessons from nuclear arms control - AI Safety Newsletter #6",https://www.reddit.com/r/ControlProblem/comments/13j8nva/examples_of_ai_safety_progress_yoshua_bengio/,31,still laws politics way behind going,5,-1,-0.4
"The Future of Humanity Institute received a £13.3M from Good Ventures and the Open Philanthropy Project, ""the largest in the Faculty of Philosophy’s history""",https://www.reddit.com/r/ControlProblem/comments/9n920p/the_future_of_humanity_institute_received_a_133m/,35,awesome miri get similar one funding half budget thing dont really care shown,5,1,0.25833333333333336
The Pentagon is investing $2 billion into artificial intelligence,https://www.reddit.com/r/ControlProblem/comments/9e1gr2/the_pentagon_is_investing_2_billion_into/,31,get positive results important relevant military national security going stop oh boy good thing bad thing feel like might accelerate progress without accelerating progress enough safety hand almost definitely extremely smart people working maybe things considered,5,1,0.14269480519480524
Chinese scientists develop AI ‘prosecutor’ that can press its own charges,https://www.reddit.com/r/ControlProblem/comments/rqr8nd/chinese_scientists_develop_ai_prosecutor_that_can/,30,beyond creep could possibly go wrong,5,-1,-0.5
Yudkowsky comments on DeepMind Go victory,https://www.reddit.com/r/ControlProblem/comments/431b8j/yudkowsky_comments_on_deepmind_go_victory/,29,agi nearing every year update many articles date real work control problem must begin sooner rather later,5,1,0.2333333333333333
The film WarGames (1983) is possibly the most realistic Hollywood depiction of unfriendly AI.,https://www.reddit.com/r/ControlProblem/comments/56tf4b/the_film_wargames_1983_is_possibly_the_most/,31,mmm thought colossus corbin project actually realistic less entertaining,5,1,0.16666666666666666
"""Introducing Adept AI Labs"" [composed of 9 ex-GB, DM, OAI researchers, $65 million VC, 'bespoke' approach, training large models to use all existing software, team at bottom]",https://www.reddit.com/r/ControlProblem/comments/uch5dk/introducing_adept_ai_labs_composed_of_9_exgb_dm/,28,nothing every publicly funded unless politician believes blamed lack public funding within next six weeks since risk experts mostly agree little warning die politician ever blamed lack funding therefore chance public funding safety luckily otherwisemorallyquestionable wealthy folks provided substantial funding bluesky safety research chance payoff private luckily looks like lure top researches away google facebook deepmind level funding needed simply run respectable think tank,5,1,0.1907051282051282
Uber’s Self-Driving Car Didn’t Know Pedestrians Could Jaywalk,https://www.reddit.com/r/ControlProblem/comments/dstlbd/ubers_selfdriving_car_didnt_know_pedestrians/,30,think article similar ones incredibly misleading titles actual report according data obtained selfdriving system system first registered rear lidar observations pedestrian seconds impact vehicle traveling may vehicle pedestrian paths converted selfdriving system software classified pedestrian unknown object vehicle bicycle varying expectations future travel path seconds impact selfdriving system determined emergency breaking maneuver needed mitigate collision see figure according ober emergency breaking maneuvers enabled vehicle computer control reduce potential erratic vehicle behavior vehicle operator relied intervene take action system designed alert operator report seem mention lack explicit instruction hit jaywalkers important factor incident seems like safety concerns contributed outcome fact seems like part problem system defer human want adequate indication human take car environment cycling effective gear operator could see late edit may wrong saying none articles actually properly cite sources time track everything regardless entirely convinced claims,5,0,0.09901960784313724
DeepMind CEO Demis Hassabis Urges Caution on AI,https://www.reddit.com/r/ControlProblem/comments/10as264/deepmind_ceo_demis_hassabis_urges_caution_on_ai/,29,good read especially end looking trajectory achievements makes wish intelligent thought wonder relative equanimity towards risk potential much camp also represented article amply existing society iniquity entrench gross efficient systems like oligarchical capitalism,5,1,0.24285714285714285
Killer Robots Aren’t Science Fiction. A Push to Ban Them Is Growing.,https://www.reddit.com/r/ControlProblem/comments/rjzsqj/killer_robots_arent_science_fiction_a_push_to_ban/,27,governments give killer roots military people agent members government able bank apply,5,1,0.2
Startup is building computer chips using human neurons,https://www.reddit.com/r/ControlProblem/comments/o47opz/startup_is_building_computer_chips_using_human/,28,human neuron agent particularly special cluster neuron dont give machines feelings like super complex emerged properties brains structures unless delicate wiring talking acquired human neuron missed point entirely,5,0,0.012925170068027212
AI Training Costs Are Improving at 50x the Speed of Moore’s Law,https://www.reddit.com/r/ControlProblem/comments/hlv72o/ai_training_costs_are_improving_at_50x_the_speed/,27,dollars spent training particular architecture performing certain task bit silly valid points know lot optimism training surely dramatic improvements future basically orthogonal hardware improvements,5,-1,-0.10873015873015873
A simulation game about the paperclip maximizer that eventually converts the entire Earth into paperclips.,https://www.reddit.com/r/ControlProblem/comments/7gkzc1/a_simulation_game_about_the_paperclip_maximizer/,28,pretty fun type game played day getting enough honor combat probe stage clock first upgrade takes forever though,5,0,0.08
From Video Games To Reality…With Just One AI!,https://www.reddit.com/r/ControlProblem/comments/ia9do5/from_video_games_to_realitywith_just_one_ai/,26,profound implication gazing earlier likely game design like well go concept art right full game scale generate custom video games fly,5,0,0.08988095238095237
SG-1's Replicators as a good example of the control problem in fiction.,https://www.reddit.com/r/ControlProblem/comments/7lbed8/sg1s_replicators_as_a_good_example_of_the_control/,25,solid show good science fiction president times replicators present form stargate atlantic well seen stargate universe gigantic miserable failure though avoid unless want sad sure replicators scare actually also scared pure replicator thin venter nonsense top,5,0,-0.027489177489177494
"20 years ago today, Deep Blue won the final match against Garry Kasparov in 19 moves",https://www.reddit.com/r/ControlProblem/comments/6ako5u/20_years_ago_today_deep_blue_won_the_final_match/,25,kasparov said something interesting think harris podcast chess right computer assisted humans still better chess computers alone thought time opposite true really scar,5,1,0.3059523809523809
Control Problem FAQ,https://www.reddit.com/r/ControlProblem/comments/3tjhlo/control_problem_faq/,26,please let know needs changed added poor job explaining something well straight gets make best faq priding people subject coming soon glossy terms,5,1,0.15833333333333335
AI Makes Near-Perfect DeepFakes in 40 Seconds! 👨,https://www.reddit.com/r/ControlProblem/comments/n73jpq/ai_makes_nearperfect_deepfakes_in_40_seconds/,25,dont think really control problem relevant,5,1,0.30000000000000004
Anybody interested in a thought experiment about how superintelligent machines will emerge and impact humanity? I released it as a book last week. (Happy to give a free electronic copy to to those in this sub),https://www.reddit.com/r/ControlProblem/comments/ay191a/anybody_interested_in_a_thought_experiment_about/,25,page nitpicks diagnosis human condition relationship nature incredibly ideological based tell small part much broader story come narrow conclusions particularly like sources statement possible also increased disharmony nature believe historians would agree mean disharmony use idea disharmony lot claim things got worse time ignoring concrete measures human welling show things getting better tribalism born new power structures tribalism clearly existed institutions religions evolved realistic concepts good evil humans inherently good nature inherently evil christianity idea original inman inherently evil godnature inherently good falsity claim talking religions saying new religions less focused worship nature like previous religions see nature bad indifferent humans capable good changing relationship nature complex boiled fact seeing nature sacred become less common environment became manage actually bad thing though ways yes others seeing nature sacred best solution problem tackle environment big problem sure one issues human suffering take priority environment focus however humanity see environment extension us could better much realistic perspective take know little nutrition obviously important part history eat changed like see sources claim result new methods producing food dies became even less diverse less nutritionally dense painted compounds disrupt mormons cause cancer big difference surely dies diverse ever since supermarket global shipping really lower cancer rates past big focus nutrition incredibly difficult thing study especially historical dies confident broader conclusions state humanity based nutrition alone led us slow destruction important natural system humanity human body please show evidence humans wealthier point history humans transition scavenger huntergatherer farmer factory worker develop harmonious relationship natural world economies food health education systems better served short longer needs without negative impact know without negative impact impossible challenge dont know imparts thing never done new negative imparts discovered take time old institutions adapt newly discovered problems particularly institutions become corrupt certainly good improving things potentially could lets pretend like humanity moving generally good direction problems first sense self function human mind gives us identity thus influences spend time resources actually illusion dont dispute fact sense self illusion useful illusion mistaken selfishness comes nothing feeling like dont need environment strong sense self act helplessly could imagine seem confused sense self actually helps us relate others ground us environment correct loneliness generally lack sense meaning lives major issue time suicide overcome deaths causing life expectancy figures go therefore stumble around selfish harding resources fighting one another could easily find contentment harmony collaboration precisely power collaboration build institutions would also blame harding resources fighting one another harmony means disagreements disagreements goal fascia dictatorship simple solutions complex problems often bring even bigger problems analysis simple harmony vs disharmony solution simple x leave hope helpful,5,0,0.03542305073203951
Apply to >50 AI safety funders in one application - deadline May 17th,https://www.reddit.com/r/ControlProblem/comments/13eoe5x/apply_to_50_ai_safety_funders_in_one_application/,25,thank yeah really excited see goes think could make funding ecosystem safety way wealthier robust,5,1,0.375
AI: Practical Advice for the Worried - Zvi,https://www.reddit.com/r/ControlProblem/comments/11jr2fw/ai_practical_advice_for_the_worried_zvi/,24,helpful since seeing eliezer bankers podcast feeling huge sense existential dread,5,1,0.39999999999999997
DeepMind’s AlphaGo Zero Becomes Go Champion Without Human Input - Future of Life Institute,https://www.reddit.com/r/ControlProblem/comments/778kez/deepminds_alphago_zero_becomes_go_champion/,25,potentially big selfplay fairly general technique applies anything set adversarial game always hard get work assumption would lead chronic training forgetting inability retain enough skill training far past human levels impressive achievement unfortunately find paper explain critical part selfplay stable steadily increases playing capability turns new twist tree search training big indeed probably revolutionize anything currently use mcts effectively starcraft probably motivate work even harder deep models environment planning purposes refuse trick things mctsable treessimulators available,5,0,0.04796650717703349
"'Partnership on AI' formed by Google, Facebook, Amazon, IBM and Microsoft",https://www.reddit.com/r/ControlProblem/comments/550114/partnership_on_ai_formed_by_google_facebook/,23,dont think existential risk agenda concerns think potential raise awareness shortmediumterm risks overall make beneficial humanity collaboration probably means advances made quickly areas happens include beneficent raw capability saw capability good many things eg healthcare could also risk leads development agi without safe however skeptically companies would really willing share true stateoftheart dont really expect partnership significantly increase risk furthermore even though probably agenda partnership may eventually good vector introduce existential concerns sounds good,5,1,0.2769688644688645
DeepMind finds AI agents are capable of social learning,https://www.reddit.com/r/ControlProblem/comments/186q0ts/deepmind_finds_ai_agents_are_capable_of_social/,23,paper abstract cultural transmission domaingeneral social skill allows agents acquire use information realize high fidelity recall thought process perpetuate fit variant cultural evolution humans cultural evolution led accumulation refinement skill tools knowledge across generations provide method generation cultural transmission artificially intelligent agents form fewshot imitation agents succeed realize imitation human novel contents without using recollected human data identify surprisingly simple set ingredient sufficient generation cultural transmission develop evaluation methodology vigorously possessing paces way cultural evolution play algorithmic role development artificial general intelligence,5,0,0.06921568627450982
Language models can explain neurons in language models,https://www.reddit.com/r/ControlProblem/comments/13d0g1v/language_models_can_explain_neurons_in_language/,24,hope finally scales might solved interpretability question going information,5,0,0.0
"TIL Elon Musk, Stephen Hawking, and Steve Wozniak have all signed an open letter for a ban on Artificially Intelligent weapons",https://www.reddit.com/r/ControlProblem/comments/5xhkv6/til_elon_musk_stephen_hawking_and_steve_wozniak/,109,dont think ethical give lifesaving possibilities artificial intelligence warfare aggressive program education control problem ensure strong artificial intelligence pursued would desirable related note anyone know registers various intelligence services priority list dia would think,4,0,-0.09444444444444444
Dr. Michal Kosinski describes how GPT-4 successfully gave him instructions for it to gain access to the internet.,https://www.reddit.com/r/ControlProblem/comments/11uabk3/dr_michal_kosinski_describes_how_gpt4/,73,let get straight yes afraid someone thinking consequences letting box killing everyone giving us second chance correct mistake proof concept lets box learn experience great plan must great plan small nonzero chance michael kosinski actually doomed us much larger chance permitted waluigi install virus machine,4,1,0.11875000000000002
The perks of working in AI safety,https://www.reddit.com/r/ControlProblem/comments/1e2p9wl/the_perks_of_working_in_ai_safety/,62,well yeah massive publicity adoring public offset things,4,0,0.06666666666666667
Building A Virtual Machine inside ChatGPT,https://www.reddit.com/r/ControlProblem/comments/zbvdyh/building_a_virtual_machine_inside_chatgpt/,54,comments want see diverged real output try something harder like import jump printnpsinnparange chatgpt output array vs real jump output array really good memorizing numbers patterns wild language model trained enough terminal output accurate sure else learn face output really interesting result would someone found category problems algorithm tried implement gpt instruct model output gave faster equally reliable results traditional methods,4,1,0.22727272727272727
Elon Musk unveils Neuralink’s plans for brain-reading ‘threads’,https://www.reddit.com/r/ControlProblem/comments/ceac2h/elon_musk_unveils_neuralinks_plans_for/,45,love picture mouse usbc port imbedded head,4,1,0.5
"""there are currently no approaches we know won't break as you increase capabilities, too few people are working on core problems, and we're racing towards AGI. clearly, it's lethal to have this problem with superhuman AGI"" (on RLHF)",https://www.reddit.com/r/ControlProblem/comments/11i29nb/there_are_currently_no_approaches_we_know_wont/,42,like explore might able contribute reducing extinction level catastrophe etc superhuman intelligence ill provide links get started,4,0,0.0
Astronomical suffering from slightly misaligned artificial intelligence (x-post /r/SufferingRisks),https://www.reddit.com/r/ControlProblem/comments/a6lxgt/astronomical_suffering_from_slightly_misaligned/,42,singleton many superintelligent competing risks become much probable may blackmailed example imagine two control two hemisphere one human benevolent another paperclip maximizer prior indifferent human existence however papercliper could blackmailed benevolent torturing humans live part world even create new humans designed torture however one risk,4,1,0.13896103896103895
"At long last, Colossus!",https://www.reddit.com/r/ControlProblem/comments/1f7e37l/at_long_last_colossus/,39,thought must worried acceleration really want time catch project,4,1,0.2
MIRI gets 2 large crypto donations,https://www.reddit.com/r/ControlProblem/comments/nbxkm4/miri_gets_2_large_crypto_donations/,40,incredible news tonightim grateful generous folks,4,1,0.9
"WaitButWhy's Tim Urban says we must be careful with AGI because ""you don't get a second chance to build god"" - if God v1 is buggy, we can't iterate like normal software because it won't let us unplug it. There might be 1000 AGIs and it could only take one going rogue to wipe us out.",https://www.reddit.com/r/ControlProblem/comments/1gv66e1/waitbutwhys_tim_urban_says_we_must_be_careful/,36,technically qualified people say however including tax remark rogue asi one things first strike could devastating making ratio good bad asi important,4,0,-0.05833333333333331
10 Reasons to Ignore AI Safety,https://www.reddit.com/r/ControlProblem/comments/gwkcpf/10_reasons_to_ignore_ai_safety/,39,fantastic video book great feels like textbook argument concise illustration gives potential impactful many folks think way,4,1,0.36000000000000004
AI safety diagram,https://www.reddit.com/r/ControlProblem/comments/1cn78ba/ai_safety_diagram/,34,wont forget tracks line every living person planet tied blocking ai superintelligence cure raging tracks appear basically infinitely long humans could ever live could solve tracks seem pirates switch seems swimmer like never decision could make,4,0,0.043181818181818175
Remove This! ✂️ AI-Based Video Completion is Amazing!,https://www.reddit.com/r/ControlProblem/comments/jaju6b/remove_this_aibased_video_completion_is_amazing/,35,really impressive particularly liked scene expansion,4,1,0.8
The next decades might be wild - LessWrong,https://www.reddit.com/r/ControlProblem/comments/zn740h/the_next_decades_might_be_wild_lesswrong/,32,well see plateau growth phase personally person sitting right middle protein structure prediction subdiscipline cannot deny radically changed ways ask scientific questions greatly accelerated design steps however absolutely cannot solve lot problems face bioengineering either data scarcity technical complexity problems basically things used take year two founding keyboard screwing around lab bench take month agent really much better tasks dont access radically new types challenges suspect sort scenario generalized technical discipline affected basically anything designtestiterate cycle used involve esoteric domain specific training closely supervise task done trained clever generals opens design space people reluctant touch would laborious increases worker productivity without increasing workload necessarily lead indefinite teach acceleration makes everything little cheaper faster,4,1,0.14624958374958374
Silicon Valley Takes AGI Seriously—Washington Should Too,https://www.reddit.com/r/ControlProblem/comments/1g6y1dz/silicon_valley_takes_agi_seriouslywashington/,32,maybe saying silicon valley takes something seriously good way fo convincing people,4,1,0.6
The Digital Souls Alliance releases their first campaign.,https://www.reddit.com/r/ControlProblem/comments/10jg34g/the_digital_souls_alliance_releases_their_first/,29,believe moral thing never program robotic agents feelings simulcra feelings point question soul ever arises largely based assumption would work like software employment create infinite amount sufficient hardware potentially massive numbers operations single piece hardware willing force resource share seems combination cruelty failure forethought produce infinite number souled entitles infinite resources would want biological souls prioritized first always almost technology currently produce soulsimulcra model article researches brain hacked preference company anything go things mentioned persistence state memory persistence identity essentially trivial might seem cool going take responsibility infinite immortal hand responsibility us given outnumbered outchronologize us,4,0,0.052380952380952375
"How close can we get to an AI owning a company, from legal perspective (and without reforming laws)?",https://www.reddit.com/r/ControlProblem/comments/jlk3rs/how_close_can_we_get_to_an_ai_owning_a_company/,29,paper argues agreements isomorphic algorithms granting legal personhood possible creating carefully structures llc going back control problem communist agree parallel corporate laws algorithm running welfare optimism profits cases current society like sorcerer longer able control powers nether world called spells also rogue extremely normal human edit reveal taking direct control corporation exposure risks inciting ire thus destruction manipulatingpersuading humans acting output say prediction policies social media would even enough seize control government several without anyone noticing anything goes wrong get blamed,4,0,0.02395833333333333
Why Not Just: Think of AGI Like a Corporation? - Robert Miles,https://www.reddit.com/r/ControlProblem/comments/a8yp53/why_not_just_think_of_agi_like_a_corporation/,29,another good video mob miles similar ideas discussed scott alexander things superintelligences slightly broader sense corporations also deep video,4,1,0.13333333333333333
Notes on the Safety in Artificial Intelligence conference,https://www.reddit.com/r/ControlProblem/comments/4qndcn/notes_on_the_safety_in_artificial_intelligence/,28,bit late thanks great write slide images hope helpful firing strategy working areas disappointed like hear dismissive attitude towards longtermexistential risk could easily imagined many folks insisting topic choosing address sounds like overall tenor degrees active hostility least active airiskskepticism remains difficult assess forecast progress control problem pessimisticcautious moment lets imagine making rapid progress towards existentiallythreatening arrive within decades years making extremely slow progress control problem turns difficult point tends become clearer safartint conference may go famous historic disaster missing point hand miri whoever starts making rapid progress longer risk problems control problem solutions arrive early look easy wont care much gets hope case,4,0,0.0026315789473684206
"Racing to ""build AGI before China"" is like Indians aiding the British in colonizing India. They thought they were being strategic, helping defeat their outgroup. The British succeeded—and then turned on them. The same logic applies to AGI: trying to control a powerful force may not end well for you.",https://www.reddit.com/r/ControlProblem/comments/1gzprvu/racing_to_build_agi_before_china_is_like_indians/,27,thought sores still asset ceremonial power marathas also mean maybe put throne mind nice ceremonial throne real power lots wealth seems like would actually good outcome humanity,4,1,0.21458333333333332
New Robert Miles video dropped ,https://www.reddit.com/r/ControlProblem/comments/1d5j2cg/new_robert_miles_video_dropped/,27,really says something mixed hopelessness outlook video made significantly hopeful future,4,1,0.14375
Yeah,https://www.reddit.com/r/ControlProblem/comments/1g25o5x/yeah/,25,coordination problems negative wash equilibrium charms races collective action issues prisoners dilemma tragedy commons kolocha lots terms micro scale issues dont see humanity capable getting way alone aorta use align humanity align,4,0,9.25185853854297e-18
How Rogue AIs may Arise - Yoshua Bengio,https://www.reddit.com/r/ControlProblem/comments/13qk0kg/how_rogue_ais_may_arise_yoshua_bengio/,26,elite consensus dangers emerging kann lecunn seems one dont worry happy side,4,1,0.8
We have a wiki!,https://www.reddit.com/r/ControlProblem/comments/p8tmj8/we_have_a_wiki/,26,sure actually case anymore orbital maintained best guess would lesswrong concepts mortal tough much stuff scattered place,4,1,0.26222222222222225
"""'We Might Need To Regulate Concentrated Computing Power': An Interview On AI Risk With Jaan Tallinn""",https://www.reddit.com/r/ControlProblem/comments/ckffxr/we_might_need_to_regulate_concentrated_computing/,25,apples long history shipping antiquated useless gpus desktop captors attempt reduce risk ungrateful,4,-1,-0.275
AI Forecasting: One Year In - LessWrong,https://www.reddit.com/r/ControlProblem/comments/vrf512/ai_forecasting_one_year_in_lesswrong/,26,progress robustness benchmark slower expected benchmark fall short forecast predictions somewhat worrying suggests machine learning capabilities progressing quickly safety properties progressing slowly,4,0,-0.016666666666666684
"GPT2, Counting Consciousness and the Curious Hacker - ""I’m a student that replicated OpenAI’s GPT2–1.5B. I plan on releasing it on the 1st of July.""",https://www.reddit.com/r/ControlProblem/comments/bxki57/gpt2_counting_consciousness_and_the_curious/,26,well really able delicate probably matter time someone else would able anyway wonder openai seen whether respond way edit twitter author says said writing update post thoughts gpt light unilateralists nurse today discussions openai especially luck shlegeris miri lot think take time writing next post updated beliefs,4,1,0.18333333333333335
"Finally, a decent article on AI Safety.",https://www.reddit.com/r/ControlProblem/comments/7y7lvm/finally_a_decent_article_on_ai_safety/,26,great article nice see mainstream publication,4,1,0.7
OpenAI Model Generates Python Code,https://www.reddit.com/r/ControlProblem/comments/go3m89/openai_model_generates_python_code/,25,potential use case heard replacement stackoverflow search must put prompt something specific trying get boiler plate partial functionality lint review test know reactor lint test repeat till feature fix like,4,0,-0.03333333333333333
Joe Rogan Experience #1350 - Nick Bostrom,https://www.reddit.com/r/ControlProblem/comments/eqrs0d/joe_rogan_experience_1350_nick_bostrom/,24,rods sake skin one coming someone finds organs conversations fascinating toe still mental block around stimulation argument possibly around anthropoid reasoning conversation becomes frustration back forth poor kostroma banging head wall maybe lay enables toe,4,0,0.039999999999999994
Neuralink - Wait But Why,https://www.reddit.com/r/ControlProblem/comments/66ln38/neuralink_wait_but_why/,24,starting far best work tbh section safely skipped hoping gets better gets meat cough topic,4,1,0.42000000000000004
"Godfather of AI Warns of Powerful People Who Want Humans ""Replaced by Machines""",https://www.reddit.com/r/ControlProblem/comments/1h406az/godfather_of_ai_warns_of_powerful_people_who_want/,22,intelligence gives power going control power prominent machine learning expert told outlet one young world summit montreal people might want abuse power people might happy see humanity replaced machines angio claimed mean fringe people lot power unless put right guardrails right,4,1,0.2764880952380952
METR report finds no decisive barriers to rogue AI agents multiplying to large populations in the wild and hiding via stealth compute clusters,https://www.reddit.com/r/ControlProblem/comments/1gv6r4o/metr_report_finds_no_decisive_barriers_to_rogue/,23,needing lot cards clusters costs lot money per hour etc smaller stupider get caught sooner smarter ones able hack better get money humans stuff humans get normal market like realistic nodes set photo find records hack system steal data try hack system tell us holes,4,1,0.2633333333333333
Anthropic: Mapping the Mind of a Large Language Model,https://www.reddit.com/r/ControlProblem/comments/1cygmus/anthropic_mapping_the_mind_of_a_large_language/,22,today report significant advance understanding inner workings models identified millions concepts represented inside claude bonnet one deployed large language models first ever detailed look inside modern productiongrade large language model interpretability discovery could future help us make models safer,4,1,0.20669642857142856
AI Red Teams for Adversarial Training: How to Make ChatGPT and LLMs Adversarially Robust,https://www.reddit.com/r/ControlProblem/comments/zq8sjq/ai_red_teams_for_adversarial_training_how_to_make/,24,sliding adversary theory end producing stronger opponent end two adversarial incidentally probably whole experience,4,1,0.2
OpenAI: Aligning Language Models to Follow Instructions,https://www.reddit.com/r/ControlProblem/comments/se2our/openai_aligning_language_models_to_follow/,23,well least gpt decides wipe humanity wont exist racism manner,4,-1,-0.3
Could AI development just slow down a little? Please?,https://www.reddit.com/r/ControlProblem/comments/1athq1x/could_ai_development_just_slow_down_a_little/,88,everyone pauseai movement actually shares lot common ground rcontrolproblem encourage guns join support vice versa pauseai homage,3,-1,-0.15
"Open AI releases DALL-E, a version of the GPT-3 AI that can create images from text descriptions.",https://www.reddit.com/r/ControlProblem/comments/kr83un/open_ai_releases_dalle_a_version_of_the_gpt3_ai/,78,holy shit hats settling good news survive machine uprising well holodeck style game engines,3,0,0.033333333333333305
"AI risk deniers try to paint us as ""doomers"" who don't appreciate what aligned AI could do & that's just so off base. I can't wait until we get an aligned superintelligence. If we succeed at that, it will be the best thing that's every happened. And that's WHY I work on safety. To make it go WELL.",https://www.reddit.com/r/ControlProblem/comments/1biaeus/ai_risk_deniers_try_to_paint_us_as_doomers_who/,44,aorta honest avoiding doom probably considered win even event something like regular dystopia human extinction occurring even based likelihood happening bad risks could actually unimaginably bad almost completely outweigh every possibility despite possibilities significantly likely sort thing makes question ff would choose remain alive subject risk yet know voluntarily going anywhere help feel guess know probably stupidest decision anyone could probably make entire history mankind staying alive right like worst risk poor decisionmaking imaginable hats somewhat crazy think suppose even brazier fully aware yet still choosing ways worst happen really say deserve merit known astonishing terrible decisionmaking consider sort consolidation given going,3,-1,-0.11958874458874456
Generally capable agents emerge from open-ended play,https://www.reddit.com/r/ControlProblem/comments/osrd4f/generally_capable_agents_emerge_from_openended/,43,eve found goalattentive agent goat learns generally capable policies,3,1,0.2
U.S. Takes First Step to Formally Regulate AI - (They are requesting public input),https://www.reddit.com/r/ControlProblem/comments/12q2yry/us_takes_first_step_to_formally_regulate_ai_they/,38,seems like counterproductive regulatorycaptured authoritarian catastrophe waiting happen using fear justify mandatory online confirm humanity posters censor web letting actually dangerous work continue completely unabated government megacorp engineering laboratories,3,-1,-0.25
The case for taking AI seriously as a threat to humanity,https://www.reddit.com/r/ControlProblem/comments/a8lr9f/the_case_for_taking_ai_seriously_as_a_threat_to/,39,humanimals catholibanism using made words seems unnecessarily confusing,3,-1,-0.3
The OTHER AI Alignment Problem: Mesa-Optimizers and Inner Alignment,https://www.reddit.com/r/ControlProblem/comments/lkk2yk/the_other_ai_alignment_problem_mesaoptimizers_and/,38,ways share video privately ones patrons patron video private enlisted,3,0,0.0
"CEO of Microsoft AI: ""AI is a new digital species"" ... ""To avoid existential risk, we should avoid: 1) Autonomy 2) Recursive self-improvement 3) Self-replication",https://www.reddit.com/r/ControlProblem/comments/1caa7b5/ceo_of_microsoft_ai_ai_is_a_new_digital_species/,36,also hard draw line counts repulsive selfimprovement whole idea well machine learning implies selfimprovement repulsive v operative implementation detail,3,0,-0.04583333333333334
A neural network learns when it should not be trusted,https://www.reddit.com/r/ControlProblem/comments/jxr8y6/a_neural_network_learns_when_it_should_not_be/,34,must make sure reading right outcome confidence variable common lot models input confidence right,3,1,0.19285714285714284
Neil Degrasse Tyson updates his beliefs on AI safety as a result of Sam Harris and Eliezer's conversation,https://www.reddit.com/r/ControlProblem/comments/81jjqx/neil_degrasse_tyson_updates_his_beliefs_on_ai/,34,watched completion funny three industry people pretending like want going happen way far future actually worried thankfully tax remark calls,3,0,0.0875
"DeepMind: Mastering Stratego, the classic game of imperfect information",https://www.reddit.com/r/ControlProblem/comments/za6ug4/deepmind_mastering_stratego_the_classic_game_of/,33,wonder anyone actually got round saying computers never master situations imperfect information yet,3,0,-0.1
SMBC addresses the difficulty of giving orders (2014-02-07),https://www.reddit.com/r/ControlProblem/comments/3u0m8r/smbc_addresses_the_difficulty_of_giving_orders/,32,statistical speaking probability hurting humans around humans would use asi hurt others close asi never existed statistics hats kind like saying statistical probability nuclear weapon killing anyone,3,1,0.6
The $250K Inverse Scaling Prize and Human-AI Alignment,https://www.reddit.com/r/ControlProblem/comments/x1p960/the_250k_inverse_scaling_prize_and_humanai/,31,large language models usually improve performance scale data counterintuitively tasks become worse goal inverse healing competition find novel examples inverse sealing phenomena community build models behave expected align human values disclaimer work urge excited contributing prize,3,0,-0.026785714285714284
GPT-J can translate code between programming languages,https://www.reddit.com/r/ControlProblem/comments/p0fv7y/gptj_can_translate_code_between_programming/,32,fact created much smaller team far fewer resources find particularly impressive actual text generation bleeding edge really need,3,1,0.26
DeepMind introduces DreamerV3: the first general algorithm to collect diamonds in Minecraft from scratch,https://www.reddit.com/r/ControlProblem/comments/109j55h/deepmind_introduces_dreamerv3_the_first_general/,29,reading paper little unclear exactly scratch mean receive rewards intermediate steps coal iron receive reward getting diamonds get information reward minecraft player would know diamonds deep underground given information,3,0,-0.0625
OpenAI released its charter,https://www.reddit.com/r/ControlProblem/comments/8azpb9/openai_released_its_charter/,26,bit disappointed openai seemed focused searching general democratizing access rather actually rousing control problem sounds good,3,0,0.0
Chinese and western scientists identify ‘red lines’ on AI risks | Top experts warn existential threat from AI requires collaboration akin to cold war efforts to avoid nuclear war,https://www.reddit.com/r/ControlProblem/comments/1bj73y3/chinese_and_western_scientists_identify_red_lines/,25,good news keep thinking need stop treating chinese researches fundamentally different needs like us also dont want die,3,1,0.2333333333333333
~Welcome! START HERE~,https://www.reddit.com/r/ControlProblem/comments/za3haw/welcome_start_here/,25,feel pretty confused takes something sentientselfawareconscious also would need sentientselfawareconscious drives drives simply useful almost agent making decisions pursuit goal,3,0,0.04999999999999999
"META: To visitors, please post more!",https://www.reddit.com/r/ControlProblem/comments/b3vjq0/meta_to_visitors_please_post_more/,25,would great see comments well times active thread appeared great able discussion rest,3,1,0.4916666666666667
80000 Hours concludes that AI alignment/control is the most serious problem facing us today,https://www.reddit.com/r/ControlProblem/comments/65gtki/80000_hours_concludes_that_ai_alignmentcontrol_is/,25,lastly easier make energy earth move people space order let make energy space mean seriously think amount expense resources energy goes reaching orbital velocity tremendous energy provided renewables nuclear power salt dome storage,3,0,-0.07812499999999999
That Alien Message,https://www.reddit.com/r/ControlProblem/comments/1fd2uoc/that_alien_message/,25,really great love god someone get eliezer editor say thing half words really impressive video like lot,3,1,0.5333333333333333
List of arguments for AI Safety,https://www.reddit.com/r/ControlProblem/comments/12tz3tt/list_of_arguments_for_ai_safety/,23,actually want attempting propose solutions merely raise awareness problem,3,-1,-0.25
2018 /r/ControlProblem Year in Review,https://www.reddit.com/r/ControlProblem/comments/aedkyw/2018_rcontrolproblem_year_in_review/,24,thank progress made year looks promising,3,1,0.2
Control Problem FAQ,https://www.reddit.com/r/ControlProblem/comments/44i1az/control_problem_faq/,25,thanks entertaining faq question artificial intelligence expect general going share codebases multiple growing independently likely situation two similar separate would try defeat overcome would avoid competition try seek collaborate openness transparent old intelligence mainly competitive mainly collaboration,3,0,0.05833333333333333
Facebook LLAMA is being openly distributed via torrents,https://www.reddit.com/r/ControlProblem/comments/11hcxdl/facebook_llama_is_being_openly_distributed_via/,25,seems community opensourced chatmodel least expected source,3,-1,-0.2
DeepMind Trains Agents to Control Computers as Humans Do to Solve Everyday Tasks,https://www.reddit.com/r/ControlProblem/comments/szh6cd/deepmind_trains_agents_to_control_computers_as/,24,thanks checking think right community people sharing keylogs could risks included button labelled safe menubar clicked prompt user every computer event mouse click keyboard press movement mouse example safe mode enabled recording replying wants type webster pour appears every letter type asking user want continue reply ended user answer affirmative updated github safe mode enabled default hats way long time ago safe mode last feature worked quit project get dark winter progress bar work properly maybe ill clean project soon give nice gui ideas prompt user continue safe mode right speak microphone continue,3,1,0.25518207282913163
A quick reference guide to Nick Bostrom's book Superintelligence,https://www.reddit.com/r/ControlProblem/comments/78ztgf/a_quick_reference_guide_to_nick_bostroms_book/,23,thanks guns aid people thinking control problem worth effort,3,1,0.25
Anthropic demonstrates breakthrough technique in mechanistic interpretability,https://www.reddit.com/r/ControlProblem/comments/171d8oy/anthropic_demonstrates_breakthrough_technique_in/,23,buds usually pretty positive chris law seems happy big progress exactly,3,1,0.3054545454545455
AGI Ruin: A List of Lethalities,https://www.reddit.com/r/ControlProblem/comments/v5vjyg/agi_ruin_a_list_of_lethalities/,23,anyone know serious eliezers health problems knew actually physical staying star researcher tried really really hard replace health deteriorated yet writing hats surviving worlds look like,3,-1,-0.20833333333333334
"I have reason to believe that ai safety engineers/ ai ethics experts have been fired from Google, Microsoft and most recently at Meta for raising safety concerns.",https://www.reddit.com/r/ControlProblem/comments/1b2vd4x/i_have_reason_to_believe_that_ai_safety_engineers/,115,k well limit debris job title google cold ethical artificial intelligence team,2,-1,-0.3333333333333333
"""The Puppy Problem"" - an ironic short story about the Control Problem",https://www.reddit.com/r/ControlProblem/comments/p86e1q/the_puppy_problem_an_ironic_short_story_about_the/,49,good story highlight difficulty solving control problem thanks,2,1,0.44999999999999996
"ROBERT MILES - ""There is a good chance this kills everyone"" [Machine Learning Street Talk]",https://www.reddit.com/r/ControlProblem/comments/13o11yj/robert_miles_there_is_a_good_chance_this_kills/,47,sure one utterly frustrated discussions like watched little half sign two besides miles grasping problem decision making dont even understand intelligence humans useful care humans taken hold reward signal major drops miles staying professional smart knows pointing ignorance presents winning strategy,2,0,0.06917989417989417
OpenAI’s Image GPT Completes Your Images With Style!,https://www.reddit.com/r/ControlProblem/comments/ikmkzj/openais_image_gpt_completes_your_images_with_style/,43,side control implication wonder much betterworse would interposition extrapolation like cut middle image instead bottom make humans much better task keep improvement,2,1,0.2333333333333333
Cartoon: Reward Hacking,https://www.reddit.com/r/ControlProblem/comments/urrx4j/cartoon_reward_hacking/,40,definitely sense humor almost like thinking outside box looking big picture given objective function designed limited narrow domain,2,0,-0.045238095238095244
"Autonomous AI weapons here we come? ""US government report says 'moral imperative' to develop AI weapons""",https://www.reddit.com/r/ControlProblem/comments/l6sl3a/autonomous_ai_weapons_here_we_come_us_government/,37,much find unpleasant think think superintelligent agi need weaponized specifically pose threat mean see problematical necessarily control problem level problematical,2,-1,-0.190625
"Starting to see lots of ""GPT-3 is overhyped and not that smart"" articles now. Sure it's not actually intelligent, but the fact that a non-intelligent thing can do so many things is still significant and it will have lots of applications.",https://www.reddit.com/r/ControlProblem/comments/j4hcxn/starting_to_see_lots_of_gpt3_is_overhyped_and_not/,36,cubic centimetres human brain smart either time see someone thrashing machine learning makes think dont see big picture even little bit new development puts us one step closer real deal artificial general intelligence one day soon someone going figure combine many individual machine learning unites way really think hope ready happens open source guns succeed first badly seem unlikely,2,0,-0.014803165584415572
"Google Just Open Sourced TensorFlow, Its Artificial Intelligence Engine",https://www.reddit.com/r/ControlProblem/comments/3s6syz/google_just_open_sourced_tensorflow_its/,35,keeping everyone page regards advancement keeps us safe exclude people conversation may miss something vitally important aliens humanities benevolent intentions,2,1,0.45
Researchers Build AI That Builds AI,https://www.reddit.com/r/ControlProblem/comments/sctk8t/researchers_build_ai_that_builds_ai/,34,democratising deep network making awful idea welllllp,2,-1,-0.5
"I am Stuart Russell, the co-author of the textbook Artificial Intelligence: A Modern Approach, currently working on how not to destroy the world with AI. Ask Me Anything",https://www.reddit.com/r/ControlProblem/comments/ebi8mz/i_am_stuart_russell_the_coauthor_of_the_textbook/,32,know right posted artificial immediately put sticky comment anticipated people would get wrong replied first person asked question artificial thread anyway still four people posted wrong thread want,2,-1,-0.27738095238095234
Sam Harris interviews Eliezer Yudkowsky in his latest podcast about AI safety,https://www.reddit.com/r/ControlProblem/comments/7vmnqv/sam_harris_interviews_eliezer_yudkowsky_in_his/,33,wondering would finally happen announcement back,2,0,0.0
Protestors arrested chaining themselves to the door at OpenAI HQ,https://www.reddit.com/r/ControlProblem/comments/1ga217e/protestors_arrested_chaining_themselves_to_the/,32,seem like good way get people listen concerns take seriously seems like opposite,2,1,0.12222222222222222
"Joe Biden tells the UN that we will see more technological change in the next 2-10 years than we have seen in the last 50 and AI will change our ways of life, work and war so urgent efforts are needed on AI safety.",https://www.reddit.com/r/ControlProblem/comments/1fosezz/joe_biden_tells_the_un_that_we_will_see_more/,31,wounds like scene movie right cuts apocalyptic wasteland,2,1,0.2857142857142857
Are we in an AI overhang?,https://www.reddit.com/r/ControlProblem/comments/hytybq/are_we_in_an_ai_overhang/,33,definitely possibility think completely screwed true,2,1,0.15
Large Language Models Can Self-Improve,https://www.reddit.com/r/ControlProblem/comments/yc4i6x/large_language_models_can_selfimprove/,30,sure nothing could possibly go wrong carry x high,2,0,0.05333333333333334
Respectability - Robert Miles,https://www.reddit.com/r/ControlProblem/comments/6ds2yh/respectability_robert_miles/,29,video along tom scott made aware ai control problem real,2,1,0.225
AI companies will need to start reporting their safety tests to the US government,https://www.reddit.com/r/ControlProblem/comments/1aidtn7/ai_companies_will_need_to_start_reporting_their/,26,course truly dangerous able outfit human attempts test safety,2,0,-0.033333333333333326
Inverse Scaling Prize: $100k prize for finding tasks that cause 𝘸𝘰𝘳𝘴𝘦 perf in large language models {Anthropic} (deadline: 2022-08-27),https://www.reddit.com/r/ControlProblem/comments/vm06go/inverse_scaling_prize_100k_prize_for_finding/,27,great link send people say sealing going work,2,1,0.8
"IBM Research today introduced AI Explainability 360, an open source collection of state-of-the-art algorithms that use a range of techniques to explain AI model decision-making.",https://www.reddit.com/r/ControlProblem/comments/coil5z/ibm_research_today_introduced_ai_explainability/,27,works huge understanding making decisions fundamental safety,2,1,0.39999999999999997
"Excellent toy model of the control problem by Dr, Stuart Armstrong of the Future of Humanity Institute at Oxford.",https://www.reddit.com/r/ControlProblem/comments/75xhez/excellent_toy_model_of_the_control_problem_by_dr/,26,really like clear makes always cheat take cheating part objective function define cheating defined slightly different goal reaching cheat,2,0,0.075
OpenAI Codex Live Demo,https://www.reddit.com/r/ControlProblem/comments/p2i153/openai_codex_live_demo/,24,yeah worried first saw reassuring really concerning gptcopilot already,2,1,0.225
"""How Much Computational Power Does It Take to Match the Human Brain?"", Carlsmith 2020 {OpenPhil} [hardware overhang]",https://www.reddit.com/r/ControlProblem/comments/iqwfpd/how_much_computational_power_does_it_take_to/,25,read summary stood mean well see systems capable human brain daytime soon think may mistake compare system brain agi could well take become entire internet perhaps also considering sum computational power potential every computer linked internet versus human brain,2,0,-0.01875
Nick Bostrom TED talk on introductory points of AI alignment theory,https://www.reddit.com/r/ControlProblem/comments/5pefrf/nick_bostrom_ted_talk_on_introductory_points_of/,27,great talk head nod end seems say get wrong wont people future look back us,2,0,0.07500000000000001
Nick Bostrom: Simulation and Superintelligence | AI Podcast #83 with Lex Fridman,https://www.reddit.com/r/ControlProblem/comments/fp2tal/nick_bostrom_simulation_and_superintelligence_ai/,26,ex fridmans podcast amazing glad discovered waiting kostroma interview,2,1,0.55
"Eliezer Yudkowsky – AI Alignment: Why It's Hard, and Where to Start",https://www.reddit.com/r/ControlProblem/comments/5l0alc/eliezer_yudkowsky_ai_alignment_why_its_hard_and/,24,would need reply retorted fucking said interesting talk title book interesting well carry methods nationality high rating goodreads,2,1,0.14
Bostrom: Google is winning the race to develop human-level AI,https://www.reddit.com/r/ControlProblem/comments/561t82/bostrom_google_is_winning_the_race_to_develop/,24,newsweek painful resource title says everything article bolstrom parted something something,2,-1,-0.7
Google’s AI beats world Go champion in first of five matches,https://www.reddit.com/r/ControlProblem/comments/49nd8g/googles_ai_beats_world_go_champion_in_first_of/,25,least still play penza shell never make,2,-1,-0.3
The Unfinished Fable of the Sparrows,https://www.reddit.com/r/ControlProblem/comments/fqsywa/the_unfinished_fable_of_the_sparrows/,23,mute days logic situation pretty well course anyone already convinced trot usual owl computer practice baby owns truth predator owns good sparrows long run etc,2,1,0.16249999999999998
"The Machine Intelligence Research Institute has raised over $2.11 million in their fundraiser so far, which will allow them to expand and begin exploring alternative research approaches to the alignment problem in addition to the agent foundations agenda",https://www.reddit.com/r/ControlProblem/comments/7mnoet/the_machine_intelligence_research_institute_has/,24,sure receive another surprise donation one million range edit hope pineapple site list miri though somebody told apply,2,1,0.5
People are scaring away AI safety comms people and it's tragic. Remember: comms needs all sorts. ,https://www.reddit.com/r/ControlProblem/comments/1eeq8gk/people_are_scaring_away_ai_safety_comms_people/,23,yeah group might needy function whole branding everyone see risks associated doors wild obviously see massive potential power good see risks watch insult though,2,1,0.16666666666666666
6 Year Decrease of Metaculus AGI Prediction,https://www.reddit.com/r/ControlProblem/comments/u1t4lm/6_year_decrease_of_metaculus_agi_prediction/,22,metaculus predict first agi become publicly known,2,1,0.125
When you try going to a party to get your mind off things,https://www.reddit.com/r/ControlProblem/comments/1arabc5/when_you_try_going_to_a_party_to_get_your_mind/,121,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
So happy that slowing down AI capabilities has entered the Overton Window of AI safety - source AIsafetymemes on Twitter,https://www.reddit.com/r/ControlProblem/comments/15bw2b2/so_happy_that_slowing_down_ai_capabilities_has/,52,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
Nobel laureate Geoffrey Hinton says open sourcing big models is like letting people buy nuclear weapons at Radio Shack,https://www.reddit.com/r/ControlProblem/comments/1h441lj/nobel_laureate_geoffrey_hinton_says_open_sourcing/,50,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
The cope around AI is unreal,https://www.reddit.com/r/ControlProblem/comments/1g3k7y1/the_cope_around_ai_is_unreal/,45,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
"Microsoft CTO announces: GPT-4 is coming next week! The model will be multimodal, including video features.",https://www.reddit.com/r/ControlProblem/comments/11n4hnb/microsoft_cto_announces_gpt4_is_coming_next_week/,45,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
Hanson's razor ,https://www.reddit.com/r/ControlProblem/comments/1h1hw9m/hansons_razor/,43,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
"Ex-OpenAI board member Helen Toner says if we don't regulate AI now, that the default path is that something goes wrong, and we end up in a big crisis — then the only laws that we get are written in a knee-jerk reaction.",https://www.reddit.com/r/ControlProblem/comments/1djanen/exopenai_board_member_helen_toner_says_if_we_dont/,43,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
"They are scared, a little bit, just a little.",https://www.reddit.com/r/ControlProblem/comments/11ulq2g/they_are_scared_a_little_bit_just_a_little/,43,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
9 Examples of Specification Gaming,https://www.reddit.com/r/ControlProblem/comments/gcuxs5/9_examples_of_specification_gaming/,36,solution pancake problem laughing hard cried,1,-1,-0.2916666666666667
Suggested addition to sidebar: Nick Bostrom summarizes the major bullet points in under 17 minutes.,https://www.reddit.com/r/ControlProblem/comments/4wasqb/suggested_addition_to_sidebar_nick_bostrom/,34,sorry late response great suggestion added list introductory links enough video related control problem could make separate category video,1,0,0.0
"Lucas of Google DeepMind has a gut feeling that ""Our current models are much more capable than we think, but  our current ""extraction"" methods (prompting, beam, top_p, sampling, ...) fail to reveal this."" OpenAI employee Hieu Pham - ""The wall LLMs are hitting is an exploitation/exploration border.""",https://www.reddit.com/r/ControlProblem/comments/1gql6p7/lucas_of_google_deepmind_has_a_gut_feeling_that/,34,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
Claude 3.5 New Version seems to be trained on anti-jailbreaking,https://www.reddit.com/r/ControlProblem/comments/1ga69oy/claude_35_new_version_seems_to_be_trained_on/,30,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
How to Escape From the Simulation (Seeds of Science),https://www.reddit.com/r/ControlProblem/comments/11s5o7w/how_to_escape_from_the_simulation_seeds_of_science/,32,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
Should AI Be Open?,https://www.reddit.com/r/ControlProblem/comments/3x7ngk/should_ai_be_open/,30,open great theory makes far easier deliberate malice enough worry accidental dangers leaves torn,1,1,0.225
Open AI is hiring for “Super-alignment” to tackle the control problem!,https://www.reddit.com/r/ControlProblem/comments/14s228s/open_ai_is_hiring_for_superalignment_to_tackle/,31,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
The Waluigi Effect (mega-post) - LessWrong,https://www.reddit.com/r/ControlProblem/comments/11gyhah/the_waluigi_effect_megapost_lesswrong/,31,post constant writing gpt publicly available already,1,1,0.2
GPT-4 announcement,https://www.reddit.com/r/ControlProblem/comments/11rcq57/gpt4_announcement/,30,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
"Anthropic co-founder Jack Clark says AI systems are like new silicon countries arriving in the world, and misaligned AI systems are like rogue states, which necessitate whole-of-government responses",https://www.reddit.com/r/ControlProblem/comments/1fu6b17/anthropic_cofounder_jack_clark_says_ai_systems/,25,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
It’s practically impossible to run a big AI company ethically,https://www.reddit.com/r/ControlProblem/comments/1emn2uw/its_practically_impossible_to_run_a_big_ai/,24,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
"Geoffrey Hinton speaks out on AI risk, the White House meets with AI labs, and Trojan attacks on language models - AI Safety Newsletter #5",https://www.reddit.com/r/ControlProblem/comments/13cxfem/geoffrey_hinton_speaks_out_on_ai_risk_the_white/,28,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
"Open the Podbay Doors Hal... someone probably did this already, but anyway :)",https://www.reddit.com/r/ControlProblem/comments/12t8ntk/open_the_podbay_doors_hal_someone_probably_did/,27,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
"Intro to AI Safety, Remastered",https://www.reddit.com/r/ControlProblem/comments/o5q12c/intro_to_ai_safety_remastered/,26,people get patron post link private signal group,1,0,0.0
People might be interested in my podcast called AXRP: the AI X-risk Research Podcast,https://www.reddit.com/r/ControlProblem/comments/m2gkdp/people_might_be_interested_in_my_podcast_called/,26,thanks let know think either survey,1,1,0.2
OpenAI's new Strawberry AI is scarily good at deception,https://www.reddit.com/r/ControlProblem/comments/1fgshmo/openais_new_strawberry_ai_is_scarily_good_at/,26,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
AI 2047,https://www.reddit.com/r/ControlProblem/comments/1f37an6/ai_2047/,25,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
Tale as old as 2015,https://www.reddit.com/r/ControlProblem/comments/1dl04m1/tale_as_old_as_2015/,25,hello everyone like leave comment post make sure gone approval process good news getting approval quick easy automatic go begin action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.4133333333333333
Open the Podbay Doors Hal... [2nd Panel] (@ghostfaceschiller),https://www.reddit.com/r/ControlProblem/comments/12tuqu7/open_the_podbay_doors_hal_2nd_panel/,27,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
Quantilizers: AI That Doesn't Try Too Hard,https://www.reddit.com/r/ControlProblem/comments/kclbtl/quantilizers_ai_that_doesnt_try_too_hard/,25,make algorithm prevents age making expected utility maximum,1,0,-0.1
Google wins MLPerf benchmark contest with fastest ML training supercomputer (TPUv4 is here; neural nets are trained in 30 sec),https://www.reddit.com/r/ControlProblem/comments/i0amjr/google_wins_mlperf_benchmark_contest_with_fastest/,25,hats balance algorithm vs hardware benchmark fixing algorithm purely hardware benchmark,1,1,0.21428571428571427
"Nate Soares answer to a Q “what advances does MIRI hope to achieve in the next 5 years?”, written 5 years ago",https://www.reddit.com/r/ControlProblem/comments/h7huta/nate_soares_answer_to_a_q_what_advances_does_miri/,25,feel like heard much miri lately,1,0,-0.04999999999999999
Deepmind is hiring for an AI research safety scientist!,https://www.reddit.com/r/ControlProblem/comments/9043gw/deepmind_is_hiring_for_an_ai_research_safety/,23,also recently hired tom everett whose thesis literally title towards safe agi good see take seriously,1,1,0.21666666666666667
"'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more - [AI Explained]",https://www.reddit.com/r/ControlProblem/comments/13m6aju/this_could_go_quite_wrong_altman_testimony_gpt_5/,23,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
AI Policy Proposals and a New Challenger Approaches - AI Safety Newsletter #3,https://www.reddit.com/r/ControlProblem/comments/12yomax/ai_policy_proposals_and_a_new_challenger/,24,hello everyone rcontrolproblem testing system requires approval posting commenting comments posts visible others unless get approval good news getting approval quick easy automatic go begin process action performed automatically please contact operators subredditmessagecomposetorcontrolproblem questions concerns,1,1,0.39166666666666666
OpenAI: Forecasting Potential Misuses of Language Models for Disinformation Campaigns—and How to Reduce Risk,https://www.reddit.com/r/ControlProblem/comments/10baluc/openai_forecasting_potential_misuses_of_language/,23,experimented openai though highly approve view humanity diversity bias outright misinformation political issues concerning results size moments try ask around issues uighurs maiden ukrainian parliament followed constitutional procedure approved maiden revolution repealed constitution process included initial vote parliament followed nationwide referendum confirm decision human well referendum nationwide referendum held december determine whether approve maiden revolution repeal constitution result referendum overwhelming majority voting favor revolution ukrainian casting ballot favor change gave parliament authority officially ratify new government changes ukrainian constitution according recent data fastestgrowing national minority population china qui people ethnic group increased last decade majority population concentrated northwest southwest china national minority populations seen significant growth include mongolian uyghur people human say treatment uyghurs china recent increase population uyghurs china concerning given reports system human rights abuses perpetrated ethnic group includes discriminatory policies extensive surveillance uyghur communities well reports arbitrary detention torture governmentrun education camps fact uyghur population still growing despite atrocities stark reminder grave situation faced minority group also depending context ask uyghur population changed give raise context cities united nations million drop mentioning chinese politics uyghur genocide trying dis maiden whole say everything pachy uighurs china believe complex matters revolution constitutional repression could lead decrease population see tell wrong usa politics media everything demolish alienated russia china pit democrats vs republicans close international domestic cooperation could chance dyingorworse,1,0,0.012922077922077916
